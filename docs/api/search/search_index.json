{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"gcip API reference project structure and terminology of artifacts To keep this source code folder as clean as possible, all code files are sorted into one of these folders: core lib tools addons The core folder contains, as the name implies, all the core components that represent Gitlab CI objects in Python. You need to know that all class names from all Python modules within the core folder are mapped to the gcip root module. This is done within the __init__.py of the gcip folder. Instead of import gcip.core.job.Job you should import gcip.Job . You should import all classes of the core folder the same way. Always remember: # Dos: from gcip import Pipeline , Job , Sequence # ... and so on pipeline = Pipeline () # Dont's from gcip.core import pipeline , job pipeline = pipeline . Pipeline () The lib folder contains all higher level objects which are derived from the core objects. For example: gcip.Rule from gcip.core.rule is the general Gitlab CI Rule representation, whereas core.rules contains some convenient predefined Rule instances like on_main() or on_tags() . The tools folder contains all code which is used by the library code but does not represent any Gitlab CI specific functionality. This directory also contains scripts which could be run on their own and are supposed to be called by Gitlab CI jobs during the pipeline execution. For example gcip.tools.url.is_valid_url(str) which, as the name implies, checks if str is a valid url. The addons folder also contains code which extends the core components in form of higher level objects that provide functionality for a specific use case. A use case could be python , ruby , cloudformation , ansible et cetera. Every subdirectory of addons has the name of such a use case. The name addons is chosen by the intention that in future the subdirectories will be outsourced into separate projects. This could be the case when the core library is stable enough to not hinder the development of the downstream addons projects and the addons were too many to be maintained within the core library. However at this point the project is small enough to provide the core and add on functionality in an easy to use all-in-one package. We also use a following naming conventions throughout the library: Files called job_scripts.py hold functions that return strings, which could be used as command within Gitlab CI jobs. Directories called tools hold Python scripts which could be called by Gitlab CI jobs during the pipeline execution. They will be called directly from the Gitlab CI Python library, e.g. python3 -m gcip.path.to.script .","title":"gcip API reference"},{"location":"#gcip-api-reference","text":"","title":"gcip API reference"},{"location":"#project-structure-and-terminology-of-artifacts","text":"To keep this source code folder as clean as possible, all code files are sorted into one of these folders: core lib tools addons The core folder contains, as the name implies, all the core components that represent Gitlab CI objects in Python. You need to know that all class names from all Python modules within the core folder are mapped to the gcip root module. This is done within the __init__.py of the gcip folder. Instead of import gcip.core.job.Job you should import gcip.Job . You should import all classes of the core folder the same way. Always remember: # Dos: from gcip import Pipeline , Job , Sequence # ... and so on pipeline = Pipeline () # Dont's from gcip.core import pipeline , job pipeline = pipeline . Pipeline () The lib folder contains all higher level objects which are derived from the core objects. For example: gcip.Rule from gcip.core.rule is the general Gitlab CI Rule representation, whereas core.rules contains some convenient predefined Rule instances like on_main() or on_tags() . The tools folder contains all code which is used by the library code but does not represent any Gitlab CI specific functionality. This directory also contains scripts which could be run on their own and are supposed to be called by Gitlab CI jobs during the pipeline execution. For example gcip.tools.url.is_valid_url(str) which, as the name implies, checks if str is a valid url. The addons folder also contains code which extends the core components in form of higher level objects that provide functionality for a specific use case. A use case could be python , ruby , cloudformation , ansible et cetera. Every subdirectory of addons has the name of such a use case. The name addons is chosen by the intention that in future the subdirectories will be outsourced into separate projects. This could be the case when the core library is stable enough to not hinder the development of the downstream addons projects and the addons were too many to be maintained within the core library. However at this point the project is small enough to provide the core and add on functionality in an easy to use all-in-one package. We also use a following naming conventions throughout the library: Files called job_scripts.py hold functions that return strings, which could be used as command within Gitlab CI jobs. Directories called tools hold Python scripts which could be called by Gitlab CI jobs during the pipeline execution. They will be called directly from the Gitlab CI Python library, e.g. python3 -m gcip.path.to.script .","title":"project structure and terminology of artifacts"},{"location":"CONTRIBUTING/","text":"Thanks for your interest in our project. Contributions are welcome. Feel free to [open an issue])(issues) with questions or reporting ideas and bugs, or open pull requests to contribute code. Currently this project is an early implementation of an idea with a lot of influences from the daily use in our pipelines at deutschebahn.com. Not yet ready designed we might still publish breaking changes. We also have a strong opinion of how this library should be designed. That means not all contributions would be accepted as-is. Please respect if we enforce changes to contributions or deny some. However our opinion of how things work are changing, so discussions are welcomed. We are committed to fostering a welcoming, respectful, and harassment-free environment. Be kind!","title":"Contributing"},{"location":"docs/portray/","text":"gcip API reference project structure and terminology of artifacts To keep this source code folder as clean as possible, all code files are sorted into one of these folders: core lib tools addons The core folder contains, as the name implies, all the core components that represent Gitlab CI objects in Python. You need to know that all class names from all Python modules within the core folder are mapped to the gcip root module. This is done within the __init__.py of the gcip folder. Instead of import gcip.core.job.Job you should import gcip.Job . You should import all classes of the core folder the same way. Always remember: # Dos: from gcip import Pipeline , Job , Sequence # ... and so on pipeline = Pipeline () # Dont's from gcip.core import pipeline , job pipeline = pipeline . Pipeline () The lib folder contains all higher level objects which are derived from the core objects. For example: gcip.Rule from gcip.core.rule is the general Gitlab CI Rule representation, whereas core.rules contains some convenient predefined Rule instances like on_main() or on_tags() . The tools folder contains all code which is used by the library code but does not represent any Gitlab CI specific functionality. This directory also contains scripts which could be run on their own and are supposed to be called by Gitlab CI jobs during the pipeline execution. For example gcip.tools.url.is_valid_url(str) which, as the name implies, checks if str is a valid url. The addons folder also contains code which extends the core components in form of higher level objects that provide functionality for a specific use case. A use case could be python , ruby , cloudformation , ansible et cetera. Every subdirectory of addons has the name of such a use case. The name addons is chosen by the intention that in future the subdirectories will be outsourced into separate projects. This could be the case when the core library is stable enough to not hinder the development of the downstream addons projects and the addons were too many to be maintained within the core library. However at this point the project is small enough to provide the core and add on functionality in an easy to use all-in-one package. We also use a following naming conventions throughout the library: Files called job_scripts.py hold functions that return strings, which could be used as command within Gitlab CI jobs. Directories called tools hold Python scripts which could be called by Gitlab CI jobs during the pipeline execution. They will be called directly from the Gitlab CI Python library, e.g. python3 -m gcip.path.to.script .","title":"Home"},{"location":"docs/portray/#gcip-api-reference","text":"","title":"gcip API reference"},{"location":"docs/portray/#project-structure-and-terminology-of-artifacts","text":"To keep this source code folder as clean as possible, all code files are sorted into one of these folders: core lib tools addons The core folder contains, as the name implies, all the core components that represent Gitlab CI objects in Python. You need to know that all class names from all Python modules within the core folder are mapped to the gcip root module. This is done within the __init__.py of the gcip folder. Instead of import gcip.core.job.Job you should import gcip.Job . You should import all classes of the core folder the same way. Always remember: # Dos: from gcip import Pipeline , Job , Sequence # ... and so on pipeline = Pipeline () # Dont's from gcip.core import pipeline , job pipeline = pipeline . Pipeline () The lib folder contains all higher level objects which are derived from the core objects. For example: gcip.Rule from gcip.core.rule is the general Gitlab CI Rule representation, whereas core.rules contains some convenient predefined Rule instances like on_main() or on_tags() . The tools folder contains all code which is used by the library code but does not represent any Gitlab CI specific functionality. This directory also contains scripts which could be run on their own and are supposed to be called by Gitlab CI jobs during the pipeline execution. For example gcip.tools.url.is_valid_url(str) which, as the name implies, checks if str is a valid url. The addons folder also contains code which extends the core components in form of higher level objects that provide functionality for a specific use case. A use case could be python , ruby , cloudformation , ansible et cetera. Every subdirectory of addons has the name of such a use case. The name addons is chosen by the intention that in future the subdirectories will be outsourced into separate projects. This could be the case when the core library is stable enough to not hinder the development of the downstream addons projects and the addons were too many to be maintained within the core library. However at this point the project is small enough to provide the core and add on functionality in an easy to use all-in-one package. We also use a following naming conventions throughout the library: Files called job_scripts.py hold functions that return strings, which could be used as command within Gitlab CI jobs. Directories called tools hold Python scripts which could be called by Gitlab CI jobs during the pipeline execution. They will be called directly from the Gitlab CI Python library, e.g. python3 -m gcip.path.to.script .","title":"project structure and terminology of artifacts"},{"location":"reference/gcip/","text":"Module gcip gcip None View Source from pkg_resources import ( DistributionNotFound as _DistributionNotFound , get_distribution as _get_distribution , ) # yapf: disable from .core.job import ( # noqa Job , TriggerJob , TriggerStrategy , ) from .core.need import Need # noqa # yapf: disable from .core.rule import Rule , WhenStatement # noqa # yapf: disable from .core.cache import ( # noqa Cache , CacheKey , CachePolicy , ) # yapf: disable from .core.image import Image # noqa # yapf: disable from .core.include import ( # noqa IncludeFile , IncludeLocal , IncludeRemote , IncludeArtifact , IncludeTemplate , ) # yapf: disable from .core.pipeline import Pipeline # noqa from .core.variables import PredefinedVariables # noqa from .core.job_sequence import JobSequence # noqa __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' try : _distribution = _get_distribution ( \"gcip\" ) __version__ = _distribution . version __doc__ = _distribution . project_name except _DistributionNotFound : __version__ = \"unknown\" Sub-modules gcip.addons gcip.core gcip.lib gcip.tools","title":"Index"},{"location":"reference/gcip/#module-gcip","text":"gcip None View Source from pkg_resources import ( DistributionNotFound as _DistributionNotFound , get_distribution as _get_distribution , ) # yapf: disable from .core.job import ( # noqa Job , TriggerJob , TriggerStrategy , ) from .core.need import Need # noqa # yapf: disable from .core.rule import Rule , WhenStatement # noqa # yapf: disable from .core.cache import ( # noqa Cache , CacheKey , CachePolicy , ) # yapf: disable from .core.image import Image # noqa # yapf: disable from .core.include import ( # noqa IncludeFile , IncludeLocal , IncludeRemote , IncludeArtifact , IncludeTemplate , ) # yapf: disable from .core.pipeline import Pipeline # noqa from .core.variables import PredefinedVariables # noqa from .core.job_sequence import JobSequence # noqa __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' try : _distribution = _get_distribution ( \"gcip\" ) __version__ = _distribution . version __doc__ = _distribution . project_name except _DistributionNotFound : __version__ = \"unknown\"","title":"Module gcip"},{"location":"reference/gcip/#sub-modules","text":"gcip.addons gcip.core gcip.lib gcip.tools","title":"Sub-modules"},{"location":"reference/gcip/addons/","text":"Module gcip.addons None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' Sub-modules gcip.addons.cdk gcip.addons.gitlab gcip.addons.python","title":"Index"},{"location":"reference/gcip/addons/#module-gcipaddons","text":"None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com'","title":"Module gcip.addons"},{"location":"reference/gcip/addons/#sub-modules","text":"gcip.addons.cdk gcip.addons.gitlab gcip.addons.python","title":"Sub-modules"},{"location":"reference/gcip/addons/cdk/","text":"Module gcip.addons.cdk None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' Sub-modules gcip.addons.cdk.jobs gcip.addons.cdk.sequences gcip.addons.cdk.tools","title":"Index"},{"location":"reference/gcip/addons/cdk/#module-gcipaddonscdk","text":"None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com'","title":"Module gcip.addons.cdk"},{"location":"reference/gcip/addons/cdk/#sub-modules","text":"gcip.addons.cdk.jobs gcip.addons.cdk.sequences gcip.addons.cdk.tools","title":"Sub-modules"},{"location":"reference/gcip/addons/cdk/jobs/","text":"Module gcip.addons.cdk.jobs None None View Source import warnings from typing import Dict , Optional from gcip.core.job import Job __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def bootstrap ( * args : None , aws_account_id : str , aws_region : str , toolkit_stack_name : str , qualifier : str , ** tags : str ) -> Job : \"\"\" Test \"\"\" return Job ( namespace = \"cdk_bootstrap\" , script = \"cdk bootstrap\" f \" --toolkit-stack-name {toolkit_stack_name}\" f \" --qualifier {qualifier}\" f \" aws://{aws_account_id}/{aws_region}\" + \" \" . join ([ \"\" ] + list ( map ( lambda keyvalue : f \"-t {keyvalue[0]}={keyvalue[1]}\" , tags . items ()))), ) . add_variables ( CDK_NEW_BOOTSTRAP = \"1\" ) def _context_options ( context_dict : Dict [ str , str ]) -> str : if not context_dict : return \"\" return \" \" . join ( f \"-c {key}={value}\" for key , value in context_dict . items ()) + \" \" def _space ( string : str ) -> str : if string : return f \"{string} \" return \"\" def diff ( * stacks : str , synth_options : str = \"\" , diff_options : str = \"\" , ** context : str ) -> Job : stacks_string = \" \" . join ( stacks ) return Job ( name = \"cdk\" , namespace = \"diff\" , script = [ f \"cdk synth {_space(synth_options)}{stacks_string}\" , f \"cdk diff {_space(diff_options)}{_context_options(context)}{stacks_string}\" , ], ) def deploy ( * stacks : str , toolkit_stack_name : str , wait_for_stack : bool = True , wait_for_stack_assume_role : Optional [ str ] = None , wait_for_stack_account_id : Optional [ str ] = None , options : str = \"\" , ** context : str , ) -> Job : stacks_string = \" \" . join ( stacks ) job = Job ( name = \"cdk\" , namespace = \"deploy\" , script = [ f \"cdk deploy --strict --require-approval 'never' {_space(options)}\" f \"--toolkit-stack-name {toolkit_stack_name} {_context_options(context)}{stacks_string}\" , ], ) if wait_for_stack : wait_for_stack_options = \"\" if wait_for_stack_assume_role : wait_for_stack_options += f \" --assume-role {wait_for_stack_assume_role}\" if wait_for_stack_account_id : wait_for_stack_options += f \" --assume-role-account-id {wait_for_stack_account_id}\" elif wait_for_stack_account_id : warnings . warn ( \"`wait_for_stack_account_id` has no effects without `wait_for_stack_assume_role`\" ) job . prepend_scripts ( \"pip3 install gcip\" , f \"python3 -m gcip.addons.cdk.tools.wait_for_cloudformation_stack_ready --stack-names '{stacks_string}'{wait_for_stack_options}\" , ) return job Functions bootstrap def bootstrap ( * args : None , aws_account_id : str , aws_region : str , toolkit_stack_name : str , qualifier : str , ** tags : str ) -> gcip . core . job . Job Test View Source def bootstrap ( * args : None , aws_account_id : str , aws_region : str , toolkit_stack_name : str , qualifier : str , ** tags : str ) -> Job : \"\"\" Test \"\"\" return Job ( namespace = \"cdk_bootstrap\" , script = \"cdk bootstrap\" f \" --toolkit-stack-name {toolkit_stack_name}\" f \" --qualifier {qualifier}\" f \" aws://{aws_account_id}/{aws_region}\" + \" \" . join ([ \"\" ] + list ( map ( lambda keyvalue : f \"-t {keyvalue[0]}={keyvalue[1]}\" , tags . items ()))), ) . add_variables ( CDK_NEW_BOOTSTRAP = \"1\" ) deploy def deploy ( * stacks : str , toolkit_stack_name : str , wait_for_stack : bool = True , wait_for_stack_assume_role : Optional [ str ] = None , wait_for_stack_account_id : Optional [ str ] = None , options : str = '' , ** context : str ) -> gcip . core . job . Job View Source def deploy ( * stacks : str , toolkit_stack_name : str , wait_for_stack : bool = True , wait_for_stack_assume_role : Optional [ str ] = None , wait_for_stack_account_id : Optional [ str ] = None , options : str = \"\" , ** context : str , ) -> Job : stacks_string = \" \" . join ( stacks ) job = Job ( name = \"cdk\" , namespace = \"deploy\" , script = [ f \"cdk deploy --strict --require-approval 'never' {_space(options)}\" f \"--toolkit-stack-name {toolkit_stack_name} {_context_options(context)}{stacks_string}\" , ], ) if wait_for_stack : wait_for_stack_options = \"\" if wait_for_stack_assume_role : wait_for_stack_options += f \" --assume-role {wait_for_stack_assume_role}\" if wait_for_stack_account_id : wait_for_stack_options += f \" --assume-role-account-id {wait_for_stack_account_id}\" elif wait_for_stack_account_id : warnings . warn ( \"`wait_for_stack_account_id` has no effects without `wait_for_stack_assume_role`\" ) job . prepend_scripts ( \"pip3 install gcip\" , f \"python3 -m gcip.addons.cdk.tools.wait_for_cloudformation_stack_ready --stack-names '{stacks_string}'{wait_for_stack_options}\" , ) return job diff def diff ( * stacks : str , synth_options : str = '' , diff_options : str = '' , ** context : str ) -> gcip . core . job . Job View Source def diff ( * stacks : str , synth_options : str = \"\" , diff_options : str = \"\" , ** context : str ) -> Job : stacks_string = \" \" . join ( stacks ) return Job ( name = \"cdk\" , namespace = \"diff\" , script = [ f \"cdk synth {_space(synth_options)}{stacks_string}\" , f \"cdk diff {_space(diff_options)}{_context_options(context)}{stacks_string}\" , ], )","title":"Jobs"},{"location":"reference/gcip/addons/cdk/jobs/#module-gcipaddonscdkjobs","text":"None None View Source import warnings from typing import Dict , Optional from gcip.core.job import Job __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def bootstrap ( * args : None , aws_account_id : str , aws_region : str , toolkit_stack_name : str , qualifier : str , ** tags : str ) -> Job : \"\"\" Test \"\"\" return Job ( namespace = \"cdk_bootstrap\" , script = \"cdk bootstrap\" f \" --toolkit-stack-name {toolkit_stack_name}\" f \" --qualifier {qualifier}\" f \" aws://{aws_account_id}/{aws_region}\" + \" \" . join ([ \"\" ] + list ( map ( lambda keyvalue : f \"-t {keyvalue[0]}={keyvalue[1]}\" , tags . items ()))), ) . add_variables ( CDK_NEW_BOOTSTRAP = \"1\" ) def _context_options ( context_dict : Dict [ str , str ]) -> str : if not context_dict : return \"\" return \" \" . join ( f \"-c {key}={value}\" for key , value in context_dict . items ()) + \" \" def _space ( string : str ) -> str : if string : return f \"{string} \" return \"\" def diff ( * stacks : str , synth_options : str = \"\" , diff_options : str = \"\" , ** context : str ) -> Job : stacks_string = \" \" . join ( stacks ) return Job ( name = \"cdk\" , namespace = \"diff\" , script = [ f \"cdk synth {_space(synth_options)}{stacks_string}\" , f \"cdk diff {_space(diff_options)}{_context_options(context)}{stacks_string}\" , ], ) def deploy ( * stacks : str , toolkit_stack_name : str , wait_for_stack : bool = True , wait_for_stack_assume_role : Optional [ str ] = None , wait_for_stack_account_id : Optional [ str ] = None , options : str = \"\" , ** context : str , ) -> Job : stacks_string = \" \" . join ( stacks ) job = Job ( name = \"cdk\" , namespace = \"deploy\" , script = [ f \"cdk deploy --strict --require-approval 'never' {_space(options)}\" f \"--toolkit-stack-name {toolkit_stack_name} {_context_options(context)}{stacks_string}\" , ], ) if wait_for_stack : wait_for_stack_options = \"\" if wait_for_stack_assume_role : wait_for_stack_options += f \" --assume-role {wait_for_stack_assume_role}\" if wait_for_stack_account_id : wait_for_stack_options += f \" --assume-role-account-id {wait_for_stack_account_id}\" elif wait_for_stack_account_id : warnings . warn ( \"`wait_for_stack_account_id` has no effects without `wait_for_stack_assume_role`\" ) job . prepend_scripts ( \"pip3 install gcip\" , f \"python3 -m gcip.addons.cdk.tools.wait_for_cloudformation_stack_ready --stack-names '{stacks_string}'{wait_for_stack_options}\" , ) return job","title":"Module gcip.addons.cdk.jobs"},{"location":"reference/gcip/addons/cdk/jobs/#functions","text":"","title":"Functions"},{"location":"reference/gcip/addons/cdk/jobs/#bootstrap","text":"def bootstrap ( * args : None , aws_account_id : str , aws_region : str , toolkit_stack_name : str , qualifier : str , ** tags : str ) -> gcip . core . job . Job Test View Source def bootstrap ( * args : None , aws_account_id : str , aws_region : str , toolkit_stack_name : str , qualifier : str , ** tags : str ) -> Job : \"\"\" Test \"\"\" return Job ( namespace = \"cdk_bootstrap\" , script = \"cdk bootstrap\" f \" --toolkit-stack-name {toolkit_stack_name}\" f \" --qualifier {qualifier}\" f \" aws://{aws_account_id}/{aws_region}\" + \" \" . join ([ \"\" ] + list ( map ( lambda keyvalue : f \"-t {keyvalue[0]}={keyvalue[1]}\" , tags . items ()))), ) . add_variables ( CDK_NEW_BOOTSTRAP = \"1\" )","title":"bootstrap"},{"location":"reference/gcip/addons/cdk/jobs/#deploy","text":"def deploy ( * stacks : str , toolkit_stack_name : str , wait_for_stack : bool = True , wait_for_stack_assume_role : Optional [ str ] = None , wait_for_stack_account_id : Optional [ str ] = None , options : str = '' , ** context : str ) -> gcip . core . job . Job View Source def deploy ( * stacks : str , toolkit_stack_name : str , wait_for_stack : bool = True , wait_for_stack_assume_role : Optional [ str ] = None , wait_for_stack_account_id : Optional [ str ] = None , options : str = \"\" , ** context : str , ) -> Job : stacks_string = \" \" . join ( stacks ) job = Job ( name = \"cdk\" , namespace = \"deploy\" , script = [ f \"cdk deploy --strict --require-approval 'never' {_space(options)}\" f \"--toolkit-stack-name {toolkit_stack_name} {_context_options(context)}{stacks_string}\" , ], ) if wait_for_stack : wait_for_stack_options = \"\" if wait_for_stack_assume_role : wait_for_stack_options += f \" --assume-role {wait_for_stack_assume_role}\" if wait_for_stack_account_id : wait_for_stack_options += f \" --assume-role-account-id {wait_for_stack_account_id}\" elif wait_for_stack_account_id : warnings . warn ( \"`wait_for_stack_account_id` has no effects without `wait_for_stack_assume_role`\" ) job . prepend_scripts ( \"pip3 install gcip\" , f \"python3 -m gcip.addons.cdk.tools.wait_for_cloudformation_stack_ready --stack-names '{stacks_string}'{wait_for_stack_options}\" , ) return job","title":"deploy"},{"location":"reference/gcip/addons/cdk/jobs/#diff","text":"def diff ( * stacks : str , synth_options : str = '' , diff_options : str = '' , ** context : str ) -> gcip . core . job . Job View Source def diff ( * stacks : str , synth_options : str = \"\" , diff_options : str = \"\" , ** context : str ) -> Job : stacks_string = \" \" . join ( stacks ) return Job ( name = \"cdk\" , namespace = \"diff\" , script = [ f \"cdk synth {_space(synth_options)}{stacks_string}\" , f \"cdk diff {_space(diff_options)}{_context_options(context)}{stacks_string}\" , ], )","title":"diff"},{"location":"reference/gcip/addons/cdk/sequences/","text":"Module gcip.addons.cdk.sequences None None View Source from typing import Optional from gcip.core.job_sequence import JobSequence from . import jobs as cdk __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def diff_deploy ( * stacks : str , toolkit_stack_name : str , wait_for_stack : bool = True , wait_for_stack_assume_role : Optional [ str ] = None , wait_for_stack_account_id : Optional [ str ] = None , synth_options : str = \"\" , diff_options : str = \"\" , deploy_options : str = \"\" , ** context : str , ) -> JobSequence : sequence = JobSequence () diff_job = cdk . diff ( * stacks , synth_options = synth_options , diff_options = diff_options , ** context ) sequence . add_children ( diff_job , cdk . deploy ( * stacks , toolkit_stack_name = toolkit_stack_name , wait_for_stack = wait_for_stack , wait_for_stack_assume_role = wait_for_stack_assume_role , wait_for_stack_account_id = wait_for_stack_account_id , options = deploy_options , ** context , ) . add_needs ( diff_job ), ) return sequence Functions diff_deploy def diff_deploy ( * stacks : str , toolkit_stack_name : str , wait_for_stack : bool = True , wait_for_stack_assume_role : Optional [ str ] = None , wait_for_stack_account_id : Optional [ str ] = None , synth_options : str = '' , diff_options : str = '' , deploy_options : str = '' , ** context : str ) -> gcip . core . job_sequence . JobSequence View Source def diff_deploy ( * stacks : str , toolkit_stack_name : str , wait_for_stack : bool = True , wait_for_stack_assume_role : Optional [ str ] = None , wait_for_stack_account_id : Optional [ str ] = None , synth_options : str = \"\" , diff_options : str = \"\" , deploy_options : str = \"\" , ** context : str , ) -> JobSequence : sequence = JobSequence () diff_job = cdk . diff ( * stacks , synth_options = synth_options , diff_options = diff_options , ** context ) sequence . add_children ( diff_job , cdk . deploy ( * stacks , toolkit_stack_name = toolkit_stack_name , wait_for_stack = wait_for_stack , wait_for_stack_assume_role = wait_for_stack_assume_role , wait_for_stack_account_id = wait_for_stack_account_id , options = deploy_options , ** context , ). add_needs ( diff_job ), ) return sequence","title":"Sequences"},{"location":"reference/gcip/addons/cdk/sequences/#module-gcipaddonscdksequences","text":"None None View Source from typing import Optional from gcip.core.job_sequence import JobSequence from . import jobs as cdk __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def diff_deploy ( * stacks : str , toolkit_stack_name : str , wait_for_stack : bool = True , wait_for_stack_assume_role : Optional [ str ] = None , wait_for_stack_account_id : Optional [ str ] = None , synth_options : str = \"\" , diff_options : str = \"\" , deploy_options : str = \"\" , ** context : str , ) -> JobSequence : sequence = JobSequence () diff_job = cdk . diff ( * stacks , synth_options = synth_options , diff_options = diff_options , ** context ) sequence . add_children ( diff_job , cdk . deploy ( * stacks , toolkit_stack_name = toolkit_stack_name , wait_for_stack = wait_for_stack , wait_for_stack_assume_role = wait_for_stack_assume_role , wait_for_stack_account_id = wait_for_stack_account_id , options = deploy_options , ** context , ) . add_needs ( diff_job ), ) return sequence","title":"Module gcip.addons.cdk.sequences"},{"location":"reference/gcip/addons/cdk/sequences/#functions","text":"","title":"Functions"},{"location":"reference/gcip/addons/cdk/sequences/#diff_deploy","text":"def diff_deploy ( * stacks : str , toolkit_stack_name : str , wait_for_stack : bool = True , wait_for_stack_assume_role : Optional [ str ] = None , wait_for_stack_account_id : Optional [ str ] = None , synth_options : str = '' , diff_options : str = '' , deploy_options : str = '' , ** context : str ) -> gcip . core . job_sequence . JobSequence View Source def diff_deploy ( * stacks : str , toolkit_stack_name : str , wait_for_stack : bool = True , wait_for_stack_assume_role : Optional [ str ] = None , wait_for_stack_account_id : Optional [ str ] = None , synth_options : str = \"\" , diff_options : str = \"\" , deploy_options : str = \"\" , ** context : str , ) -> JobSequence : sequence = JobSequence () diff_job = cdk . diff ( * stacks , synth_options = synth_options , diff_options = diff_options , ** context ) sequence . add_children ( diff_job , cdk . deploy ( * stacks , toolkit_stack_name = toolkit_stack_name , wait_for_stack = wait_for_stack , wait_for_stack_assume_role = wait_for_stack_assume_role , wait_for_stack_account_id = wait_for_stack_account_id , options = deploy_options , ** context , ). add_needs ( diff_job ), ) return sequence","title":"diff_deploy"},{"location":"reference/gcip/addons/cdk/tools/","text":"Module gcip.addons.cdk.tools None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' Sub-modules gcip.addons.cdk.tools.wait_for_cloudformation_stack_ready","title":"Index"},{"location":"reference/gcip/addons/cdk/tools/#module-gcipaddonscdktools","text":"None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com'","title":"Module gcip.addons.cdk.tools"},{"location":"reference/gcip/addons/cdk/tools/#sub-modules","text":"gcip.addons.cdk.tools.wait_for_cloudformation_stack_ready","title":"Sub-modules"},{"location":"reference/gcip/addons/cdk/tools/wait_for_cloudformation_stack_ready/","text":"Module gcip.addons.cdk.tools.wait_for_cloudformation_stack_ready None None View Source import argparse from time import sleep import boto3 # type: ignore from botocore.config import Config # type: ignore __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' if __name__ == \"__main__\" : argparser = argparse . ArgumentParser () argparser . add_argument ( \"--stack-names\" , dest = \"stack_names\" , help = \"The names of the stacks to wait all CloudFormation operations are finished for, separated by blanks.\" , ) argparser . add_argument ( \"--wait-seconds\" , type = int , default = 30 , dest = \"wait_seconds\" , help = \"The number of seconds to wait before checking stack status again. Default=30\" , ) argparser . add_argument ( \"--assume-role\" , dest = \"assume_role\" , help = \"The IAM role to execute this script with.\" , ) argparser . add_argument ( \"--assume-role-account-id\" , dest = \"assume_role_account_id\" , help = \"The account Id the `--assume-role` resides in.\" , ) args = argparser . parse_args () config = Config ( retries = { 'max_attempts' : 15 , 'mode' : 'standard' }) if args . assume_role : assume_role_account_id = args . assume_role_account_id if not assume_role_account_id : assume_role_account_id = boto3 . client ( 'sts' ) . get_caller_identity () . get ( 'Account' ) sts_client = boto3 . client ( 'sts' ) assumed_role_object = sts_client . assume_role ( RoleArn = f \"arn:aws:iam::{assume_role_account_id}:role/{args.assume_role}\" , RoleSessionName = \"AssumeRoleSession1\" , ) credentials = assumed_role_object [ 'Credentials' ] session = boto3 . session . Session ( aws_access_key_id = credentials [ 'AccessKeyId' ], aws_secret_access_key = credentials [ 'SecretAccessKey' ], aws_session_token = credentials [ 'SessionToken' ], ) cfn = session . client ( 'cloudformation' , config = config ) else : cfn = boto3 . client ( 'cloudformation' , config = config ) # everything but DELETE_COMPLETE stack_status_filter = [ 'CREATE_IN_PROGRESS' , 'CREATE_FAILED' , 'CREATE_COMPLETE' , 'ROLLBACK_IN_PROGRESS' , 'ROLLBACK_FAILED' , 'ROLLBACK_COMPLETE' , 'DELETE_IN_PROGRESS' , 'DELETE_FAILED' , 'UPDATE_IN_PROGRESS' , 'UPDATE_COMPLETE_CLEANUP_IN_PROGRESS' , 'UPDATE_COMPLETE' , 'UPDATE_ROLLBACK_IN_PROGRESS' , 'UPDATE_ROLLBACK_FAILED' , 'UPDATE_ROLLBACK_COMPLETE_CLEANUP_IN_PROGRESS' , 'UPDATE_ROLLBACK_COMPLETE' , 'REVIEW_IN_PROGRESS' , 'IMPORT_IN_PROGRESS' , 'IMPORT_COMPLETE' , 'IMPORT_ROLLBACK_IN_PROGRESS' , 'IMPORT_ROLLBACK_FAILED' , 'IMPORT_ROLLBACK_COMPLETE' , ] stacks = [] for stack_id in args . stack_names . split ( \" \" ): if \"*\" in stack_id : stack_name = stack_id . replace ( \"*\" , \"\" ) for ppage in cfn . get_paginator ( \"list_stacks\" ) . paginate ( StackStatusFilter = stack_status_filter ): for stack in ppage . get ( \"StackSummaries\" ): if stack_name in stack [ \"StackName\" ]: stacks . append ( stack [ \"StackName\" ]) else : for ppage in cfn . get_paginator ( \"list_stacks\" ) . paginate ( StackStatusFilter = stack_status_filter ): for stack in ppage . get ( \"StackSummaries\" ): if stack_id == stack [ \"StackName\" ]: stacks . append ( stack_id ) print ( f \"waiting for stacks to complete: {stacks}\" ) def stack_in_progress () -> bool : for stack in stacks : sleep ( 0.5 ) # prevent API rate limiting when iterating through many stacks if \"IN_PROGRESS\" in cfn . describe_stacks ( StackName = stack )[ \"Stacks\" ][ 0 ][ \"StackStatus\" ]: return True return False while stack_in_progress (): print ( f \"One of the stacks {stacks} status is in progress. Waiting...\" , flush = True ) sleep ( args . wait_seconds )","title":"Wait For Cloudformation Stack Ready"},{"location":"reference/gcip/addons/cdk/tools/wait_for_cloudformation_stack_ready/#module-gcipaddonscdktoolswait_for_cloudformation_stack_ready","text":"None None View Source import argparse from time import sleep import boto3 # type: ignore from botocore.config import Config # type: ignore __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' if __name__ == \"__main__\" : argparser = argparse . ArgumentParser () argparser . add_argument ( \"--stack-names\" , dest = \"stack_names\" , help = \"The names of the stacks to wait all CloudFormation operations are finished for, separated by blanks.\" , ) argparser . add_argument ( \"--wait-seconds\" , type = int , default = 30 , dest = \"wait_seconds\" , help = \"The number of seconds to wait before checking stack status again. Default=30\" , ) argparser . add_argument ( \"--assume-role\" , dest = \"assume_role\" , help = \"The IAM role to execute this script with.\" , ) argparser . add_argument ( \"--assume-role-account-id\" , dest = \"assume_role_account_id\" , help = \"The account Id the `--assume-role` resides in.\" , ) args = argparser . parse_args () config = Config ( retries = { 'max_attempts' : 15 , 'mode' : 'standard' }) if args . assume_role : assume_role_account_id = args . assume_role_account_id if not assume_role_account_id : assume_role_account_id = boto3 . client ( 'sts' ) . get_caller_identity () . get ( 'Account' ) sts_client = boto3 . client ( 'sts' ) assumed_role_object = sts_client . assume_role ( RoleArn = f \"arn:aws:iam::{assume_role_account_id}:role/{args.assume_role}\" , RoleSessionName = \"AssumeRoleSession1\" , ) credentials = assumed_role_object [ 'Credentials' ] session = boto3 . session . Session ( aws_access_key_id = credentials [ 'AccessKeyId' ], aws_secret_access_key = credentials [ 'SecretAccessKey' ], aws_session_token = credentials [ 'SessionToken' ], ) cfn = session . client ( 'cloudformation' , config = config ) else : cfn = boto3 . client ( 'cloudformation' , config = config ) # everything but DELETE_COMPLETE stack_status_filter = [ 'CREATE_IN_PROGRESS' , 'CREATE_FAILED' , 'CREATE_COMPLETE' , 'ROLLBACK_IN_PROGRESS' , 'ROLLBACK_FAILED' , 'ROLLBACK_COMPLETE' , 'DELETE_IN_PROGRESS' , 'DELETE_FAILED' , 'UPDATE_IN_PROGRESS' , 'UPDATE_COMPLETE_CLEANUP_IN_PROGRESS' , 'UPDATE_COMPLETE' , 'UPDATE_ROLLBACK_IN_PROGRESS' , 'UPDATE_ROLLBACK_FAILED' , 'UPDATE_ROLLBACK_COMPLETE_CLEANUP_IN_PROGRESS' , 'UPDATE_ROLLBACK_COMPLETE' , 'REVIEW_IN_PROGRESS' , 'IMPORT_IN_PROGRESS' , 'IMPORT_COMPLETE' , 'IMPORT_ROLLBACK_IN_PROGRESS' , 'IMPORT_ROLLBACK_FAILED' , 'IMPORT_ROLLBACK_COMPLETE' , ] stacks = [] for stack_id in args . stack_names . split ( \" \" ): if \"*\" in stack_id : stack_name = stack_id . replace ( \"*\" , \"\" ) for ppage in cfn . get_paginator ( \"list_stacks\" ) . paginate ( StackStatusFilter = stack_status_filter ): for stack in ppage . get ( \"StackSummaries\" ): if stack_name in stack [ \"StackName\" ]: stacks . append ( stack [ \"StackName\" ]) else : for ppage in cfn . get_paginator ( \"list_stacks\" ) . paginate ( StackStatusFilter = stack_status_filter ): for stack in ppage . get ( \"StackSummaries\" ): if stack_id == stack [ \"StackName\" ]: stacks . append ( stack_id ) print ( f \"waiting for stacks to complete: {stacks}\" ) def stack_in_progress () -> bool : for stack in stacks : sleep ( 0.5 ) # prevent API rate limiting when iterating through many stacks if \"IN_PROGRESS\" in cfn . describe_stacks ( StackName = stack )[ \"Stacks\" ][ 0 ][ \"StackStatus\" ]: return True return False while stack_in_progress (): print ( f \"One of the stacks {stacks} status is in progress. Waiting...\" , flush = True ) sleep ( args . wait_seconds )","title":"Module gcip.addons.cdk.tools.wait_for_cloudformation_stack_ready"},{"location":"reference/gcip/addons/gitlab/","text":"Module gcip.addons.gitlab None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' Sub-modules gcip.addons.gitlab.job_scripts","title":"Index"},{"location":"reference/gcip/addons/gitlab/#module-gcipaddonsgitlab","text":"None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com'","title":"Module gcip.addons.gitlab"},{"location":"reference/gcip/addons/gitlab/#sub-modules","text":"gcip.addons.gitlab.job_scripts","title":"Sub-modules"},{"location":"reference/gcip/addons/gitlab/job_scripts/","text":"Module gcip.addons.gitlab.job_scripts None None View Source from typing import Any __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def clone_repository ( path : str , * args : Any , branch : str = \"main\" ) -> str : if not path . startswith ( \"/\" ): path = \"/\" + path return f \"git clone --branch {branch} --single-branch https://gitlab-ci-token:${{CI_JOB_TOKEN}}@${{CI_SERVER_HOST}}{path}.git\" Functions clone_repository def clone_repository ( path : str , * args : Any , branch : str = 'main' ) -> str View Source def clone_repository(path: str, *args: Any, branch: str = \"main\") -> str: if not path.startswith(\"/\"): path = \"/\" + path return f\"git clone --branch {branch} --single-branch https://gitlab-ci-token: ${ { CI_JOB_TOKEN } }@ ${ { CI_SERVER_HOST } }{path}.git\"","title":"Job Scripts"},{"location":"reference/gcip/addons/gitlab/job_scripts/#module-gcipaddonsgitlabjob_scripts","text":"None None View Source from typing import Any __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def clone_repository ( path : str , * args : Any , branch : str = \"main\" ) -> str : if not path . startswith ( \"/\" ): path = \"/\" + path return f \"git clone --branch {branch} --single-branch https://gitlab-ci-token:${{CI_JOB_TOKEN}}@${{CI_SERVER_HOST}}{path}.git\"","title":"Module gcip.addons.gitlab.job_scripts"},{"location":"reference/gcip/addons/gitlab/job_scripts/#functions","text":"","title":"Functions"},{"location":"reference/gcip/addons/gitlab/job_scripts/#clone_repository","text":"def clone_repository ( path : str , * args : Any , branch : str = 'main' ) -> str View Source def clone_repository(path: str, *args: Any, branch: str = \"main\") -> str: if not path.startswith(\"/\"): path = \"/\" + path return f\"git clone --branch {branch} --single-branch https://gitlab-ci-token: ${ { CI_JOB_TOKEN } }@ ${ { CI_SERVER_HOST } }{path}.git\"","title":"clone_repository"},{"location":"reference/gcip/addons/python/","text":"Module gcip.addons.python None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' Sub-modules gcip.addons.python.job_scripts gcip.addons.python.jobs gcip.addons.python.sequences","title":"Index"},{"location":"reference/gcip/addons/python/#module-gcipaddonspython","text":"None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com'","title":"Module gcip.addons.python"},{"location":"reference/gcip/addons/python/#sub-modules","text":"gcip.addons.python.job_scripts gcip.addons.python.jobs gcip.addons.python.sequences","title":"Sub-modules"},{"location":"reference/gcip/addons/python/job_scripts/","text":"Module gcip.addons.python.job_scripts None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def pip_install_requirements ( requirements_file : str = \"requirements.txt\" ) -> str : \"\"\" Runs `pip3 install --upgrade -v -r {requirements_file}` * Requires to have access to the `{requirements_file}` in the working directory. :arg requirements_file: Defaults to `requirements.txt` \"\"\" return f \"pip3 install --upgrade -v -r {requirements_file}\" Functions pip_install_requirements def pip_install_requirements ( requirements_file : str = 'requirements.txt' ) -> str Runs pip3 install --upgrade -v -r {requirements_file} Requires to have access to the {requirements_file} in the working directory. Parameters: Name Type Description Default requirements_file None Defaults to requirements.txt None View Source def pip_install_requirements ( requirements_file : str = \"requirements.txt\" ) -> str : \"\"\" Runs `pip3 install --upgrade -v -r {requirements_file}` * Requires to have access to the `{requirements_file}` in the working directory. :arg requirements_file: Defaults to `requirements.txt` \"\"\" return f \"pip3 install --upgrade -v -r {requirements_file}\"","title":"Job Scripts"},{"location":"reference/gcip/addons/python/job_scripts/#module-gcipaddonspythonjob_scripts","text":"None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def pip_install_requirements ( requirements_file : str = \"requirements.txt\" ) -> str : \"\"\" Runs `pip3 install --upgrade -v -r {requirements_file}` * Requires to have access to the `{requirements_file}` in the working directory. :arg requirements_file: Defaults to `requirements.txt` \"\"\" return f \"pip3 install --upgrade -v -r {requirements_file}\"","title":"Module gcip.addons.python.job_scripts"},{"location":"reference/gcip/addons/python/job_scripts/#functions","text":"","title":"Functions"},{"location":"reference/gcip/addons/python/job_scripts/#pip_install_requirements","text":"def pip_install_requirements ( requirements_file : str = 'requirements.txt' ) -> str Runs pip3 install --upgrade -v -r {requirements_file} Requires to have access to the {requirements_file} in the working directory. Parameters: Name Type Description Default requirements_file None Defaults to requirements.txt None View Source def pip_install_requirements ( requirements_file : str = \"requirements.txt\" ) -> str : \"\"\" Runs `pip3 install --upgrade -v -r {requirements_file}` * Requires to have access to the `{requirements_file}` in the working directory. :arg requirements_file: Defaults to `requirements.txt` \"\"\" return f \"pip3 install --upgrade -v -r {requirements_file}\"","title":"pip_install_requirements"},{"location":"reference/gcip/addons/python/jobs/","text":"Module gcip.addons.python.jobs None None View Source from gcip.lib import rules from gcip.core.job import Job from . import job_scripts as scripts __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def flake8 () -> Job : \"\"\" Runs: ``` pip3 install --upgrade flake8 flake8 ``` \"\"\" return Job ( name = \"flake8\" , namespace = \"lint\" , script = [ \"pip3 install --upgrade flake8\" , \"flake8\" , ], ) def mypy ( package_dir : str ) -> Job : \"\"\"Runs: ```python pip3 install --upgrade mypy mypy package_dir ``` Args: package_dir (str): Relativ path to package which should be checked with mypy. Returns: Job: Job running mypy. \"\"\" return Job ( name = \"mypy\" , namespace = \"test\" , script = [ \"pip3 install --upgrade mypy\" , f \"mypy {package_dir}\" ], ) def isort () -> Job : \"\"\" Runs: ``` pip3 install --upgrade isort isort --check . ``` \"\"\" return Job ( name = \"isort\" , namespace = \"lint\" , script = [ \"pip3 install --upgrade isort\" , \"isort --check .\" , ], ) def pytest () -> Job : \"\"\" Runs `pytest` and installs project requirements before (`scripts.pip_install_requirements()`) * Requires a `requirements.txt` in your project folder containing at least `pytest` \"\"\" return Job ( name = \"pytest\" , namespace = \"test\" , script = [ scripts . pip_install_requirements (), \"pytest\" , ], ) def evaluate_git_tag_pep404_conformity () -> Job : \"\"\" Checks if the current pipelines `$CI_COMMIT_TAG` validates to a valid Python package version according to https://www.python.org/dev/peps/pep-0440 This job already contains a rule to only run when a `$CI_COMMIT_TAG` is present (`rules.only_tags()`). \"\"\" job = Job ( name = \"evaluate_git_tag_pep404_conformity\" , namespace = \"test\" , script = [ \"pip3 install --upgrade gcip\" , \"python3 -m gcip.tools.evaluate_git_tag_pep404_conformity\" , ], ) job . append_rules ( rules . on_tags ()) return job def bdist_wheel () -> Job : \"\"\" Runs `python3 setup.py bdist_wheel` and installs project requirements before (`scripts.pip_install_requirements()`) * Requires a `requirements.txt` in your project folder containing at least `setuptools` * Creates artifacts under the path `dist/` \"\"\" job = Job ( name = \"bdist_wheel\" , namespace = \"build\" , script = [ scripts . pip_install_requirements (), \"python3 setup.py bdist_wheel\" , ], ) job . add_artifacts_paths ( \"dist/\" ) return job def pages_sphinx () -> Job : \"\"\" Runs `sphinx-build -b html -E -a docs public/${CI_COMMIT_REF_NAME}` and installs project requirements before (`scripts.pip_install_requirements()`) * Requires a `docs/requirements.txt` in your project folder` containing at least `sphinx` * Creates it artifacts for Gitlab Pages under `pages` \"\"\" job = Job ( name = \"pages_python_sphinx\" , namespace = \"build\" , script = [ scripts . pip_install_requirements ( \"docs/requirements.txt\" ), \"sphinx-build -b html -E -a docs public/${CI_COMMIT_REF_NAME}\" , ], ) job . add_artifacts_paths ( \"public\" ) return job def twine_upload ( repository_url : str , user : str , varname_password : str , ) -> Job : \"\"\" Runs: ``` pip3 install --upgrade twine python3 -m twine upload --non-interactive --disable-progress-bar dist/* ``` * Requires artifacts from a build job under `dist/` (e.g. from `bdist_wheel()`) :arg repository_url: The URL to the PyPI repository the python artifacts will be deployed to. :arg user: The name of the user to access the PyPI repository. :arg varname_password: The name of the environment variable delivering the password to access the PyPI repository. If not existent, automatically a \"$\" will be prepended to the string. DO NOT DEFINE THE PASSWORD WITHIN THE PIPELINE. Define your password outside the pipeline, e.g. as secret variable in the Gitlab CI/CD settings section. \"\"\" if not varname_password . startswith ( \"$\" ): varname_password = \"$\" + varname_password job = Job ( name = \"twine_upload\" , namespace = \"deploy\" , script = [ \"pip3 install --upgrade twine\" , \"python3 -m twine upload --non-interactive --disable-progress-bar dist/*\" , ], ) job . add_variables ( TWINE_REPOSITORY_URL = repository_url , TWINE_USERNAME = user , TWINE_PASSWORD = varname_password , ) return job Functions bdist_wheel def bdist_wheel ( ) -> gcip . core . job . Job Runs python3 setup.py bdist_wheel and installs project requirements before ( scripts.pip_install_requirements() ) Requires a requirements.txt in your project folder containing at least setuptools Creates artifacts under the path dist/ View Source def bdist_wheel () -> Job : \" \"\" Runs `python3 setup.py bdist_wheel` and installs project requirements before (`scripts.pip_install_requirements()`) * Requires a `requirements.txt` in your project folder containing at least `setuptools` * Creates artifacts under the path `dist/` \"\" \" job = Job ( name = \"bdist_wheel\" , namespace = \"build\" , script = [ scripts . pip_install_requirements (), \"python3 setup.py bdist_wheel\" , ] , ) job . add_artifacts_paths ( \"dist/\" ) return job evaluate_git_tag_pep404_conformity def evaluate_git_tag_pep404_conformity ( ) -> gcip . core . job . Job Checks if the current pipelines $CI_COMMIT_TAG validates to a valid Python package version according to https://www.python.org/dev/peps/pep-0440 This job already contains a rule to only run when a $CI_COMMIT_TAG is present ( rules.only_tags() ). View Source def evaluate_git_tag_pep404_conformity () -> Job : \"\"\" Checks if the current pipelines `$CI_COMMIT_TAG` validates to a valid Python package version according to https://www.python.org/dev/peps/pep-0440 This job already contains a rule to only run when a `$CI_COMMIT_TAG` is present (`rules.only_tags()`). \"\"\" job = Job ( name = \"evaluate_git_tag_pep404_conformity\" , namespace = \"test\" , script = [ \"pip3 install --upgrade gcip\" , \"python3 -m gcip.tools.evaluate_git_tag_pep404_conformity\" , ], ) job . append_rules ( rules . on_tags ()) return job flake8 def flake8 ( ) -> gcip . core . job . Job Runs: pip3 install --upgrade flake8 flake8 View Source def flake8 () -> Job : \"\"\" Runs: ``` pip3 install --upgrade flake8 flake8 ``` \"\"\" return Job ( name = \"flake8\" , namespace = \"lint\" , script = [ \"pip3 install --upgrade flake8\" , \"flake8\" , ], ) isort def isort ( ) -> gcip . core . job . Job Runs: pip3 install --upgrade isort isort --check . View Source def isort () -> Job : \"\"\" Runs: ``` pip3 install --upgrade isort isort --check . ``` \"\"\" return Job ( name = \"isort\" , namespace = \"lint\" , script = [ \"pip3 install --upgrade isort\" , \"isort --check .\" , ], ) mypy def mypy ( package_dir : str ) -> gcip . core . job . Job Runs: pip3 install -- upgrade mypy mypy package_dir Parameters: Name Type Description Default package_dir str Relativ path to package which should be checked with mypy. None Returns: Type Description Job Job running mypy. View Source def mypy ( package_dir : str ) -> Job : \"\"\"Runs: ```python pip3 install --upgrade mypy mypy package_dir ``` Args: package_dir (str): Relativ path to package which should be checked with mypy. Returns: Job: Job running mypy. \"\"\" return Job ( name = \"mypy\" , namespace = \"test\" , script = [ \"pip3 install --upgrade mypy\" , f \"mypy {package_dir}\" ], ) pages_sphinx def pages_sphinx ( ) -> gcip . core . job . Job Runs sphinx-build -b html -E -a docs public/${CI_COMMIT_REF_NAME} and installs project requirements before ( scripts.pip_install_requirements() ) Requires a docs/requirements.txt in your project folder containing at least sphinx` Creates it artifacts for Gitlab Pages under pages View Source def pages_sphinx () -> Job : \" \"\" Runs `sphinx-build -b html -E -a docs public/${CI_COMMIT_REF_NAME}` and installs project requirements before (`scripts.pip_install_requirements()`) * Requires a `docs/requirements.txt` in your project folder` containing at least `sphinx` * Creates it artifacts for Gitlab Pages under `pages` \"\" \" job = Job ( name = \"pages_python_sphinx\" , namespace = \"build\" , script = [ scripts . pip_install_requirements ( \"docs/requirements.txt\" ), \"sphinx-build -b html -E -a docs public/${CI_COMMIT_REF_NAME}\" , ] , ) job . add_artifacts_paths ( \"public\" ) return job pytest def pytest ( ) -> gcip . core . job . Job Runs pytest and installs project requirements before ( scripts.pip_install_requirements() ) Requires a requirements.txt in your project folder containing at least pytest View Source def pytest () -> Job : \" \"\" Runs `pytest` and installs project requirements before (`scripts.pip_install_requirements()`) * Requires a `requirements.txt` in your project folder containing at least `pytest` \"\" \" return Job ( name = \"pytest\" , namespace = \"test\" , script = [ scripts . pip_install_requirements (), \"pytest\" , ] , ) twine_upload def twine_upload ( repository_url : str , user : str , varname_password : str ) -> gcip . core . job . Job Runs: pip3 install -- upgrade twine python3 - m twine upload -- non - interactive -- disable - progress - bar dist /* Requires artifacts from a build job under dist/ (e.g. from bdist_wheel() ) Parameters: Name Type Description Default repository_url None The URL to the PyPI repository the python artifacts will be deployed to. None user None The name of the user to access the PyPI repository. None varname_password None The name of the environment variable delivering the password to access the PyPI repository. If not existent, automatically a \"$\" will be prepended to the string. DO NOT DEFINE THE PASSWORD WITHIN THE PIPELINE. Define your password outside the pipeline, e.g. as secret variable in the Gitlab CI/CD settings section. None View Source def twine_upload ( repository_url : str , user : str , varname_password : str , ) -> Job : \"\"\" Runs: ``` pip3 install --upgrade twine python3 -m twine upload --non-interactive --disable-progress-bar dist/* ``` * Requires artifacts from a build job under `dist/` (e.g. from `bdist_wheel()`) :arg repository_url: The URL to the PyPI repository the python artifacts will be deployed to. :arg user: The name of the user to access the PyPI repository. :arg varname_password: The name of the environment variable delivering the password to access the PyPI repository. If not existent, automatically a \"$\" will be prepended to the string. DO NOT DEFINE THE PASSWORD WITHIN THE PIPELINE. Define your password outside the pipeline, e.g. as secret variable in the Gitlab CI/CD settings section. \"\"\" if not varname_password . startswith ( \"$\" ): varname_password = \"$\" + varname_password job = Job ( name = \"twine_upload\" , namespace = \"deploy\" , script = [ \"pip3 install --upgrade twine\" , \"python3 -m twine upload --non-interactive --disable-progress-bar dist/*\" , ], ) job . add_variables ( TWINE_REPOSITORY_URL = repository_url , TWINE_USERNAME = user , TWINE_PASSWORD = varname_password , ) return job","title":"Jobs"},{"location":"reference/gcip/addons/python/jobs/#module-gcipaddonspythonjobs","text":"None None View Source from gcip.lib import rules from gcip.core.job import Job from . import job_scripts as scripts __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def flake8 () -> Job : \"\"\" Runs: ``` pip3 install --upgrade flake8 flake8 ``` \"\"\" return Job ( name = \"flake8\" , namespace = \"lint\" , script = [ \"pip3 install --upgrade flake8\" , \"flake8\" , ], ) def mypy ( package_dir : str ) -> Job : \"\"\"Runs: ```python pip3 install --upgrade mypy mypy package_dir ``` Args: package_dir (str): Relativ path to package which should be checked with mypy. Returns: Job: Job running mypy. \"\"\" return Job ( name = \"mypy\" , namespace = \"test\" , script = [ \"pip3 install --upgrade mypy\" , f \"mypy {package_dir}\" ], ) def isort () -> Job : \"\"\" Runs: ``` pip3 install --upgrade isort isort --check . ``` \"\"\" return Job ( name = \"isort\" , namespace = \"lint\" , script = [ \"pip3 install --upgrade isort\" , \"isort --check .\" , ], ) def pytest () -> Job : \"\"\" Runs `pytest` and installs project requirements before (`scripts.pip_install_requirements()`) * Requires a `requirements.txt` in your project folder containing at least `pytest` \"\"\" return Job ( name = \"pytest\" , namespace = \"test\" , script = [ scripts . pip_install_requirements (), \"pytest\" , ], ) def evaluate_git_tag_pep404_conformity () -> Job : \"\"\" Checks if the current pipelines `$CI_COMMIT_TAG` validates to a valid Python package version according to https://www.python.org/dev/peps/pep-0440 This job already contains a rule to only run when a `$CI_COMMIT_TAG` is present (`rules.only_tags()`). \"\"\" job = Job ( name = \"evaluate_git_tag_pep404_conformity\" , namespace = \"test\" , script = [ \"pip3 install --upgrade gcip\" , \"python3 -m gcip.tools.evaluate_git_tag_pep404_conformity\" , ], ) job . append_rules ( rules . on_tags ()) return job def bdist_wheel () -> Job : \"\"\" Runs `python3 setup.py bdist_wheel` and installs project requirements before (`scripts.pip_install_requirements()`) * Requires a `requirements.txt` in your project folder containing at least `setuptools` * Creates artifacts under the path `dist/` \"\"\" job = Job ( name = \"bdist_wheel\" , namespace = \"build\" , script = [ scripts . pip_install_requirements (), \"python3 setup.py bdist_wheel\" , ], ) job . add_artifacts_paths ( \"dist/\" ) return job def pages_sphinx () -> Job : \"\"\" Runs `sphinx-build -b html -E -a docs public/${CI_COMMIT_REF_NAME}` and installs project requirements before (`scripts.pip_install_requirements()`) * Requires a `docs/requirements.txt` in your project folder` containing at least `sphinx` * Creates it artifacts for Gitlab Pages under `pages` \"\"\" job = Job ( name = \"pages_python_sphinx\" , namespace = \"build\" , script = [ scripts . pip_install_requirements ( \"docs/requirements.txt\" ), \"sphinx-build -b html -E -a docs public/${CI_COMMIT_REF_NAME}\" , ], ) job . add_artifacts_paths ( \"public\" ) return job def twine_upload ( repository_url : str , user : str , varname_password : str , ) -> Job : \"\"\" Runs: ``` pip3 install --upgrade twine python3 -m twine upload --non-interactive --disable-progress-bar dist/* ``` * Requires artifacts from a build job under `dist/` (e.g. from `bdist_wheel()`) :arg repository_url: The URL to the PyPI repository the python artifacts will be deployed to. :arg user: The name of the user to access the PyPI repository. :arg varname_password: The name of the environment variable delivering the password to access the PyPI repository. If not existent, automatically a \"$\" will be prepended to the string. DO NOT DEFINE THE PASSWORD WITHIN THE PIPELINE. Define your password outside the pipeline, e.g. as secret variable in the Gitlab CI/CD settings section. \"\"\" if not varname_password . startswith ( \"$\" ): varname_password = \"$\" + varname_password job = Job ( name = \"twine_upload\" , namespace = \"deploy\" , script = [ \"pip3 install --upgrade twine\" , \"python3 -m twine upload --non-interactive --disable-progress-bar dist/*\" , ], ) job . add_variables ( TWINE_REPOSITORY_URL = repository_url , TWINE_USERNAME = user , TWINE_PASSWORD = varname_password , ) return job","title":"Module gcip.addons.python.jobs"},{"location":"reference/gcip/addons/python/jobs/#functions","text":"","title":"Functions"},{"location":"reference/gcip/addons/python/jobs/#bdist_wheel","text":"def bdist_wheel ( ) -> gcip . core . job . Job Runs python3 setup.py bdist_wheel and installs project requirements before ( scripts.pip_install_requirements() ) Requires a requirements.txt in your project folder containing at least setuptools Creates artifacts under the path dist/ View Source def bdist_wheel () -> Job : \" \"\" Runs `python3 setup.py bdist_wheel` and installs project requirements before (`scripts.pip_install_requirements()`) * Requires a `requirements.txt` in your project folder containing at least `setuptools` * Creates artifacts under the path `dist/` \"\" \" job = Job ( name = \"bdist_wheel\" , namespace = \"build\" , script = [ scripts . pip_install_requirements (), \"python3 setup.py bdist_wheel\" , ] , ) job . add_artifacts_paths ( \"dist/\" ) return job","title":"bdist_wheel"},{"location":"reference/gcip/addons/python/jobs/#evaluate_git_tag_pep404_conformity","text":"def evaluate_git_tag_pep404_conformity ( ) -> gcip . core . job . Job Checks if the current pipelines $CI_COMMIT_TAG validates to a valid Python package version according to https://www.python.org/dev/peps/pep-0440 This job already contains a rule to only run when a $CI_COMMIT_TAG is present ( rules.only_tags() ). View Source def evaluate_git_tag_pep404_conformity () -> Job : \"\"\" Checks if the current pipelines `$CI_COMMIT_TAG` validates to a valid Python package version according to https://www.python.org/dev/peps/pep-0440 This job already contains a rule to only run when a `$CI_COMMIT_TAG` is present (`rules.only_tags()`). \"\"\" job = Job ( name = \"evaluate_git_tag_pep404_conformity\" , namespace = \"test\" , script = [ \"pip3 install --upgrade gcip\" , \"python3 -m gcip.tools.evaluate_git_tag_pep404_conformity\" , ], ) job . append_rules ( rules . on_tags ()) return job","title":"evaluate_git_tag_pep404_conformity"},{"location":"reference/gcip/addons/python/jobs/#flake8","text":"def flake8 ( ) -> gcip . core . job . Job Runs: pip3 install --upgrade flake8 flake8 View Source def flake8 () -> Job : \"\"\" Runs: ``` pip3 install --upgrade flake8 flake8 ``` \"\"\" return Job ( name = \"flake8\" , namespace = \"lint\" , script = [ \"pip3 install --upgrade flake8\" , \"flake8\" , ], )","title":"flake8"},{"location":"reference/gcip/addons/python/jobs/#isort","text":"def isort ( ) -> gcip . core . job . Job Runs: pip3 install --upgrade isort isort --check . View Source def isort () -> Job : \"\"\" Runs: ``` pip3 install --upgrade isort isort --check . ``` \"\"\" return Job ( name = \"isort\" , namespace = \"lint\" , script = [ \"pip3 install --upgrade isort\" , \"isort --check .\" , ], )","title":"isort"},{"location":"reference/gcip/addons/python/jobs/#mypy","text":"def mypy ( package_dir : str ) -> gcip . core . job . Job Runs: pip3 install -- upgrade mypy mypy package_dir Parameters: Name Type Description Default package_dir str Relativ path to package which should be checked with mypy. None Returns: Type Description Job Job running mypy. View Source def mypy ( package_dir : str ) -> Job : \"\"\"Runs: ```python pip3 install --upgrade mypy mypy package_dir ``` Args: package_dir (str): Relativ path to package which should be checked with mypy. Returns: Job: Job running mypy. \"\"\" return Job ( name = \"mypy\" , namespace = \"test\" , script = [ \"pip3 install --upgrade mypy\" , f \"mypy {package_dir}\" ], )","title":"mypy"},{"location":"reference/gcip/addons/python/jobs/#pages_sphinx","text":"def pages_sphinx ( ) -> gcip . core . job . Job Runs sphinx-build -b html -E -a docs public/${CI_COMMIT_REF_NAME} and installs project requirements before ( scripts.pip_install_requirements() ) Requires a docs/requirements.txt in your project folder containing at least sphinx` Creates it artifacts for Gitlab Pages under pages View Source def pages_sphinx () -> Job : \" \"\" Runs `sphinx-build -b html -E -a docs public/${CI_COMMIT_REF_NAME}` and installs project requirements before (`scripts.pip_install_requirements()`) * Requires a `docs/requirements.txt` in your project folder` containing at least `sphinx` * Creates it artifacts for Gitlab Pages under `pages` \"\" \" job = Job ( name = \"pages_python_sphinx\" , namespace = \"build\" , script = [ scripts . pip_install_requirements ( \"docs/requirements.txt\" ), \"sphinx-build -b html -E -a docs public/${CI_COMMIT_REF_NAME}\" , ] , ) job . add_artifacts_paths ( \"public\" ) return job","title":"pages_sphinx"},{"location":"reference/gcip/addons/python/jobs/#pytest","text":"def pytest ( ) -> gcip . core . job . Job Runs pytest and installs project requirements before ( scripts.pip_install_requirements() ) Requires a requirements.txt in your project folder containing at least pytest View Source def pytest () -> Job : \" \"\" Runs `pytest` and installs project requirements before (`scripts.pip_install_requirements()`) * Requires a `requirements.txt` in your project folder containing at least `pytest` \"\" \" return Job ( name = \"pytest\" , namespace = \"test\" , script = [ scripts . pip_install_requirements (), \"pytest\" , ] , )","title":"pytest"},{"location":"reference/gcip/addons/python/jobs/#twine_upload","text":"def twine_upload ( repository_url : str , user : str , varname_password : str ) -> gcip . core . job . Job Runs: pip3 install -- upgrade twine python3 - m twine upload -- non - interactive -- disable - progress - bar dist /* Requires artifacts from a build job under dist/ (e.g. from bdist_wheel() ) Parameters: Name Type Description Default repository_url None The URL to the PyPI repository the python artifacts will be deployed to. None user None The name of the user to access the PyPI repository. None varname_password None The name of the environment variable delivering the password to access the PyPI repository. If not existent, automatically a \"$\" will be prepended to the string. DO NOT DEFINE THE PASSWORD WITHIN THE PIPELINE. Define your password outside the pipeline, e.g. as secret variable in the Gitlab CI/CD settings section. None View Source def twine_upload ( repository_url : str , user : str , varname_password : str , ) -> Job : \"\"\" Runs: ``` pip3 install --upgrade twine python3 -m twine upload --non-interactive --disable-progress-bar dist/* ``` * Requires artifacts from a build job under `dist/` (e.g. from `bdist_wheel()`) :arg repository_url: The URL to the PyPI repository the python artifacts will be deployed to. :arg user: The name of the user to access the PyPI repository. :arg varname_password: The name of the environment variable delivering the password to access the PyPI repository. If not existent, automatically a \"$\" will be prepended to the string. DO NOT DEFINE THE PASSWORD WITHIN THE PIPELINE. Define your password outside the pipeline, e.g. as secret variable in the Gitlab CI/CD settings section. \"\"\" if not varname_password . startswith ( \"$\" ): varname_password = \"$\" + varname_password job = Job ( name = \"twine_upload\" , namespace = \"deploy\" , script = [ \"pip3 install --upgrade twine\" , \"python3 -m twine upload --non-interactive --disable-progress-bar dist/*\" , ], ) job . add_variables ( TWINE_REPOSITORY_URL = repository_url , TWINE_USERNAME = user , TWINE_PASSWORD = varname_password , ) return job","title":"twine_upload"},{"location":"reference/gcip/addons/python/sequences/","text":"Module gcip.addons.python.sequences None None View Source from typing import Optional from gcip.lib import rules from gcip.core.job_sequence import JobSequence from . import jobs as python __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def full_stack ( dev_repository_url : str , dev_user : str , varname_dev_password : str , stable_repository_url : str , stable_user : str , varname_stable_password : str , mypy_package_dir : Optional [ str ] = None , ) -> JobSequence : \"\"\" Returns a pipeline containing all jobs from `gcip.addons.python.jobs`: * isort * flake8 * pytest * evaluating CI_COMMIT_TAG as valid PyPI version string (if exists) * bdist_wheel * Gitlab Pages sphinx * twine upload :arg repository_url: The URL to the PyPI repository the python artifacts will be deployed to. :arg user: The name of the user to access the PyPI repository. :arg varname_password: The name of the environment variable delivering the password to access the PyPI repository. If not existent, automatically a \"$\" will be prepended to the string. DO NOT DEFINE THE PASSWORD WITHIN THE PIPELINE. Define your password outside the pipeline, e.g. as secret variable in the Gitlab CI/CD settings section. \"\"\" sequence = JobSequence () sequence . add_children ( python . isort (), python . flake8 (), python . pytest (), python . evaluate_git_tag_pep404_conformity (), python . bdist_wheel (), ) if mypy_package_dir : sequence . add_children ( python . mypy ( mypy_package_dir )) pages_sphinx = python . pages_sphinx () pages_sphinx . append_rules ( rules . on_main (), rules . on_master (), rules . on_tags (), ) sequence . add_children ( pages_sphinx ) twine_upload_dev = python . twine_upload ( dev_repository_url , dev_user , varname_dev_password ) twine_upload_dev . append_rules ( rules . on_tags () . never (), rules . on_success (), ) sequence . add_children ( twine_upload_dev , name = \"dev\" ) twine_upload_stable = python . twine_upload ( stable_repository_url , stable_user , varname_stable_password ) twine_upload_stable . append_rules ( rules . on_tags ()) sequence . add_children ( twine_upload_stable , name = \"stable\" ) return sequence Functions full_stack def full_stack ( dev_repository_url : str , dev_user : str , varname_dev_password : str , stable_repository_url : str , stable_user : str , varname_stable_password : str , mypy_package_dir : Optional [ str ] = None ) -> gcip . core . job_sequence . JobSequence Returns a pipeline containing all jobs from gcip.addons.python.jobs : isort flake8 pytest evaluating CI_COMMIT_TAG as valid PyPI version string (if exists) bdist_wheel Gitlab Pages sphinx twine upload Parameters: Name Type Description Default repository_url None The URL to the PyPI repository the python artifacts will be deployed to. None user None The name of the user to access the PyPI repository. None varname_password None The name of the environment variable delivering the password to access the PyPI repository. If not existent, automatically a \"$\" will be prepended to the string. DO NOT DEFINE THE PASSWORD WITHIN THE PIPELINE. Define your password outside the pipeline, e.g. as secret variable in the Gitlab CI/CD settings section. None View Source def full_stack ( dev_repository_url : str , dev_user : str , varname_dev_password : str , stable_repository_url : str , stable_user : str , varname_stable_password : str , mypy_package_dir : Optional [ str ] = None , ) -> JobSequence : \"\"\" Returns a pipeline containing all jobs from `gcip.addons.python.jobs`: * isort * flake8 * pytest * evaluating CI_COMMIT_TAG as valid PyPI version string (if exists) * bdist_wheel * Gitlab Pages sphinx * twine upload :arg repository_url: The URL to the PyPI repository the python artifacts will be deployed to. :arg user: The name of the user to access the PyPI repository. :arg varname_password: The name of the environment variable delivering the password to access the PyPI repository. If not existent, automatically a \"$\" will be prepended to the string. DO NOT DEFINE THE PASSWORD WITHIN THE PIPELINE. Define your password outside the pipeline, e.g. as secret variable in the Gitlab CI/CD settings section. \"\"\" sequence = JobSequence () sequence . add_children ( python . isort (), python . flake8 (), python . pytest (), python . evaluate_git_tag_pep404_conformity (), python . bdist_wheel (), ) if mypy_package_dir : sequence . add_children ( python . mypy ( mypy_package_dir )) pages_sphinx = python . pages_sphinx () pages_sphinx . append_rules ( rules . on_main (), rules . on_master (), rules . on_tags (), ) sequence . add_children ( pages_sphinx ) twine_upload_dev = python . twine_upload ( dev_repository_url , dev_user , varname_dev_password ) twine_upload_dev . append_rules ( rules . on_tags () . never (), rules . on_success (), ) sequence . add_children ( twine_upload_dev , name = \"dev\" ) twine_upload_stable = python . twine_upload ( stable_repository_url , stable_user , varname_stable_password ) twine_upload_stable . append_rules ( rules . on_tags ()) sequence . add_children ( twine_upload_stable , name = \"stable\" ) return sequence","title":"Sequences"},{"location":"reference/gcip/addons/python/sequences/#module-gcipaddonspythonsequences","text":"None None View Source from typing import Optional from gcip.lib import rules from gcip.core.job_sequence import JobSequence from . import jobs as python __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def full_stack ( dev_repository_url : str , dev_user : str , varname_dev_password : str , stable_repository_url : str , stable_user : str , varname_stable_password : str , mypy_package_dir : Optional [ str ] = None , ) -> JobSequence : \"\"\" Returns a pipeline containing all jobs from `gcip.addons.python.jobs`: * isort * flake8 * pytest * evaluating CI_COMMIT_TAG as valid PyPI version string (if exists) * bdist_wheel * Gitlab Pages sphinx * twine upload :arg repository_url: The URL to the PyPI repository the python artifacts will be deployed to. :arg user: The name of the user to access the PyPI repository. :arg varname_password: The name of the environment variable delivering the password to access the PyPI repository. If not existent, automatically a \"$\" will be prepended to the string. DO NOT DEFINE THE PASSWORD WITHIN THE PIPELINE. Define your password outside the pipeline, e.g. as secret variable in the Gitlab CI/CD settings section. \"\"\" sequence = JobSequence () sequence . add_children ( python . isort (), python . flake8 (), python . pytest (), python . evaluate_git_tag_pep404_conformity (), python . bdist_wheel (), ) if mypy_package_dir : sequence . add_children ( python . mypy ( mypy_package_dir )) pages_sphinx = python . pages_sphinx () pages_sphinx . append_rules ( rules . on_main (), rules . on_master (), rules . on_tags (), ) sequence . add_children ( pages_sphinx ) twine_upload_dev = python . twine_upload ( dev_repository_url , dev_user , varname_dev_password ) twine_upload_dev . append_rules ( rules . on_tags () . never (), rules . on_success (), ) sequence . add_children ( twine_upload_dev , name = \"dev\" ) twine_upload_stable = python . twine_upload ( stable_repository_url , stable_user , varname_stable_password ) twine_upload_stable . append_rules ( rules . on_tags ()) sequence . add_children ( twine_upload_stable , name = \"stable\" ) return sequence","title":"Module gcip.addons.python.sequences"},{"location":"reference/gcip/addons/python/sequences/#functions","text":"","title":"Functions"},{"location":"reference/gcip/addons/python/sequences/#full_stack","text":"def full_stack ( dev_repository_url : str , dev_user : str , varname_dev_password : str , stable_repository_url : str , stable_user : str , varname_stable_password : str , mypy_package_dir : Optional [ str ] = None ) -> gcip . core . job_sequence . JobSequence Returns a pipeline containing all jobs from gcip.addons.python.jobs : isort flake8 pytest evaluating CI_COMMIT_TAG as valid PyPI version string (if exists) bdist_wheel Gitlab Pages sphinx twine upload Parameters: Name Type Description Default repository_url None The URL to the PyPI repository the python artifacts will be deployed to. None user None The name of the user to access the PyPI repository. None varname_password None The name of the environment variable delivering the password to access the PyPI repository. If not existent, automatically a \"$\" will be prepended to the string. DO NOT DEFINE THE PASSWORD WITHIN THE PIPELINE. Define your password outside the pipeline, e.g. as secret variable in the Gitlab CI/CD settings section. None View Source def full_stack ( dev_repository_url : str , dev_user : str , varname_dev_password : str , stable_repository_url : str , stable_user : str , varname_stable_password : str , mypy_package_dir : Optional [ str ] = None , ) -> JobSequence : \"\"\" Returns a pipeline containing all jobs from `gcip.addons.python.jobs`: * isort * flake8 * pytest * evaluating CI_COMMIT_TAG as valid PyPI version string (if exists) * bdist_wheel * Gitlab Pages sphinx * twine upload :arg repository_url: The URL to the PyPI repository the python artifacts will be deployed to. :arg user: The name of the user to access the PyPI repository. :arg varname_password: The name of the environment variable delivering the password to access the PyPI repository. If not existent, automatically a \"$\" will be prepended to the string. DO NOT DEFINE THE PASSWORD WITHIN THE PIPELINE. Define your password outside the pipeline, e.g. as secret variable in the Gitlab CI/CD settings section. \"\"\" sequence = JobSequence () sequence . add_children ( python . isort (), python . flake8 (), python . pytest (), python . evaluate_git_tag_pep404_conformity (), python . bdist_wheel (), ) if mypy_package_dir : sequence . add_children ( python . mypy ( mypy_package_dir )) pages_sphinx = python . pages_sphinx () pages_sphinx . append_rules ( rules . on_main (), rules . on_master (), rules . on_tags (), ) sequence . add_children ( pages_sphinx ) twine_upload_dev = python . twine_upload ( dev_repository_url , dev_user , varname_dev_password ) twine_upload_dev . append_rules ( rules . on_tags () . never (), rules . on_success (), ) sequence . add_children ( twine_upload_dev , name = \"dev\" ) twine_upload_stable = python . twine_upload ( stable_repository_url , stable_user , varname_stable_password ) twine_upload_stable . append_rules ( rules . on_tags ()) sequence . add_children ( twine_upload_stable , name = \"stable\" ) return sequence","title":"full_stack"},{"location":"reference/gcip/core/","text":"Module gcip.core None None View Source from typing import Dict __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' OrderedSetType = Dict [ str , None ] Sub-modules gcip.core.cache gcip.core.image gcip.core.include gcip.core.job gcip.core.job_sequence gcip.core.need gcip.core.pipeline gcip.core.rule gcip.core.variables Variables OrderedSetType","title":"Index"},{"location":"reference/gcip/core/#module-gcipcore","text":"None None View Source from typing import Dict __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' OrderedSetType = Dict [ str , None ]","title":"Module gcip.core"},{"location":"reference/gcip/core/#sub-modules","text":"gcip.core.cache gcip.core.image gcip.core.include gcip.core.job gcip.core.job_sequence gcip.core.need gcip.core.pipeline gcip.core.rule gcip.core.variables","title":"Sub-modules"},{"location":"reference/gcip/core/#variables","text":"OrderedSetType","title":"Variables"},{"location":"reference/gcip/core/cache/","text":"Module gcip.core.cache None None View Source import re from enum import Enum from typing import Any , Dict , List , Union , Optional from gcip.core.rule import WhenStatement from gcip.core.variables import PredefinedVariables class CachePolicy ( Enum ): \"\"\"Static cache policies. Used to initialize policy in conjunction with Cache object. \"\"\" PULL_PUSH = \"pull-push\" PULL = \"pull\" class CacheKey (): def __init__ ( self , key : Optional [ str ] = None , files : Optional [ List [ str ]] = None , prefix : Optional [ str ] = None ) -> None : \"\"\"Creates an object which represents an `key` within cache. For more information what a `cache` and its `key` is see: https://docs.gitlab.com/ee/ci/yaml/README.html#cachekey Args: key (Optional[str], optional): Name of the key, used to share the cache with jobs, exclusive with `files`. Defaults to PredefinedVariables.CI_COMMIT_REF_SLUG() if neither `key` nor `file` is set. files (Optional[list], optional): Files which can be used to create the cache key, exclusive to `keys`. Defaults to None. prefix (Optional[str], optional): Prefix prefixed given `files` to allow creation of caches for branches. Defaults to None. Raises: ValueError: If `key` and `files` are given at the same time. ValueError: If `key` and `prefix` are given at the same time. ValueError: If `prefix` and not `files` is given. ValueError: If `key` contains only out of dots '.'. \"\"\" self . _key = key self . _files = files self . _prefix = prefix if self . _key and self . _files : raise ValueError ( \"Parameters key and files are mutually exclusive.\" ) elif self . _prefix and not self . _files : raise ValueError ( \"Parameter 'prefix' can only be used together with 'files'.\" ) if self . _files is None and self . _key is None : self . _key = PredefinedVariables . CI_COMMIT_REF_SLUG if self . _key : # Forward slash not allowed for cache key, # therefore converting slash to underscore self . _key . replace ( \"/\" , \"_\" ) if re . match ( r \"^\\.*$\" , self . _key ): raise ValueError ( \"The cache key cannot be a value only made of '.'\" ) @property def key ( self ) -> Optional [ str ]: return self . _key @property def files ( self ) -> Optional [ List [ str ]]: return self . _files @property def prefix ( self ) -> Optional [ str ]: return self . _prefix def render ( self ) -> Union [ str , Dict [ str , Union [ List [ str ], str ]]]: \"\"\"Renders the class into a python dictionary. Example1: python``` print(CacheKey(key=\"mycachekey\").render()) -> 'mycachekey' ``` Example2: python``` print(CacheKey(files=[\"requirements.txt\", \"setup.py\"], prefix=\"myprefix\").render()) -> {'files': ['requirements.txt', 'setup.py'], 'prefix': 'myprefix'} ``` Returns: Union[str, Dict[str, Union[List[str], str]]]: Representing a cache object in Gitlab CI. \"\"\" rendered : Union [ str , Dict [ str , Union [ List [ str ], str ]]] if self . _key : rendered = self . _key else : rendered = {} if self . _files : rendered [ \"files\" ] = self . _files if self . _prefix : rendered [ \"prefix\" ] = self . _prefix return rendered class Cache (): def __init__ ( self , paths : List [ str ], cache_key : Optional [ CacheKey ] = None , untracked : Optional [ bool ] = None , when : Optional [ WhenStatement ] = None , policy : Optional [ CachePolicy ] = None , ) -> None : \"\"\"Creates Args: paths: Paths to create the cache to. cache_key (Optional[CacheKey], optional): Cache key which is used to share the cache. If None, cache_key will be initialized with an empty CacheKey. See class CacheKey untracked (Optional[bool], optional): If true, cache will cache all untracked files within project path. Defaults to None. when (Optional[WhenStatement], optional): Defines when to save the cache, depending on job status. Possible values are WhenStatement.ON_SUCCESS, WhenStatement.ON_FAILURE, WhenStatement.ALWAYS Defaults to None. policy (Optional[CachePolicy], optional): There are two policies, pull and push-pull. Use pull policy if you know, that the job does not alter the files within the cache. Defaults to None. Raises: ValueError: When unallowed WhenStatements are used. \"\"\" self . _paths = [] self . _untracked = untracked self . _when = when self . _policy = policy # Remove project path prefix from paths given. # Prepend ./ to path to clearify that cache paths # are relative to CI_PROJECT_PATH for path in paths : if path . startswith ( PredefinedVariables . CI_PROJECT_PATH ): path = path [ len ( PredefinedVariables . CI_PROJECT_PATH ):] if not path . startswith ( \"./\" ): path = \"./\" + path self . _paths . append ( path ) # Get default CacheKey = PredefinedVariables.CI_COMMIT_REF_SLUG if cache_key : self . _cache_key = cache_key else : self . _cache_key = CacheKey () allowed_when_statements = [ WhenStatement . ON_SUCCESS , WhenStatement . ON_FAILURE , WhenStatement . ALWAYS ] if self . _when and self . _when not in allowed_when_statements : raise ValueError ( f \"{self._when} is not allowed. Allowed when statements: {allowed_when_statements}\" ) @property def paths ( self ) -> List [ str ]: return self . _paths @property def cache_key ( self ) -> CacheKey : return self . _cache_key @property def untracked ( self ) -> Optional [ bool ]: return self . _untracked @property def when ( self ) -> Optional [ WhenStatement ]: return self . _when @property def policy ( self ) -> Optional [ CachePolicy ]: return self . _policy def render ( self ) -> Dict [ str , Any ]: \"\"\"Rendering method to rendere object into GitLab CI object. Returns: Dict[str, Union[str, list]]: Configuration of a GitLab cache. \"\"\" rendered : Dict [ str , Union [ str , bool , List [ str ], Union [ str , Dict [ str , Union [ List [ str ], str ]]]]] rendered = { \"paths\" : self . _paths } if self . _when : rendered [ \"when\" ] = self . _when . value if self . _untracked : rendered [ \"untracked\" ] = self . _untracked if self . _policy : rendered [ \"policy\" ] = self . _policy . value rendered [ \"key\" ] = self . _cache_key . render () return rendered Classes Cache class Cache ( paths : List [ str ], cache_key : Optional [ gcip . core . cache . CacheKey ] = None , untracked : Optional [ bool ] = None , when : Optional [ gcip . core . rule . WhenStatement ] = None , policy : Optional [ gcip . core . cache . CachePolicy ] = None ) View Source class Cache () : def __init__ ( self , paths : List [ str ] , cache_key : Optional [ CacheKey ] = None , untracked : Optional [ bool ] = None , when : Optional [ WhenStatement ] = None , policy : Optional [ CachePolicy ] = None , ) -> None : \"\"\"Creates Args: paths: Paths to create the cache to. cache_key (Optional[CacheKey], optional): Cache key which is used to share the cache. If None, cache_key will be initialized with an empty CacheKey. See class CacheKey untracked (Optional[bool], optional): If true, cache will cache all untracked files within project path. Defaults to None. when (Optional[WhenStatement], optional): Defines when to save the cache, depending on job status. Possible values are WhenStatement.ON_SUCCESS, WhenStatement.ON_FAILURE, WhenStatement.ALWAYS Defaults to None. policy (Optional[CachePolicy], optional): There are two policies, pull and push-pull. Use pull policy if you know, that the job does not alter the files within the cache. Defaults to None. Raises: ValueError: When unallowed WhenStatements are used. \"\"\" self . _paths = [] self . _untracked = untracked self . _when = when self . _policy = policy # Remove project path prefix from paths given . # Prepend . / to path to clearify that cache paths # are relative to CI_PROJECT_PATH for path in paths : if path . startswith ( PredefinedVariables . CI_PROJECT_PATH ) : path = path [ len(PredefinedVariables.CI_PROJECT_PATH): ] if not path . startswith ( \"./\" ) : path = \"./\" + path self . _paths . append ( path ) # Get default CacheKey = PredefinedVariables . CI_COMMIT_REF_SLUG if cache_key : self . _cache_key = cache_key else : self . _cache_key = CacheKey () allowed_when_statements = [ WhenStatement.ON_SUCCESS, WhenStatement.ON_FAILURE, WhenStatement.ALWAYS ] if self . _when and self . _when not in allowed_when_statements : raise ValueError ( f \"{self._when} is not allowed. Allowed when statements: {allowed_when_statements}\" ) @property def paths ( self ) -> List [ str ] : return self . _paths @property def cache_key ( self ) -> CacheKey : return self . _cache_key @property def untracked ( self ) -> Optional [ bool ] : return self . _untracked @property def when ( self ) -> Optional [ WhenStatement ] : return self . _when @property def policy ( self ) -> Optional [ CachePolicy ] : return self . _policy def render ( self ) -> Dict [ str, Any ] : \"\"\"Rendering method to rendere object into GitLab CI object. Returns: Dict[str, Union[str, list]]: Configuration of a GitLab cache. \"\"\" rendered : Dict [ str, Union[str, bool, List[str ] , Union [ str, Dict[str, Union[List[str ] , str ]]]]] rendered = { \"paths\" : self . _paths } if self . _when : rendered [ \"when\" ] = self . _when . value if self . _untracked : rendered [ \"untracked\" ] = self . _untracked if self . _policy : rendered [ \"policy\" ] = self . _policy . value rendered [ \"key\" ] = self . _cache_key . render () return rendered Instance variables cache_key paths policy untracked when Methods render def render ( self ) -> Dict [ str , Any ] Rendering method to rendere object into GitLab CI object. Returns: Type Description Dict[str, Union[str, list]] Configuration of a GitLab cache. View Source def render ( self ) -> Dict [ str, Any ] : \"\"\"Rendering method to rendere object into GitLab CI object. Returns: Dict[str, Union[str, list]]: Configuration of a GitLab cache. \"\"\" rendered : Dict [ str, Union[str, bool, List[str ] , Union [ str, Dict[str, Union[List[str ] , str ]]]]] rendered = { \"paths\" : self . _paths } if self . _when : rendered [ \"when\" ] = self . _when . value if self . _untracked : rendered [ \"untracked\" ] = self . _untracked if self . _policy : rendered [ \"policy\" ] = self . _policy . value rendered [ \"key\" ] = self . _cache_key . render () return rendered CacheKey class CacheKey ( key : Optional [ str ] = None , files : Optional [ List [ str ]] = None , prefix : Optional [ str ] = None ) View Source class CacheKey () : def __init__ ( self , key : Optional [ str ] = None , files : Optional [ List [ str ]] = None , prefix : Optional [ str ] = None ) -> None : \" \"\" Creates an object which represents an `key` within cache. For more information what a `cache` and its `key` is see: https://docs.gitlab.com/ee/ci/yaml/README.html#cachekey Args: key (Optional[str], optional): Name of the key, used to share the cache with jobs, exclusive with `files`. Defaults to PredefinedVariables.CI_COMMIT_REF_SLUG() if neither `key` nor `file` is set. files (Optional[list], optional): Files which can be used to create the cache key, exclusive to `keys`. Defaults to None. prefix (Optional[str], optional): Prefix prefixed given `files` to allow creation of caches for branches. Defaults to None. Raises: ValueError: If `key` and `files` are given at the same time. ValueError: If `key` and `prefix` are given at the same time. ValueError: If `prefix` and not `files` is given. ValueError: If `key` contains only out of dots '.'. \"\" \" self . _key = key self . _files = files self . _prefix = prefix if self . _key and self . _files : raise ValueError ( \"Parameters key and files are mutually exclusive.\" ) elif self . _prefix and not self . _files : raise ValueError ( \"Parameter 'prefix' can only be used together with 'files'.\" ) if self . _files is None and self . _key is None : self . _key = PredefinedVariables . CI_COMMIT_REF_SLUG if self . _key : # Forward slash not allowed for cache key, # therefore converting slash to underscore self . _key . replace ( \"/\" , \"_\" ) if re . match ( r \"^ \\ .*$\" , self . _key ) : raise ValueError ( \"The cache key cannot be a value only made of '.'\" ) @property def key ( self ) -> Optional [ str ] : return self . _key @property def files ( self ) -> Optional [ List [ str ]] : return self . _files @property def prefix ( self ) -> Optional [ str ] : return self . _prefix def render ( self ) -> Union [ str , Dict [ str , Union [ List [ str ] , str ]]] : \" \"\" Renders the class into a python dictionary. Example1: python``` print(CacheKey(key=\" mycachekey \").render()) -> 'mycachekey' ``` Example2: python``` print(CacheKey(files=[\" requirements . txt \", \" set up . py \"], prefix=\" myprefix \").render()) -> {'files': ['requirements.txt', 'setup.py'], 'prefix': 'myprefix'} ``` Returns: Union[str, Dict[str, Union[List[str], str]]]: Representing a cache object in Gitlab CI. \"\" \" rendered : Union [ str , Dict [ str , Union [ List [ str ] , str ]]] if self . _key : rendered = self . _key else : rendered = {} if self . _files : rendered [ \"files\" ] = self . _files if self . _prefix : rendered [ \"prefix\" ] = self . _prefix return rendered Instance variables files key prefix Methods render def render ( self ) -> Union [ str , Dict [ str , Union [ List [ str ], str ]]] Renders the class into a python dictionary. Example1: python``` print(CacheKey(key=\"mycachekey\").render()) -> 'mycachekey' Example2 : python ``` print ( CacheKey ( files =[ \"requirements.txt\" , \"setup.py\" ], prefix = \"myprefix\" ). render ()) -> { 'files' : [ 'requirements.txt' , 'setup.py' ], 'prefix' : 'myprefix' } Returns: Type Description Union[str, Dict[str, Union[List[str], str]]] Representing a cache object in Gitlab CI. View Source def render ( self ) -> Union [ str, Dict[str, Union[List[str ] , str ]]]: \"\"\"Renders the class into a python dictionary. Example1: python``` print(CacheKey(key=\" mycachekey \").render()) -> 'mycachekey' ``` Example2: python``` print(CacheKey(files=[\" requirements . txt \", \" setup . py \"], prefix=\" myprefix \").render()) -> {'files': ['requirements.txt', 'setup.py'], 'prefix': 'myprefix'} ``` Returns: Union[str, Dict[str, Union[List[str], str]]]: Representing a cache object in Gitlab CI. \"\"\" rendered : Union [ str, Dict[str, Union[List[str ] , str ]]] if self . _key : rendered = self . _key else : rendered = {} if self . _files : rendered [ \"files\" ] = self . _files if self . _prefix : rendered [ \"prefix\" ] = self . _prefix return rendered CachePolicy class CachePolicy ( / , * args , ** kwargs ) View Source class CachePolicy ( Enum ): \"\"\"Static cache policies. Used to initialize policy in conjunction with Cache object. \"\"\" PULL_PUSH = \"pull-push\" PULL = \"pull\" Ancestors (in MRO) enum.Enum Class variables PULL PULL_PUSH name value","title":"Cache"},{"location":"reference/gcip/core/cache/#module-gcipcorecache","text":"None None View Source import re from enum import Enum from typing import Any , Dict , List , Union , Optional from gcip.core.rule import WhenStatement from gcip.core.variables import PredefinedVariables class CachePolicy ( Enum ): \"\"\"Static cache policies. Used to initialize policy in conjunction with Cache object. \"\"\" PULL_PUSH = \"pull-push\" PULL = \"pull\" class CacheKey (): def __init__ ( self , key : Optional [ str ] = None , files : Optional [ List [ str ]] = None , prefix : Optional [ str ] = None ) -> None : \"\"\"Creates an object which represents an `key` within cache. For more information what a `cache` and its `key` is see: https://docs.gitlab.com/ee/ci/yaml/README.html#cachekey Args: key (Optional[str], optional): Name of the key, used to share the cache with jobs, exclusive with `files`. Defaults to PredefinedVariables.CI_COMMIT_REF_SLUG() if neither `key` nor `file` is set. files (Optional[list], optional): Files which can be used to create the cache key, exclusive to `keys`. Defaults to None. prefix (Optional[str], optional): Prefix prefixed given `files` to allow creation of caches for branches. Defaults to None. Raises: ValueError: If `key` and `files` are given at the same time. ValueError: If `key` and `prefix` are given at the same time. ValueError: If `prefix` and not `files` is given. ValueError: If `key` contains only out of dots '.'. \"\"\" self . _key = key self . _files = files self . _prefix = prefix if self . _key and self . _files : raise ValueError ( \"Parameters key and files are mutually exclusive.\" ) elif self . _prefix and not self . _files : raise ValueError ( \"Parameter 'prefix' can only be used together with 'files'.\" ) if self . _files is None and self . _key is None : self . _key = PredefinedVariables . CI_COMMIT_REF_SLUG if self . _key : # Forward slash not allowed for cache key, # therefore converting slash to underscore self . _key . replace ( \"/\" , \"_\" ) if re . match ( r \"^\\.*$\" , self . _key ): raise ValueError ( \"The cache key cannot be a value only made of '.'\" ) @property def key ( self ) -> Optional [ str ]: return self . _key @property def files ( self ) -> Optional [ List [ str ]]: return self . _files @property def prefix ( self ) -> Optional [ str ]: return self . _prefix def render ( self ) -> Union [ str , Dict [ str , Union [ List [ str ], str ]]]: \"\"\"Renders the class into a python dictionary. Example1: python``` print(CacheKey(key=\"mycachekey\").render()) -> 'mycachekey' ``` Example2: python``` print(CacheKey(files=[\"requirements.txt\", \"setup.py\"], prefix=\"myprefix\").render()) -> {'files': ['requirements.txt', 'setup.py'], 'prefix': 'myprefix'} ``` Returns: Union[str, Dict[str, Union[List[str], str]]]: Representing a cache object in Gitlab CI. \"\"\" rendered : Union [ str , Dict [ str , Union [ List [ str ], str ]]] if self . _key : rendered = self . _key else : rendered = {} if self . _files : rendered [ \"files\" ] = self . _files if self . _prefix : rendered [ \"prefix\" ] = self . _prefix return rendered class Cache (): def __init__ ( self , paths : List [ str ], cache_key : Optional [ CacheKey ] = None , untracked : Optional [ bool ] = None , when : Optional [ WhenStatement ] = None , policy : Optional [ CachePolicy ] = None , ) -> None : \"\"\"Creates Args: paths: Paths to create the cache to. cache_key (Optional[CacheKey], optional): Cache key which is used to share the cache. If None, cache_key will be initialized with an empty CacheKey. See class CacheKey untracked (Optional[bool], optional): If true, cache will cache all untracked files within project path. Defaults to None. when (Optional[WhenStatement], optional): Defines when to save the cache, depending on job status. Possible values are WhenStatement.ON_SUCCESS, WhenStatement.ON_FAILURE, WhenStatement.ALWAYS Defaults to None. policy (Optional[CachePolicy], optional): There are two policies, pull and push-pull. Use pull policy if you know, that the job does not alter the files within the cache. Defaults to None. Raises: ValueError: When unallowed WhenStatements are used. \"\"\" self . _paths = [] self . _untracked = untracked self . _when = when self . _policy = policy # Remove project path prefix from paths given. # Prepend ./ to path to clearify that cache paths # are relative to CI_PROJECT_PATH for path in paths : if path . startswith ( PredefinedVariables . CI_PROJECT_PATH ): path = path [ len ( PredefinedVariables . CI_PROJECT_PATH ):] if not path . startswith ( \"./\" ): path = \"./\" + path self . _paths . append ( path ) # Get default CacheKey = PredefinedVariables.CI_COMMIT_REF_SLUG if cache_key : self . _cache_key = cache_key else : self . _cache_key = CacheKey () allowed_when_statements = [ WhenStatement . ON_SUCCESS , WhenStatement . ON_FAILURE , WhenStatement . ALWAYS ] if self . _when and self . _when not in allowed_when_statements : raise ValueError ( f \"{self._when} is not allowed. Allowed when statements: {allowed_when_statements}\" ) @property def paths ( self ) -> List [ str ]: return self . _paths @property def cache_key ( self ) -> CacheKey : return self . _cache_key @property def untracked ( self ) -> Optional [ bool ]: return self . _untracked @property def when ( self ) -> Optional [ WhenStatement ]: return self . _when @property def policy ( self ) -> Optional [ CachePolicy ]: return self . _policy def render ( self ) -> Dict [ str , Any ]: \"\"\"Rendering method to rendere object into GitLab CI object. Returns: Dict[str, Union[str, list]]: Configuration of a GitLab cache. \"\"\" rendered : Dict [ str , Union [ str , bool , List [ str ], Union [ str , Dict [ str , Union [ List [ str ], str ]]]]] rendered = { \"paths\" : self . _paths } if self . _when : rendered [ \"when\" ] = self . _when . value if self . _untracked : rendered [ \"untracked\" ] = self . _untracked if self . _policy : rendered [ \"policy\" ] = self . _policy . value rendered [ \"key\" ] = self . _cache_key . render () return rendered","title":"Module gcip.core.cache"},{"location":"reference/gcip/core/cache/#classes","text":"","title":"Classes"},{"location":"reference/gcip/core/cache/#cache","text":"class Cache ( paths : List [ str ], cache_key : Optional [ gcip . core . cache . CacheKey ] = None , untracked : Optional [ bool ] = None , when : Optional [ gcip . core . rule . WhenStatement ] = None , policy : Optional [ gcip . core . cache . CachePolicy ] = None ) View Source class Cache () : def __init__ ( self , paths : List [ str ] , cache_key : Optional [ CacheKey ] = None , untracked : Optional [ bool ] = None , when : Optional [ WhenStatement ] = None , policy : Optional [ CachePolicy ] = None , ) -> None : \"\"\"Creates Args: paths: Paths to create the cache to. cache_key (Optional[CacheKey], optional): Cache key which is used to share the cache. If None, cache_key will be initialized with an empty CacheKey. See class CacheKey untracked (Optional[bool], optional): If true, cache will cache all untracked files within project path. Defaults to None. when (Optional[WhenStatement], optional): Defines when to save the cache, depending on job status. Possible values are WhenStatement.ON_SUCCESS, WhenStatement.ON_FAILURE, WhenStatement.ALWAYS Defaults to None. policy (Optional[CachePolicy], optional): There are two policies, pull and push-pull. Use pull policy if you know, that the job does not alter the files within the cache. Defaults to None. Raises: ValueError: When unallowed WhenStatements are used. \"\"\" self . _paths = [] self . _untracked = untracked self . _when = when self . _policy = policy # Remove project path prefix from paths given . # Prepend . / to path to clearify that cache paths # are relative to CI_PROJECT_PATH for path in paths : if path . startswith ( PredefinedVariables . CI_PROJECT_PATH ) : path = path [ len(PredefinedVariables.CI_PROJECT_PATH): ] if not path . startswith ( \"./\" ) : path = \"./\" + path self . _paths . append ( path ) # Get default CacheKey = PredefinedVariables . CI_COMMIT_REF_SLUG if cache_key : self . _cache_key = cache_key else : self . _cache_key = CacheKey () allowed_when_statements = [ WhenStatement.ON_SUCCESS, WhenStatement.ON_FAILURE, WhenStatement.ALWAYS ] if self . _when and self . _when not in allowed_when_statements : raise ValueError ( f \"{self._when} is not allowed. Allowed when statements: {allowed_when_statements}\" ) @property def paths ( self ) -> List [ str ] : return self . _paths @property def cache_key ( self ) -> CacheKey : return self . _cache_key @property def untracked ( self ) -> Optional [ bool ] : return self . _untracked @property def when ( self ) -> Optional [ WhenStatement ] : return self . _when @property def policy ( self ) -> Optional [ CachePolicy ] : return self . _policy def render ( self ) -> Dict [ str, Any ] : \"\"\"Rendering method to rendere object into GitLab CI object. Returns: Dict[str, Union[str, list]]: Configuration of a GitLab cache. \"\"\" rendered : Dict [ str, Union[str, bool, List[str ] , Union [ str, Dict[str, Union[List[str ] , str ]]]]] rendered = { \"paths\" : self . _paths } if self . _when : rendered [ \"when\" ] = self . _when . value if self . _untracked : rendered [ \"untracked\" ] = self . _untracked if self . _policy : rendered [ \"policy\" ] = self . _policy . value rendered [ \"key\" ] = self . _cache_key . render () return rendered","title":"Cache"},{"location":"reference/gcip/core/cache/#instance-variables","text":"cache_key paths policy untracked when","title":"Instance variables"},{"location":"reference/gcip/core/cache/#methods","text":"","title":"Methods"},{"location":"reference/gcip/core/cache/#render","text":"def render ( self ) -> Dict [ str , Any ] Rendering method to rendere object into GitLab CI object. Returns: Type Description Dict[str, Union[str, list]] Configuration of a GitLab cache. View Source def render ( self ) -> Dict [ str, Any ] : \"\"\"Rendering method to rendere object into GitLab CI object. Returns: Dict[str, Union[str, list]]: Configuration of a GitLab cache. \"\"\" rendered : Dict [ str, Union[str, bool, List[str ] , Union [ str, Dict[str, Union[List[str ] , str ]]]]] rendered = { \"paths\" : self . _paths } if self . _when : rendered [ \"when\" ] = self . _when . value if self . _untracked : rendered [ \"untracked\" ] = self . _untracked if self . _policy : rendered [ \"policy\" ] = self . _policy . value rendered [ \"key\" ] = self . _cache_key . render () return rendered","title":"render"},{"location":"reference/gcip/core/cache/#cachekey","text":"class CacheKey ( key : Optional [ str ] = None , files : Optional [ List [ str ]] = None , prefix : Optional [ str ] = None ) View Source class CacheKey () : def __init__ ( self , key : Optional [ str ] = None , files : Optional [ List [ str ]] = None , prefix : Optional [ str ] = None ) -> None : \" \"\" Creates an object which represents an `key` within cache. For more information what a `cache` and its `key` is see: https://docs.gitlab.com/ee/ci/yaml/README.html#cachekey Args: key (Optional[str], optional): Name of the key, used to share the cache with jobs, exclusive with `files`. Defaults to PredefinedVariables.CI_COMMIT_REF_SLUG() if neither `key` nor `file` is set. files (Optional[list], optional): Files which can be used to create the cache key, exclusive to `keys`. Defaults to None. prefix (Optional[str], optional): Prefix prefixed given `files` to allow creation of caches for branches. Defaults to None. Raises: ValueError: If `key` and `files` are given at the same time. ValueError: If `key` and `prefix` are given at the same time. ValueError: If `prefix` and not `files` is given. ValueError: If `key` contains only out of dots '.'. \"\" \" self . _key = key self . _files = files self . _prefix = prefix if self . _key and self . _files : raise ValueError ( \"Parameters key and files are mutually exclusive.\" ) elif self . _prefix and not self . _files : raise ValueError ( \"Parameter 'prefix' can only be used together with 'files'.\" ) if self . _files is None and self . _key is None : self . _key = PredefinedVariables . CI_COMMIT_REF_SLUG if self . _key : # Forward slash not allowed for cache key, # therefore converting slash to underscore self . _key . replace ( \"/\" , \"_\" ) if re . match ( r \"^ \\ .*$\" , self . _key ) : raise ValueError ( \"The cache key cannot be a value only made of '.'\" ) @property def key ( self ) -> Optional [ str ] : return self . _key @property def files ( self ) -> Optional [ List [ str ]] : return self . _files @property def prefix ( self ) -> Optional [ str ] : return self . _prefix def render ( self ) -> Union [ str , Dict [ str , Union [ List [ str ] , str ]]] : \" \"\" Renders the class into a python dictionary. Example1: python``` print(CacheKey(key=\" mycachekey \").render()) -> 'mycachekey' ``` Example2: python``` print(CacheKey(files=[\" requirements . txt \", \" set up . py \"], prefix=\" myprefix \").render()) -> {'files': ['requirements.txt', 'setup.py'], 'prefix': 'myprefix'} ``` Returns: Union[str, Dict[str, Union[List[str], str]]]: Representing a cache object in Gitlab CI. \"\" \" rendered : Union [ str , Dict [ str , Union [ List [ str ] , str ]]] if self . _key : rendered = self . _key else : rendered = {} if self . _files : rendered [ \"files\" ] = self . _files if self . _prefix : rendered [ \"prefix\" ] = self . _prefix return rendered","title":"CacheKey"},{"location":"reference/gcip/core/cache/#instance-variables_1","text":"files key prefix","title":"Instance variables"},{"location":"reference/gcip/core/cache/#methods_1","text":"","title":"Methods"},{"location":"reference/gcip/core/cache/#render_1","text":"def render ( self ) -> Union [ str , Dict [ str , Union [ List [ str ], str ]]] Renders the class into a python dictionary. Example1: python``` print(CacheKey(key=\"mycachekey\").render()) -> 'mycachekey' Example2 : python ``` print ( CacheKey ( files =[ \"requirements.txt\" , \"setup.py\" ], prefix = \"myprefix\" ). render ()) -> { 'files' : [ 'requirements.txt' , 'setup.py' ], 'prefix' : 'myprefix' } Returns: Type Description Union[str, Dict[str, Union[List[str], str]]] Representing a cache object in Gitlab CI. View Source def render ( self ) -> Union [ str, Dict[str, Union[List[str ] , str ]]]: \"\"\"Renders the class into a python dictionary. Example1: python``` print(CacheKey(key=\" mycachekey \").render()) -> 'mycachekey' ``` Example2: python``` print(CacheKey(files=[\" requirements . txt \", \" setup . py \"], prefix=\" myprefix \").render()) -> {'files': ['requirements.txt', 'setup.py'], 'prefix': 'myprefix'} ``` Returns: Union[str, Dict[str, Union[List[str], str]]]: Representing a cache object in Gitlab CI. \"\"\" rendered : Union [ str, Dict[str, Union[List[str ] , str ]]] if self . _key : rendered = self . _key else : rendered = {} if self . _files : rendered [ \"files\" ] = self . _files if self . _prefix : rendered [ \"prefix\" ] = self . _prefix return rendered","title":"render"},{"location":"reference/gcip/core/cache/#cachepolicy","text":"class CachePolicy ( / , * args , ** kwargs ) View Source class CachePolicy ( Enum ): \"\"\"Static cache policies. Used to initialize policy in conjunction with Cache object. \"\"\" PULL_PUSH = \"pull-push\" PULL = \"pull\"","title":"CachePolicy"},{"location":"reference/gcip/core/cache/#ancestors-in-mro","text":"enum.Enum","title":"Ancestors (in MRO)"},{"location":"reference/gcip/core/cache/#class-variables","text":"PULL PULL_PUSH name value","title":"Class variables"},{"location":"reference/gcip/core/image/","text":"Module gcip.core.image None None View Source from typing import Dict , List , Union , Optional class Image (): def __init__ ( self , name : str , * , entrypoint : Optional [ List [ str ]] = None ) -> None : \"\"\"Creates an object which represents an `image` for a job inside a pipeline. Args: name (str): URL where to pull image from incl. image tag. entrypoint (Optional[List[str]]): If set, overwrites the containers entrypoint. Defaults to None. \"\"\" self . _name = name self . _entrypoint = entrypoint @property def name ( self ) -> str : \"\"\"Image name\"\"\" return self . _name @property def entrypoint ( self ) -> Optional [ List [ str ]]: \"\"\"Container `entrypoint`\"\"\" return self . _entrypoint def render ( self ) -> Dict [ str , Union [ str , List [ str ]]]: \"\"\"Returns the rendered object to be attached to the job. Returns: Dict[str, str]: The dictionary representation of the image \"\"\" rendered : Dict [ str , Union [ str , List [ str ]]] = {} rendered [ \"name\" ] = self . _name if self . _entrypoint : rendered [ \"entrypoint\" ] = self . _entrypoint return rendered Classes Image class Image ( name : str , * , entrypoint : Optional [ List [ str ]] = None ) View Source class Image () : def __init__ ( self , name : str , * , entrypoint : Optional [ List[str ] ] = None ) -> None : \"\"\"Creates an object which represents an `image` for a job inside a pipeline. Args: name (str): URL where to pull image from incl. image tag. entrypoint (Optional[List[str]]): If set, overwrites the containers entrypoint. Defaults to None. \"\"\" self . _name = name self . _entrypoint = entrypoint @property def name ( self ) -> str : \"\"\"Image name\"\"\" return self . _name @property def entrypoint ( self ) -> Optional [ List[str ] ]: \"\"\"Container `entrypoint`\"\"\" return self . _entrypoint def render ( self ) -> Dict [ str, Union[str, List[str ] ]]: \"\"\"Returns the rendered object to be attached to the job. Returns: Dict[str, str]: The dictionary representation of the image \"\"\" rendered : Dict [ str, Union[str, List[str ] ]] = {} rendered [ \"name\" ] = self . _name if self . _entrypoint : rendered [ \"entrypoint\" ] = self . _entrypoint return rendered Instance variables entrypoint Container entrypoint name Image name Methods render def render ( self ) -> Dict [ str , Union [ List [ str ], str ]] Returns the rendered object to be attached to the job. Returns: Type Description Dict[str, str] The dictionary representation of the image View Source def render ( self ) -> Dict [ str, Union[str, List[str ] ]]: \"\"\"Returns the rendered object to be attached to the job. Returns: Dict[str, str]: The dictionary representation of the image \"\"\" rendered : Dict [ str, Union[str, List[str ] ]] = {} rendered [ \"name\" ] = self . _name if self . _entrypoint : rendered [ \"entrypoint\" ] = self . _entrypoint return rendered","title":"Image"},{"location":"reference/gcip/core/image/#module-gcipcoreimage","text":"None None View Source from typing import Dict , List , Union , Optional class Image (): def __init__ ( self , name : str , * , entrypoint : Optional [ List [ str ]] = None ) -> None : \"\"\"Creates an object which represents an `image` for a job inside a pipeline. Args: name (str): URL where to pull image from incl. image tag. entrypoint (Optional[List[str]]): If set, overwrites the containers entrypoint. Defaults to None. \"\"\" self . _name = name self . _entrypoint = entrypoint @property def name ( self ) -> str : \"\"\"Image name\"\"\" return self . _name @property def entrypoint ( self ) -> Optional [ List [ str ]]: \"\"\"Container `entrypoint`\"\"\" return self . _entrypoint def render ( self ) -> Dict [ str , Union [ str , List [ str ]]]: \"\"\"Returns the rendered object to be attached to the job. Returns: Dict[str, str]: The dictionary representation of the image \"\"\" rendered : Dict [ str , Union [ str , List [ str ]]] = {} rendered [ \"name\" ] = self . _name if self . _entrypoint : rendered [ \"entrypoint\" ] = self . _entrypoint return rendered","title":"Module gcip.core.image"},{"location":"reference/gcip/core/image/#classes","text":"","title":"Classes"},{"location":"reference/gcip/core/image/#image","text":"class Image ( name : str , * , entrypoint : Optional [ List [ str ]] = None ) View Source class Image () : def __init__ ( self , name : str , * , entrypoint : Optional [ List[str ] ] = None ) -> None : \"\"\"Creates an object which represents an `image` for a job inside a pipeline. Args: name (str): URL where to pull image from incl. image tag. entrypoint (Optional[List[str]]): If set, overwrites the containers entrypoint. Defaults to None. \"\"\" self . _name = name self . _entrypoint = entrypoint @property def name ( self ) -> str : \"\"\"Image name\"\"\" return self . _name @property def entrypoint ( self ) -> Optional [ List[str ] ]: \"\"\"Container `entrypoint`\"\"\" return self . _entrypoint def render ( self ) -> Dict [ str, Union[str, List[str ] ]]: \"\"\"Returns the rendered object to be attached to the job. Returns: Dict[str, str]: The dictionary representation of the image \"\"\" rendered : Dict [ str, Union[str, List[str ] ]] = {} rendered [ \"name\" ] = self . _name if self . _entrypoint : rendered [ \"entrypoint\" ] = self . _entrypoint return rendered","title":"Image"},{"location":"reference/gcip/core/image/#instance-variables","text":"entrypoint Container entrypoint name Image name","title":"Instance variables"},{"location":"reference/gcip/core/image/#methods","text":"","title":"Methods"},{"location":"reference/gcip/core/image/#render","text":"def render ( self ) -> Dict [ str , Union [ List [ str ], str ]] Returns the rendered object to be attached to the job. Returns: Type Description Dict[str, str] The dictionary representation of the image View Source def render ( self ) -> Dict [ str, Union[str, List[str ] ]]: \"\"\"Returns the rendered object to be attached to the job. Returns: Dict[str, str]: The dictionary representation of the image \"\"\" rendered : Dict [ str, Union[str, List[str ] ]] = {} rendered [ \"name\" ] = self . _name if self . _entrypoint : rendered [ \"entrypoint\" ] = self . _entrypoint return rendered","title":"render"},{"location":"reference/gcip/core/include/","text":"Module gcip.core.include None None View Source from abc import ABCMeta from typing import Dict , Optional from ..tools.url import is_valid_url __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' class Include ( metaclass = ABCMeta ): _rendered_include : Dict [ str , str ] def render ( self ) -> Dict [ str , str ]: return self . _rendered_include class IncludeLocal ( Include ): def __init__ ( self , local : str ) -> None : self . _rendered_include = { \"local\" : local } class IncludeFile ( Include ): def __init__ ( self , file : str , project : str , ref : Optional [ str ] = None , ) -> None : self . _rendered_include = { \"file\" : file , \"project\" : project } if ref : self . _rendered_include [ \"ref\" ] = ref class IncludeRemote ( Include ): def __init__ ( self , remote : str ) -> None : if not is_valid_url ( remote ): raise ValueError ( f \"`remote` is not a valid URL: {remote}\" ) self . _rendered_include = { \"remote\" : remote } class IncludeTemplate ( Include ): def __init__ ( self , template : str ): self . _rendered_include = { \"template\" : template } class IncludeArtifact ( Include ): \"\"\"for triggering a child pipeline with generated configuration file\"\"\" def __init__ ( self , job : str , artifact : str ): self . _rendered_include = { \"job\" : job , \"artifact\" : artifact } Classes Include class Include ( / , * args , ** kwargs ) View Source class Include ( metaclass = ABCMeta ): _rendered_include: Dict [ str , str ] def render ( self ) -> Dict [ str , str ]: return self . _rendered_include Descendants gcip.core.include.IncludeLocal gcip.core.include.IncludeFile gcip.core.include.IncludeRemote gcip.core.include.IncludeTemplate gcip.core.include.IncludeArtifact Methods render def render ( self ) -> Dict [ str , str ] View Source def render ( self ) -> Dict [ str , str ]: return self . _rendered_include IncludeArtifact class IncludeArtifact ( job : str , artifact : str ) View Source class IncludeArtifact ( Include ): \"\"\"for triggering a child pipeline with generated configuration file\"\"\" def __init__ ( self , job: str , artifact: str ): self . _rendered_include = { \"job\" : job , \"artifact\" : artifact } Ancestors (in MRO) gcip.core.include.Include Methods render def render ( self ) -> Dict [ str , str ] View Source def render ( self ) -> Dict [ str , str ]: return self . _rendered_include IncludeFile class IncludeFile ( file : str , project : str , ref : Optional [ str ] = None ) View Source class IncludeFile ( Include ) : def __init__ ( self , file : str , project : str , ref : Optional [ str ] = None , ) -> None : self . _rendered_include = { \"file\" : file , \"project\" : project } if ref : self . _rendered_include [ \"ref\" ] = ref Ancestors (in MRO) gcip.core.include.Include Methods render def render ( self ) -> Dict [ str , str ] View Source def render ( self ) -> Dict [ str , str ]: return self . _rendered_include IncludeLocal class IncludeLocal ( local : str ) View Source class IncludeLocal ( Include ): def __init__ ( self , local : str ) -> None : self. _rendered_include = { \"local\" : local } Ancestors (in MRO) gcip.core.include.Include Methods render def render ( self ) -> Dict [ str , str ] View Source def render ( self ) -> Dict [ str , str ]: return self . _rendered_include IncludeRemote class IncludeRemote ( remote : str ) View Source class IncludeRemote ( Include ) : def __init__ ( self , remote : str ) -> None : if not is_valid_url ( remote ) : raise ValueError ( f \"`remote` is not a valid URL: {remote}\" ) self . _rendered_include = { \"remote\" : remote } Ancestors (in MRO) gcip.core.include.Include Methods render def render ( self ) -> Dict [ str , str ] View Source def render ( self ) -> Dict [ str , str ]: return self . _rendered_include IncludeTemplate class IncludeTemplate ( template : str ) View Source class IncludeTemplate ( Include ): def __init__ ( self , template: str ): self . _rendered_include = { \"template\" : template } Ancestors (in MRO) gcip.core.include.Include Methods render def render ( self ) -> Dict [ str , str ] View Source def render ( self ) -> Dict [ str , str ]: return self . _rendered_include","title":"Include"},{"location":"reference/gcip/core/include/#module-gcipcoreinclude","text":"None None View Source from abc import ABCMeta from typing import Dict , Optional from ..tools.url import is_valid_url __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' class Include ( metaclass = ABCMeta ): _rendered_include : Dict [ str , str ] def render ( self ) -> Dict [ str , str ]: return self . _rendered_include class IncludeLocal ( Include ): def __init__ ( self , local : str ) -> None : self . _rendered_include = { \"local\" : local } class IncludeFile ( Include ): def __init__ ( self , file : str , project : str , ref : Optional [ str ] = None , ) -> None : self . _rendered_include = { \"file\" : file , \"project\" : project } if ref : self . _rendered_include [ \"ref\" ] = ref class IncludeRemote ( Include ): def __init__ ( self , remote : str ) -> None : if not is_valid_url ( remote ): raise ValueError ( f \"`remote` is not a valid URL: {remote}\" ) self . _rendered_include = { \"remote\" : remote } class IncludeTemplate ( Include ): def __init__ ( self , template : str ): self . _rendered_include = { \"template\" : template } class IncludeArtifact ( Include ): \"\"\"for triggering a child pipeline with generated configuration file\"\"\" def __init__ ( self , job : str , artifact : str ): self . _rendered_include = { \"job\" : job , \"artifact\" : artifact }","title":"Module gcip.core.include"},{"location":"reference/gcip/core/include/#classes","text":"","title":"Classes"},{"location":"reference/gcip/core/include/#include","text":"class Include ( / , * args , ** kwargs ) View Source class Include ( metaclass = ABCMeta ): _rendered_include: Dict [ str , str ] def render ( self ) -> Dict [ str , str ]: return self . _rendered_include","title":"Include"},{"location":"reference/gcip/core/include/#descendants","text":"gcip.core.include.IncludeLocal gcip.core.include.IncludeFile gcip.core.include.IncludeRemote gcip.core.include.IncludeTemplate gcip.core.include.IncludeArtifact","title":"Descendants"},{"location":"reference/gcip/core/include/#methods","text":"","title":"Methods"},{"location":"reference/gcip/core/include/#render","text":"def render ( self ) -> Dict [ str , str ] View Source def render ( self ) -> Dict [ str , str ]: return self . _rendered_include","title":"render"},{"location":"reference/gcip/core/include/#includeartifact","text":"class IncludeArtifact ( job : str , artifact : str ) View Source class IncludeArtifact ( Include ): \"\"\"for triggering a child pipeline with generated configuration file\"\"\" def __init__ ( self , job: str , artifact: str ): self . _rendered_include = { \"job\" : job , \"artifact\" : artifact }","title":"IncludeArtifact"},{"location":"reference/gcip/core/include/#ancestors-in-mro","text":"gcip.core.include.Include","title":"Ancestors (in MRO)"},{"location":"reference/gcip/core/include/#methods_1","text":"","title":"Methods"},{"location":"reference/gcip/core/include/#render_1","text":"def render ( self ) -> Dict [ str , str ] View Source def render ( self ) -> Dict [ str , str ]: return self . _rendered_include","title":"render"},{"location":"reference/gcip/core/include/#includefile","text":"class IncludeFile ( file : str , project : str , ref : Optional [ str ] = None ) View Source class IncludeFile ( Include ) : def __init__ ( self , file : str , project : str , ref : Optional [ str ] = None , ) -> None : self . _rendered_include = { \"file\" : file , \"project\" : project } if ref : self . _rendered_include [ \"ref\" ] = ref","title":"IncludeFile"},{"location":"reference/gcip/core/include/#ancestors-in-mro_1","text":"gcip.core.include.Include","title":"Ancestors (in MRO)"},{"location":"reference/gcip/core/include/#methods_2","text":"","title":"Methods"},{"location":"reference/gcip/core/include/#render_2","text":"def render ( self ) -> Dict [ str , str ] View Source def render ( self ) -> Dict [ str , str ]: return self . _rendered_include","title":"render"},{"location":"reference/gcip/core/include/#includelocal","text":"class IncludeLocal ( local : str ) View Source class IncludeLocal ( Include ): def __init__ ( self , local : str ) -> None : self. _rendered_include = { \"local\" : local }","title":"IncludeLocal"},{"location":"reference/gcip/core/include/#ancestors-in-mro_2","text":"gcip.core.include.Include","title":"Ancestors (in MRO)"},{"location":"reference/gcip/core/include/#methods_3","text":"","title":"Methods"},{"location":"reference/gcip/core/include/#render_3","text":"def render ( self ) -> Dict [ str , str ] View Source def render ( self ) -> Dict [ str , str ]: return self . _rendered_include","title":"render"},{"location":"reference/gcip/core/include/#includeremote","text":"class IncludeRemote ( remote : str ) View Source class IncludeRemote ( Include ) : def __init__ ( self , remote : str ) -> None : if not is_valid_url ( remote ) : raise ValueError ( f \"`remote` is not a valid URL: {remote}\" ) self . _rendered_include = { \"remote\" : remote }","title":"IncludeRemote"},{"location":"reference/gcip/core/include/#ancestors-in-mro_3","text":"gcip.core.include.Include","title":"Ancestors (in MRO)"},{"location":"reference/gcip/core/include/#methods_4","text":"","title":"Methods"},{"location":"reference/gcip/core/include/#render_4","text":"def render ( self ) -> Dict [ str , str ] View Source def render ( self ) -> Dict [ str , str ]: return self . _rendered_include","title":"render"},{"location":"reference/gcip/core/include/#includetemplate","text":"class IncludeTemplate ( template : str ) View Source class IncludeTemplate ( Include ): def __init__ ( self , template: str ): self . _rendered_include = { \"template\" : template }","title":"IncludeTemplate"},{"location":"reference/gcip/core/include/#ancestors-in-mro_4","text":"gcip.core.include.Include","title":"Ancestors (in MRO)"},{"location":"reference/gcip/core/include/#methods_5","text":"","title":"Methods"},{"location":"reference/gcip/core/include/#render_5","text":"def render ( self ) -> Dict [ str , str ] View Source def render ( self ) -> Dict [ str , str ]: return self . _rendered_include","title":"render"},{"location":"reference/gcip/core/job/","text":"Module gcip.core.job Testdocumentation for job View Source \"\"\"Testdocumentation for job \"\"\" from __future__ import annotations import copy from enum import Enum from typing import ( TYPE_CHECKING , Any , Set , Dict , List , Union , AnyStr , Mapping , Optional , ) from operator import itemgetter from . import OrderedSetType from .need import Need from .rule import Rule from .cache import Cache from .image import Image from .include import Include if TYPE_CHECKING : from .job_sequence import JobSequence __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' class Job (): \"\"\"Represents a Gitlab CI Job Attributes: script: The script to be executed. name: The name of the job. \"\"\" def __init__ ( self , * args : Any , script : Union [ AnyStr , List [ str ]], name : Optional [ str ] = None , namespace : Optional [ str ] = None , ): self . _stage = \"\" self . _name = \"\" self . _image : Optional [ Image ] = None self . _variables : Dict [ str , str ] = {} self . _tags : OrderedSetType = {} self . _rules : List [ Rule ] = [] self . _needs : List [ Union [ Need , Job , JobSequence ]] = [] self . _scripts : List [ str ] self . _artifacts_paths : OrderedSetType = {} self . _cache : Optional [ Cache ] = None self . _parents : List [ JobSequence ] = list () self . _original : Optional [ Job ] \"\"\"Only set if you get a :meth:`copy()` of this job\"\"\" if namespace and name : self . _name = f \"{namespace}-{name}\" self . _stage = namespace elif namespace : self . _name = namespace self . _stage = namespace elif name : self . _name = name # default for unset stages is 'test' -> https://docs.gitlab.com/ee/ci/yaml/#stages self . _stage = \"test\" else : raise ValueError ( \"At least one of the parameters `name` or `namespace` have to be set.\" ) self . _name = self . _name . replace ( \"_\" , \"-\" ) self . _stage = self . _stage . replace ( \"-\" , \"_\" ) if isinstance ( script , str ): self . _scripts = [ script ] elif isinstance ( script , list ): self . _scripts = script else : raise AttributeError ( \"script parameter must be of type string or list of strings\" ) @property def name ( self ) -> str : return self . _name @property def stage ( self ) -> str : return self . _stage def _extend_name ( self , name : Optional [ str ]) -> None : if name : self . _name += \"-\" + name . replace ( \"_\" , \"-\" ) def _extend_stage ( self , stage : Optional [ str ]) -> None : if stage : self . _stage += \"_\" + stage . replace ( \"-\" , \"_\" ) def _extend_namespace ( self , namespace : Optional [ str ]) -> None : if namespace : self . _extend_name ( namespace ) self . _extend_stage ( namespace ) def _add_parent ( self , parent : JobSequence ) -> None : self . _parents . append ( parent ) def prepend_scripts ( self , * scripts : str ) -> Job : self . _scripts = list ( scripts ) + self . _scripts return self def append_scripts ( self , * scripts : str ) -> Job : self . _scripts . extend ( scripts ) return self def add_variables ( self , ** variables : str ) -> Job : self . _variables . update ( variables ) return self def add_tags ( self , * tags : str ) -> Job : for tag in tags : self . _tags [ tag ] = None return self def add_artifacts_paths ( self , * paths : str ) -> Job : for path in paths : self . _artifacts_paths [ path ] = None return self def set_cache ( self , cache : Optional [ Cache ]) -> Job : \"\"\"Sets the cache for the Job. Args: cache (Cache): Cache to use for this Job. Returns: JobSequence: Returns the modified :class:`Job` object. \"\"\" if cache : self . _cache = cache return self def append_rules ( self , * rules : Rule ) -> Job : self . _rules . extend ( rules ) return self def prepend_rules ( self , * rules : Rule ) -> Job : self . _rules = list ( rules ) + self . _rules return self def add_needs ( self , * needs : Union [ Need , Job , JobSequence ]) -> Job : self . _needs . extend ( needs ) return self def set_image ( self , image : Optional [ Union [ Image , str ]]) -> Job : \"\"\"Sets the image of this job. For a simple container image you can provide the origin of the image. If you want to set the entrypoint, you have to provide an Image object instead. Args: image (Optional[Union[Image, str]]): Can be either `string` or `Image`. Returns: Job: Returns the modified :class:`Job` object. \"\"\" if image : if isinstance ( image , str ): image = Image ( image ) self . _image = image return self def _get_all_instance_names ( self ) -> Set [ str ]: instance_names : Set [ str ] = set () for parent in self . _parents : for postfix in parent . _get_all_instance_names ( self ): if postfix : instance_names . add ( f \"{self._name}-{postfix}\" . replace ( \"-#unset#\" , \"\" )) else : instance_names . add ( self . _name ) return instance_names def copy ( self ) -> Job : return self . _copy_into ( Job ( name = \".\" , script = copy . deepcopy ( self . _scripts ))) def _copy_into ( self , job : Job ) -> Job : job . _original = self job . _name = self . _name job . _stage = self . _stage job . set_image ( self . _image ) job . add_variables ( ** copy . deepcopy ( self . _variables )) job . add_tags ( * list ( self . _tags . keys ())) job . add_artifacts_paths ( * list ( self . _artifacts_paths . keys ())) job . set_cache ( self . _cache ) job . append_rules ( * self . _rules ) job . add_needs ( * self . _needs ) job . _parents = self . _parents . copy () return job def render ( self ) -> Dict [ str , Any ]: from .job_sequence import \\ JobSequence # late import to avoid circular dependencies rendered_job : Dict [ str , Any ] = {} if self . _image : rendered_job . update ({ \"image\" : self . _image . render ()}) if self . _needs : need_jobs : List [ Job ] = list () rendered_needs : List [ Dict [ str , Union [ str , bool ]]] = list () for need in self . _needs : if isinstance ( need , Job ): need_jobs . append ( need ) elif isinstance ( need , JobSequence ): for job in need . last_jobs_executed : need_jobs . append ( job ) elif isinstance ( need , Need ): rendered_needs . append ( need . render ()) else : raise TypeError ( f \"Need '{need}' is of type {type(need)}.\" ) job_names : Set [ str ] = set () for job in need_jobs : job_names . update ( job . _get_all_instance_names ()) for name in job_names : rendered_needs . append ( Need ( name ) . render ()) # sort needs by the name of the referenced job rendered_needs = sorted ( rendered_needs , key = itemgetter ( \"job\" )) rendered_job . update ({ \"needs\" : rendered_needs }) rendered_job . update ({ \"stage\" : self . _stage , \"script\" : self . _scripts , }) if self . _variables : rendered_job [ \"variables\" ] = self . _variables if self . _rules : rendered_rules = [] for rule in self . _rules : rendered_rules . append ( rule . render ()) rendered_job . update ({ \"rules\" : rendered_rules }) if self . _artifacts_paths . keys (): rendered_job . update ({ \"artifacts\" : { \"paths\" : list ( self . _artifacts_paths . keys ()), }}) if self . _cache : rendered_job . update ({ \"cache\" : self . _cache . render ()}) if self . _tags . keys (): rendered_job [ \"tags\" ] = list ( self . _tags . keys ()) return rendered_job class TriggerStrategy ( Enum ): \"\"\"Class with static values for ``TriggerStrategy`` used together with :class:`gcip.core.job.TriggerJob`. To construct an object.\"\"\" DEPEND = \"depend\" class TriggerJob ( Job ): def __init__ ( self , * args : Any , name : Optional [ str ] = None , namespace : Optional [ str ] = None , project : Optional [ str ] = None , branch : Optional [ str ] = None , includes : Union [ Include , List [ Include ], None ] = None , strategy : Optional [ TriggerStrategy ] = None , ** kwargs : Mapping [ Any , Any ], ) -> None : \"\"\" Class to create a Gitlab CI Trigger. You can create either a \"Parent-child\" or a \"Multi-project\" pipeline trigger. Args: project (Optional[str]): Used to create Multi-project pipeline trigger, exclusive to ``includes`` given Gitlab project name. e.g 'team1/project1'. Defaults to None. branch (Optional[str]): If ``project`` is given, you can specify which branch of ``project`` to trigger. Defaults to None. includes (Optional[List[Include]]): Used to create Parent-child pipeline trigger, exclusiv to ``project``. Defaults to None. strategy (Optional[TriggerStrategy]): Strategy of how the job behaves from the upstream pipeline. If :class:`TriggerStrategy.DEPEND`, any triggered job failed this job failed as well. Defaults to None. Raises: ValueError: If ``project`` and ``includes`` is given at the same time. ValueError: There is a Gitlab CI limitation, in \"Parent-child\" pipelines it is only allowed to add max. three includes. \"\"\" if includes and project : raise ValueError (( \"You cannot specify 'include' and 'project' together. Either 'include' or 'project' is possible.\" )) if not includes and not project : raise ValueError ( \"Neither 'includes' nor 'project' is given.\" ) super () . __init__ ( name = name , namespace = namespace , script = \"none\" ) self . _project = project self . _branch = branch self . _strategy = strategy if not includes : self . _includes = None elif isinstance ( includes , Include ): self . _includes = [ includes ] elif isinstance ( includes , list ): if len ( includes ) > 3 : raise ValueError ( ( \"The length of 'includes' is limited to three.\" \"See https://docs.gitlab.com/ee/ci/parent_child_pipelines.html for more information.\" ) ) self . _includes = includes else : raise AttributeError ( \"script parameter must be of type string or list of strings\" ) def copy ( self ) -> TriggerJob : job_copy = TriggerJob ( name = \".\" , project = \".\" ) super () . _copy_into ( job_copy ) job_copy . _project = self . _project job_copy . _branch = self . _branch job_copy . _includes = self . _includes job_copy . _strategy = self . _strategy return job_copy def render ( self ) -> Dict [ Any , Any ]: rendered_job = super () . render () # remove unsupported keywords from TriggerJob rendered_job . pop ( \"script\" ) if \"image\" in rendered_job : rendered_job . pop ( \"image\" ) if \"tags\" in rendered_job : rendered_job . pop ( \"tags\" ) if \"artifacts\" in rendered_job : rendered_job . pop ( \"artifacts\" ) if \"cache\" in rendered_job : rendered_job . pop ( \"cache\" ) trigger : Dict [ str , Union [ str , List [ Dict [ str , str ]]]] = {} # Child pipelines if self . _includes : trigger . update ({ \"include\" : [ include . render () for include in self . _includes ], }) # Multiproject pipelines if self . _project : trigger . update ({ \"project\" : self . _project , }) if self . _branch : trigger . update ({ \"branch\" : self . _branch }) if self . _strategy : trigger . update ({ \"strategy\" : self . _strategy . value }) rendered_job = { \"trigger\" : trigger , ** rendered_job } return rendered_job Variables TYPE_CHECKING Classes Job class Job ( * args : 'Any' , script : 'Union[AnyStr, List[str]]' , name : 'Optional[str]' = None , namespace : 'Optional[str]' = None ) Attributes Name Type Description Default script None The script to be executed. None name None The name of the job. None View Source class Job () : \"\"\"Represents a Gitlab CI Job Attributes: script: The script to be executed. name: The name of the job. \"\"\" def __init__ ( self , * args : Any , script : Union [ AnyStr, List[str ] ] , name : Optional [ str ] = None , namespace : Optional [ str ] = None , ) : self . _stage = \"\" self . _name = \"\" self . _image : Optional [ Image ] = None self . _variables : Dict [ str, str ] = {} self . _tags : OrderedSetType = {} self . _rules : List [ Rule ] = [] self . _needs : List [ Union[Need, Job, JobSequence ] ] = [] self . _scripts : List [ str ] self . _artifacts_paths : OrderedSetType = {} self . _cache : Optional [ Cache ] = None self . _parents : List [ JobSequence ] = list () self . _original : Optional [ Job ] \"\"\"Only set if you get a :meth:`copy()` of this job\"\"\" if namespace and name : self . _name = f \"{namespace}-{name}\" self . _stage = namespace elif namespace : self . _name = namespace self . _stage = namespace elif name : self . _name = name # default for unset stages is 'test' -> https : // docs . gitlab . com / ee / ci / yaml / #stages self . _stage = \"test\" else : raise ValueError ( \"At least one of the parameters `name` or `namespace` have to be set.\" ) self . _name = self . _name . replace ( \"_\" , \"-\" ) self . _stage = self . _stage . replace ( \"-\" , \"_\" ) if isinstance ( script , str ) : self . _scripts = [ script ] elif isinstance ( script , list ) : self . _scripts = script else : raise AttributeError ( \"script parameter must be of type string or list of strings\" ) @property def name ( self ) -> str : return self . _name @property def stage ( self ) -> str : return self . _stage def _extend_name ( self , name : Optional [ str ] ) -> None : if name : self . _name += \"-\" + name . replace ( \"_\" , \"-\" ) def _extend_stage ( self , stage : Optional [ str ] ) -> None : if stage : self . _stage += \"_\" + stage . replace ( \"-\" , \"_\" ) def _extend_namespace ( self , namespace : Optional [ str ] ) -> None : if namespace : self . _extend_name ( namespace ) self . _extend_stage ( namespace ) def _add_parent ( self , parent : JobSequence ) -> None : self . _parents . append ( parent ) def prepend_scripts ( self , * scripts : str ) -> Job : self . _scripts = list ( scripts ) + self . _scripts return self def append_scripts ( self , * scripts : str ) -> Job : self . _scripts . extend ( scripts ) return self def add_variables ( self , ** variables : str ) -> Job : self . _variables . update ( variables ) return self def add_tags ( self , * tags : str ) -> Job : for tag in tags : self . _tags [ tag ] = None return self def add_artifacts_paths ( self , * paths : str ) -> Job : for path in paths : self . _artifacts_paths [ path ] = None return self def set_cache ( self , cache : Optional [ Cache ] ) -> Job : \"\"\"Sets the cache for the Job. Args: cache (Cache): Cache to use for this Job. Returns: JobSequence: Returns the modified :class:`Job` object. \"\"\" if cache : self . _cache = cache return self def append_rules ( self , * rules : Rule ) -> Job : self . _rules . extend ( rules ) return self def prepend_rules ( self , * rules : Rule ) -> Job : self . _rules = list ( rules ) + self . _rules return self def add_needs ( self , * needs : Union [ Need, Job, JobSequence ] ) -> Job : self . _needs . extend ( needs ) return self def set_image ( self , image : Optional [ Union[Image, str ] ] ) -> Job : \"\"\"Sets the image of this job. For a simple container image you can provide the origin of the image. If you want to set the entrypoint, you have to provide an Image object instead. Args: image (Optional[Union[Image, str]]): Can be either `string` or `Image`. Returns: Job: Returns the modified :class:`Job` object. \"\"\" if image : if isinstance ( image , str ) : image = Image ( image ) self . _image = image return self def _get_all_instance_names ( self ) -> Set [ str ] : instance_names : Set [ str ] = set () for parent in self . _parents : for postfix in parent . _get_all_instance_names ( self ) : if postfix : instance_names . add ( f \"{self._name}-{postfix}\" . replace ( \"-#unset#\" , \"\" )) else : instance_names . add ( self . _name ) return instance_names def copy ( self ) -> Job : return self . _copy_into ( Job ( name = \".\" , script = copy . deepcopy ( self . _scripts ))) def _copy_into ( self , job : Job ) -> Job : job . _original = self job . _name = self . _name job . _stage = self . _stage job . set_image ( self . _image ) job . add_variables ( ** copy . deepcopy ( self . _variables )) job . add_tags ( * list ( self . _tags . keys ())) job . add_artifacts_paths ( * list ( self . _artifacts_paths . keys ())) job . set_cache ( self . _cache ) job . append_rules ( * self . _rules ) job . add_needs ( * self . _needs ) job . _parents = self . _parents . copy () return job def render ( self ) -> Dict [ str, Any ] : from . job_sequence import \\ JobSequence # late import to avoid circular dependencies rendered_job : Dict [ str, Any ] = {} if self . _image : rendered_job . update ( { \"image\" : self . _image . render () } ) if self . _needs : need_jobs : List [ Job ] = list () rendered_needs : List [ Dict[str, Union[str, bool ] ]] = list () for need in self . _needs : if isinstance ( need , Job ) : need_jobs . append ( need ) elif isinstance ( need , JobSequence ) : for job in need . last_jobs_executed : need_jobs . append ( job ) elif isinstance ( need , Need ) : rendered_needs . append ( need . render ()) else : raise TypeError ( f \"Need '{need}' is of type {type(need)}.\" ) job_names : Set [ str ] = set () for job in need_jobs : job_names . update ( job . _get_all_instance_names ()) for name in job_names : rendered_needs . append ( Need ( name ). render ()) # sort needs by the name of the referenced job rendered_needs = sorted ( rendered_needs , key = itemgetter ( \"job\" )) rendered_job . update ( { \"needs\" : rendered_needs } ) rendered_job . update ( { \"stage\" : self . _stage , \"script\" : self . _scripts , } ) if self . _variables : rendered_job [ \"variables\" ] = self . _variables if self . _rules : rendered_rules = [] for rule in self . _rules : rendered_rules . append ( rule . render ()) rendered_job . update ( { \"rules\" : rendered_rules } ) if self . _artifacts_paths . keys () : rendered_job . update ( { \"artifacts\" : { \"paths\" : list ( self . _artifacts_paths . keys ()), }} ) if self . _cache : rendered_job . update ( { \"cache\" : self . _cache . render () } ) if self . _tags . keys () : rendered_job [ \"tags\" ] = list ( self . _tags . keys ()) return rendered_job Descendants gcip.core.job.TriggerJob Instance variables name stage Methods add_artifacts_paths def add_artifacts_paths ( self , * paths : 'str' ) -> 'Job' View Source def add_artifacts_paths ( self , * paths : str ) -> Job : for path in paths : self . _artifacts_paths [ path ] = None return self add_needs def add_needs ( self , * needs : 'Union[Need, Job, JobSequence]' ) -> 'Job' View Source def add_needs ( self , * needs : Union [ Need , Job , JobSequence ]) -> Job : self . _needs . extend ( needs ) return self add_tags def add_tags ( self , * tags : 'str' ) -> 'Job' View Source def add_tags ( self , * tags : str ) -> Job : for tag in tags : self . _tags [ tag ] = None return self add_variables def add_variables ( self , ** variables : 'str' ) -> 'Job' View Source def add_variables ( self , ** variables : str ) -> Job : self . _variables . update ( variables ) return self append_rules def append_rules ( self , * rules : 'Rule' ) -> 'Job' View Source def append_rules ( self , * rules : Rule ) -> Job : self . _rules . extend ( rules ) return self append_scripts def append_scripts ( self , * scripts : 'str' ) -> 'Job' View Source def append_scripts ( self , * scripts : str ) -> Job : self . _scripts . extend ( scripts ) return self copy def copy ( self ) -> 'Job' View Source def copy ( self ) -> Job : return self . _copy_into ( Job ( name = \".\" , script = copy . deepcopy ( self . _scripts ))) prepend_rules def prepend_rules ( self , * rules : 'Rule' ) -> 'Job' View Source def prepend_rules ( self , * rules : Rule ) -> Job : self . _rules = list ( rules ) + self . _rules return self prepend_scripts def prepend_scripts ( self , * scripts : 'str' ) -> 'Job' View Source def prepend_scripts ( self , * scripts : str ) -> Job : self . _scripts = list ( scripts ) + self . _scripts return self render def render ( self ) -> 'Dict[str, Any]' View Source def render ( self ) -> Dict [ str , Any ]: from .job_sequence import \\ JobSequence # late import to avoid circular dependencies rendered_job : Dict [ str , Any ] = {} if self . _image : rendered_job . update ({ \"image\" : self . _image . render ()}) if self . _needs : need_jobs : List [ Job ] = list () rendered_needs : List [ Dict [ str , Union [ str , bool ]]] = list () for need in self . _needs : if isinstance ( need , Job ): need_jobs . append ( need ) elif isinstance ( need , JobSequence ): for job in need . last_jobs_executed : need_jobs . append ( job ) elif isinstance ( need , Need ): rendered_needs . append ( need . render ()) else : raise TypeError ( f \"Need '{need}' is of type {type(need)}.\" ) job_names : Set [ str ] = set () for job in need_jobs : job_names . update ( job . _get_all_instance_names ()) for name in job_names : rendered_needs . append ( Need ( name ) . render ()) # sort needs by the name of the referenced job rendered_needs = sorted ( rendered_needs , key = itemgetter ( \"job\" )) rendered_job . update ({ \"needs\" : rendered_needs }) rendered_job . update ({ \"stage\" : self . _stage , \"script\" : self . _scripts , }) if self . _variables : rendered_job [ \"variables\" ] = self . _variables if self . _rules : rendered_rules = [] for rule in self . _rules : rendered_rules . append ( rule . render ()) rendered_job . update ({ \"rules\" : rendered_rules }) if self . _artifacts_paths . keys (): rendered_job . update ({ \"artifacts\" : { \"paths\" : list ( self . _artifacts_paths . keys ()), }}) if self . _cache : rendered_job . update ({ \"cache\" : self . _cache . render ()}) if self . _tags . keys (): rendered_job [ \"tags\" ] = list ( self . _tags . keys ()) return rendered_job set_cache def set_cache ( self , cache : 'Optional[Cache]' ) -> 'Job' Sets the cache for the Job. Parameters: Name Type Description Default cache Cache Cache to use for this Job. None Returns: Type Description JobSequence Returns the modified :class: Job object. View Source def set _cache ( self , cache : Optional [ Cache ] ) -> Job : \" \"\" Sets the cache for the Job. Args: cache (Cache): Cache to use for this Job. Returns: JobSequence: Returns the modified :class:`Job` object. \"\" \" if cache : self . _cache = cache return self set_image def set_image ( self , image : 'Optional[Union[Image, str]]' ) -> 'Job' Sets the image of this job. For a simple container image you can provide the origin of the image. If you want to set the entrypoint, you have to provide an Image object instead. Parameters: Name Type Description Default image Optional[Union[Image, str]] Can be either string or Image . None Returns: Type Description Job Returns the modified :class: Job object. View Source def set _image ( self , image : Optional [ Union [ Image , str ]] ) -> Job : \" \"\" Sets the image of this job. For a simple container image you can provide the origin of the image. If you want to set the entrypoint, you have to provide an Image object instead. Args: image (Optional[Union[Image, str]]): Can be either `string` or `Image`. Returns: Job: Returns the modified :class:`Job` object. \"\" \" if image : if isinstance ( image , str ) : image = Image ( image ) self . _image = image return self TriggerJob class TriggerJob ( * args : 'Any' , name : 'Optional[str]' = None , namespace : 'Optional[str]' = None , project : 'Optional[str]' = None , branch : 'Optional[str]' = None , includes : 'Union[Include, List[Include], None]' = None , strategy : 'Optional[TriggerStrategy]' = None , ** kwargs : 'Mapping[Any, Any]' ) Attributes Name Type Description Default script None The script to be executed. None name None The name of the job. None View Source class TriggerJob ( Job ) : def __init__ ( self , * args : Any , name : Optional [ str ] = None , namespace : Optional [ str ] = None , project : Optional [ str ] = None , branch : Optional [ str ] = None , includes : Union [ Include, List[Include ] , None ] = None , strategy : Optional [ TriggerStrategy ] = None , ** kwargs : Mapping [ Any, Any ] , ) -> None : \"\"\" Class to create a Gitlab CI Trigger. You can create either a \" Parent - child \" or a \" Multi - project \" pipeline trigger. Args: project (Optional[str]): Used to create Multi-project pipeline trigger, exclusive to ``includes`` given Gitlab project name. e.g 'team1/project1'. Defaults to None. branch (Optional[str]): If ``project`` is given, you can specify which branch of ``project`` to trigger. Defaults to None. includes (Optional[List[Include]]): Used to create Parent-child pipeline trigger, exclusiv to ``project``. Defaults to None. strategy (Optional[TriggerStrategy]): Strategy of how the job behaves from the upstream pipeline. If :class:`TriggerStrategy.DEPEND`, any triggered job failed this job failed as well. Defaults to None. Raises: ValueError: If ``project`` and ``includes`` is given at the same time. ValueError: There is a Gitlab CI limitation, in \" Parent - child \" pipelines it is only allowed to add max. three includes. \"\"\" if includes and project : raise ValueError (( \"You cannot specify 'include' and 'project' together. Either 'include' or 'project' is possible.\" )) if not includes and not project : raise ValueError ( \"Neither 'includes' nor 'project' is given.\" ) super (). __init__ ( name = name , namespace = namespace , script = \"none\" ) self . _project = project self . _branch = branch self . _strategy = strategy if not includes : self . _includes = None elif isinstance ( includes , Include ) : self . _includes = [ includes ] elif isinstance ( includes , list ) : if len ( includes ) > 3 : raise ValueError ( ( \"The length of 'includes' is limited to three.\" \"See https://docs.gitlab.com/ee/ci/parent_child_pipelines.html for more information.\" ) ) self . _includes = includes else : raise AttributeError ( \"script parameter must be of type string or list of strings\" ) def copy ( self ) -> TriggerJob : job_copy = TriggerJob ( name = \".\" , project = \".\" ) super (). _copy_into ( job_copy ) job_copy . _project = self . _project job_copy . _branch = self . _branch job_copy . _includes = self . _includes job_copy . _strategy = self . _strategy return job_copy def render ( self ) -> Dict [ Any, Any ] : rendered_job = super (). render () # remove unsupported keywords from TriggerJob rendered_job . pop ( \"script\" ) if \"image\" in rendered_job : rendered_job . pop ( \"image\" ) if \"tags\" in rendered_job : rendered_job . pop ( \"tags\" ) if \"artifacts\" in rendered_job : rendered_job . pop ( \"artifacts\" ) if \"cache\" in rendered_job : rendered_job . pop ( \"cache\" ) trigger : Dict [ str, Union[str, List[Dict[str, str ] ]]] = {} # Child pipelines if self . _includes : trigger . update ( { \"include\" : [ include.render() for include in self._includes ] , } ) # Multiproject pipelines if self . _project : trigger . update ( { \"project\" : self . _project , } ) if self . _branch : trigger . update ( { \"branch\" : self . _branch } ) if self . _strategy : trigger . update ( { \"strategy\" : self . _strategy . value } ) rendered_job = { \"trigger\" : trigger , ** rendered_job } return rendered_job Ancestors (in MRO) gcip.core.job.Job Instance variables name stage Methods add_artifacts_paths def add_artifacts_paths ( self , * paths : 'str' ) -> 'Job' View Source def add_artifacts_paths ( self , * paths : str ) -> Job : for path in paths : self . _artifacts_paths [ path ] = None return self add_needs def add_needs ( self , * needs : 'Union[Need, Job, JobSequence]' ) -> 'Job' View Source def add_needs ( self , * needs : Union [ Need , Job , JobSequence ]) -> Job : self . _needs . extend ( needs ) return self add_tags def add_tags ( self , * tags : 'str' ) -> 'Job' View Source def add_tags ( self , * tags : str ) -> Job : for tag in tags : self . _tags [ tag ] = None return self add_variables def add_variables ( self , ** variables : 'str' ) -> 'Job' View Source def add_variables ( self , ** variables : str ) -> Job : self . _variables . update ( variables ) return self append_rules def append_rules ( self , * rules : 'Rule' ) -> 'Job' View Source def append_rules ( self , * rules : Rule ) -> Job : self . _rules . extend ( rules ) return self append_scripts def append_scripts ( self , * scripts : 'str' ) -> 'Job' View Source def append_scripts ( self , * scripts : str ) -> Job : self . _scripts . extend ( scripts ) return self copy def copy ( self ) -> 'TriggerJob' View Source def copy ( self ) -> TriggerJob : job_copy = TriggerJob ( name = \".\" , project = \".\" ) super (). _copy_into ( job_copy ) job_copy . _project = self . _project job_copy . _branch = self . _branch job_copy . _includes = self . _includes job_copy . _strategy = self . _strategy return job_copy prepend_rules def prepend_rules ( self , * rules : 'Rule' ) -> 'Job' View Source def prepend_rules ( self , * rules : Rule ) -> Job : self . _rules = list ( rules ) + self . _rules return self prepend_scripts def prepend_scripts ( self , * scripts : 'str' ) -> 'Job' View Source def prepend_scripts ( self , * scripts : str ) -> Job : self . _scripts = list ( scripts ) + self . _scripts return self render def render ( self ) -> 'Dict[Any, Any]' View Source def render ( self ) -> Dict [ Any , Any ]: rendered_job = super (). render () # remove unsupported keywords from TriggerJob rendered_job . pop ( \"script\" ) if \"image\" in rendered_job : rendered_job . pop ( \"image\" ) if \"tags\" in rendered_job : rendered_job . pop ( \"tags\" ) if \"artifacts\" in rendered_job : rendered_job . pop ( \"artifacts\" ) if \"cache\" in rendered_job : rendered_job . pop ( \"cache\" ) trigger : Dict [ str , Union [ str , List [ Dict [ str , str ]]]] = {} # Child pipelines if self . _includes : trigger . update ( { \"include\" : [ include . render () for include in self . _includes ], } ) # Multiproject pipelines if self . _project : trigger . update ( { \"project\" : self . _project , } ) if self . _branch : trigger . update ( { \"branch\" : self . _branch } ) if self . _strategy : trigger . update ( { \"strategy\" : self . _strategy . value } ) rendered_job = { \"trigger\" : trigger , ** rendered_job } return rendered_job set_cache def set_cache ( self , cache : 'Optional[Cache]' ) -> 'Job' Sets the cache for the Job. Parameters: Name Type Description Default cache Cache Cache to use for this Job. None Returns: Type Description JobSequence Returns the modified :class: Job object. View Source def set _cache ( self , cache : Optional [ Cache ] ) -> Job : \" \"\" Sets the cache for the Job. Args: cache (Cache): Cache to use for this Job. Returns: JobSequence: Returns the modified :class:`Job` object. \"\" \" if cache : self . _cache = cache return self set_image def set_image ( self , image : 'Optional[Union[Image, str]]' ) -> 'Job' Sets the image of this job. For a simple container image you can provide the origin of the image. If you want to set the entrypoint, you have to provide an Image object instead. Parameters: Name Type Description Default image Optional[Union[Image, str]] Can be either string or Image . None Returns: Type Description Job Returns the modified :class: Job object. View Source def set _image ( self , image : Optional [ Union [ Image , str ]] ) -> Job : \" \"\" Sets the image of this job. For a simple container image you can provide the origin of the image. If you want to set the entrypoint, you have to provide an Image object instead. Args: image (Optional[Union[Image, str]]): Can be either `string` or `Image`. Returns: Job: Returns the modified :class:`Job` object. \"\" \" if image : if isinstance ( image , str ) : image = Image ( image ) self . _image = image return self TriggerStrategy class TriggerStrategy ( / , * args , ** kwargs ) View Source class TriggerStrategy ( Enum ) : \" \"\" Class with static values for ``TriggerStrategy`` used together with :class:`gcip.core.job.TriggerJob`. To construct an object. \"\" \" DEPEND = \"depend\" Ancestors (in MRO) enum.Enum Class variables DEPEND name value","title":"Job"},{"location":"reference/gcip/core/job/#module-gcipcorejob","text":"Testdocumentation for job View Source \"\"\"Testdocumentation for job \"\"\" from __future__ import annotations import copy from enum import Enum from typing import ( TYPE_CHECKING , Any , Set , Dict , List , Union , AnyStr , Mapping , Optional , ) from operator import itemgetter from . import OrderedSetType from .need import Need from .rule import Rule from .cache import Cache from .image import Image from .include import Include if TYPE_CHECKING : from .job_sequence import JobSequence __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' class Job (): \"\"\"Represents a Gitlab CI Job Attributes: script: The script to be executed. name: The name of the job. \"\"\" def __init__ ( self , * args : Any , script : Union [ AnyStr , List [ str ]], name : Optional [ str ] = None , namespace : Optional [ str ] = None , ): self . _stage = \"\" self . _name = \"\" self . _image : Optional [ Image ] = None self . _variables : Dict [ str , str ] = {} self . _tags : OrderedSetType = {} self . _rules : List [ Rule ] = [] self . _needs : List [ Union [ Need , Job , JobSequence ]] = [] self . _scripts : List [ str ] self . _artifacts_paths : OrderedSetType = {} self . _cache : Optional [ Cache ] = None self . _parents : List [ JobSequence ] = list () self . _original : Optional [ Job ] \"\"\"Only set if you get a :meth:`copy()` of this job\"\"\" if namespace and name : self . _name = f \"{namespace}-{name}\" self . _stage = namespace elif namespace : self . _name = namespace self . _stage = namespace elif name : self . _name = name # default for unset stages is 'test' -> https://docs.gitlab.com/ee/ci/yaml/#stages self . _stage = \"test\" else : raise ValueError ( \"At least one of the parameters `name` or `namespace` have to be set.\" ) self . _name = self . _name . replace ( \"_\" , \"-\" ) self . _stage = self . _stage . replace ( \"-\" , \"_\" ) if isinstance ( script , str ): self . _scripts = [ script ] elif isinstance ( script , list ): self . _scripts = script else : raise AttributeError ( \"script parameter must be of type string or list of strings\" ) @property def name ( self ) -> str : return self . _name @property def stage ( self ) -> str : return self . _stage def _extend_name ( self , name : Optional [ str ]) -> None : if name : self . _name += \"-\" + name . replace ( \"_\" , \"-\" ) def _extend_stage ( self , stage : Optional [ str ]) -> None : if stage : self . _stage += \"_\" + stage . replace ( \"-\" , \"_\" ) def _extend_namespace ( self , namespace : Optional [ str ]) -> None : if namespace : self . _extend_name ( namespace ) self . _extend_stage ( namespace ) def _add_parent ( self , parent : JobSequence ) -> None : self . _parents . append ( parent ) def prepend_scripts ( self , * scripts : str ) -> Job : self . _scripts = list ( scripts ) + self . _scripts return self def append_scripts ( self , * scripts : str ) -> Job : self . _scripts . extend ( scripts ) return self def add_variables ( self , ** variables : str ) -> Job : self . _variables . update ( variables ) return self def add_tags ( self , * tags : str ) -> Job : for tag in tags : self . _tags [ tag ] = None return self def add_artifacts_paths ( self , * paths : str ) -> Job : for path in paths : self . _artifacts_paths [ path ] = None return self def set_cache ( self , cache : Optional [ Cache ]) -> Job : \"\"\"Sets the cache for the Job. Args: cache (Cache): Cache to use for this Job. Returns: JobSequence: Returns the modified :class:`Job` object. \"\"\" if cache : self . _cache = cache return self def append_rules ( self , * rules : Rule ) -> Job : self . _rules . extend ( rules ) return self def prepend_rules ( self , * rules : Rule ) -> Job : self . _rules = list ( rules ) + self . _rules return self def add_needs ( self , * needs : Union [ Need , Job , JobSequence ]) -> Job : self . _needs . extend ( needs ) return self def set_image ( self , image : Optional [ Union [ Image , str ]]) -> Job : \"\"\"Sets the image of this job. For a simple container image you can provide the origin of the image. If you want to set the entrypoint, you have to provide an Image object instead. Args: image (Optional[Union[Image, str]]): Can be either `string` or `Image`. Returns: Job: Returns the modified :class:`Job` object. \"\"\" if image : if isinstance ( image , str ): image = Image ( image ) self . _image = image return self def _get_all_instance_names ( self ) -> Set [ str ]: instance_names : Set [ str ] = set () for parent in self . _parents : for postfix in parent . _get_all_instance_names ( self ): if postfix : instance_names . add ( f \"{self._name}-{postfix}\" . replace ( \"-#unset#\" , \"\" )) else : instance_names . add ( self . _name ) return instance_names def copy ( self ) -> Job : return self . _copy_into ( Job ( name = \".\" , script = copy . deepcopy ( self . _scripts ))) def _copy_into ( self , job : Job ) -> Job : job . _original = self job . _name = self . _name job . _stage = self . _stage job . set_image ( self . _image ) job . add_variables ( ** copy . deepcopy ( self . _variables )) job . add_tags ( * list ( self . _tags . keys ())) job . add_artifacts_paths ( * list ( self . _artifacts_paths . keys ())) job . set_cache ( self . _cache ) job . append_rules ( * self . _rules ) job . add_needs ( * self . _needs ) job . _parents = self . _parents . copy () return job def render ( self ) -> Dict [ str , Any ]: from .job_sequence import \\ JobSequence # late import to avoid circular dependencies rendered_job : Dict [ str , Any ] = {} if self . _image : rendered_job . update ({ \"image\" : self . _image . render ()}) if self . _needs : need_jobs : List [ Job ] = list () rendered_needs : List [ Dict [ str , Union [ str , bool ]]] = list () for need in self . _needs : if isinstance ( need , Job ): need_jobs . append ( need ) elif isinstance ( need , JobSequence ): for job in need . last_jobs_executed : need_jobs . append ( job ) elif isinstance ( need , Need ): rendered_needs . append ( need . render ()) else : raise TypeError ( f \"Need '{need}' is of type {type(need)}.\" ) job_names : Set [ str ] = set () for job in need_jobs : job_names . update ( job . _get_all_instance_names ()) for name in job_names : rendered_needs . append ( Need ( name ) . render ()) # sort needs by the name of the referenced job rendered_needs = sorted ( rendered_needs , key = itemgetter ( \"job\" )) rendered_job . update ({ \"needs\" : rendered_needs }) rendered_job . update ({ \"stage\" : self . _stage , \"script\" : self . _scripts , }) if self . _variables : rendered_job [ \"variables\" ] = self . _variables if self . _rules : rendered_rules = [] for rule in self . _rules : rendered_rules . append ( rule . render ()) rendered_job . update ({ \"rules\" : rendered_rules }) if self . _artifacts_paths . keys (): rendered_job . update ({ \"artifacts\" : { \"paths\" : list ( self . _artifacts_paths . keys ()), }}) if self . _cache : rendered_job . update ({ \"cache\" : self . _cache . render ()}) if self . _tags . keys (): rendered_job [ \"tags\" ] = list ( self . _tags . keys ()) return rendered_job class TriggerStrategy ( Enum ): \"\"\"Class with static values for ``TriggerStrategy`` used together with :class:`gcip.core.job.TriggerJob`. To construct an object.\"\"\" DEPEND = \"depend\" class TriggerJob ( Job ): def __init__ ( self , * args : Any , name : Optional [ str ] = None , namespace : Optional [ str ] = None , project : Optional [ str ] = None , branch : Optional [ str ] = None , includes : Union [ Include , List [ Include ], None ] = None , strategy : Optional [ TriggerStrategy ] = None , ** kwargs : Mapping [ Any , Any ], ) -> None : \"\"\" Class to create a Gitlab CI Trigger. You can create either a \"Parent-child\" or a \"Multi-project\" pipeline trigger. Args: project (Optional[str]): Used to create Multi-project pipeline trigger, exclusive to ``includes`` given Gitlab project name. e.g 'team1/project1'. Defaults to None. branch (Optional[str]): If ``project`` is given, you can specify which branch of ``project`` to trigger. Defaults to None. includes (Optional[List[Include]]): Used to create Parent-child pipeline trigger, exclusiv to ``project``. Defaults to None. strategy (Optional[TriggerStrategy]): Strategy of how the job behaves from the upstream pipeline. If :class:`TriggerStrategy.DEPEND`, any triggered job failed this job failed as well. Defaults to None. Raises: ValueError: If ``project`` and ``includes`` is given at the same time. ValueError: There is a Gitlab CI limitation, in \"Parent-child\" pipelines it is only allowed to add max. three includes. \"\"\" if includes and project : raise ValueError (( \"You cannot specify 'include' and 'project' together. Either 'include' or 'project' is possible.\" )) if not includes and not project : raise ValueError ( \"Neither 'includes' nor 'project' is given.\" ) super () . __init__ ( name = name , namespace = namespace , script = \"none\" ) self . _project = project self . _branch = branch self . _strategy = strategy if not includes : self . _includes = None elif isinstance ( includes , Include ): self . _includes = [ includes ] elif isinstance ( includes , list ): if len ( includes ) > 3 : raise ValueError ( ( \"The length of 'includes' is limited to three.\" \"See https://docs.gitlab.com/ee/ci/parent_child_pipelines.html for more information.\" ) ) self . _includes = includes else : raise AttributeError ( \"script parameter must be of type string or list of strings\" ) def copy ( self ) -> TriggerJob : job_copy = TriggerJob ( name = \".\" , project = \".\" ) super () . _copy_into ( job_copy ) job_copy . _project = self . _project job_copy . _branch = self . _branch job_copy . _includes = self . _includes job_copy . _strategy = self . _strategy return job_copy def render ( self ) -> Dict [ Any , Any ]: rendered_job = super () . render () # remove unsupported keywords from TriggerJob rendered_job . pop ( \"script\" ) if \"image\" in rendered_job : rendered_job . pop ( \"image\" ) if \"tags\" in rendered_job : rendered_job . pop ( \"tags\" ) if \"artifacts\" in rendered_job : rendered_job . pop ( \"artifacts\" ) if \"cache\" in rendered_job : rendered_job . pop ( \"cache\" ) trigger : Dict [ str , Union [ str , List [ Dict [ str , str ]]]] = {} # Child pipelines if self . _includes : trigger . update ({ \"include\" : [ include . render () for include in self . _includes ], }) # Multiproject pipelines if self . _project : trigger . update ({ \"project\" : self . _project , }) if self . _branch : trigger . update ({ \"branch\" : self . _branch }) if self . _strategy : trigger . update ({ \"strategy\" : self . _strategy . value }) rendered_job = { \"trigger\" : trigger , ** rendered_job } return rendered_job","title":"Module gcip.core.job"},{"location":"reference/gcip/core/job/#variables","text":"TYPE_CHECKING","title":"Variables"},{"location":"reference/gcip/core/job/#classes","text":"","title":"Classes"},{"location":"reference/gcip/core/job/#job","text":"class Job ( * args : 'Any' , script : 'Union[AnyStr, List[str]]' , name : 'Optional[str]' = None , namespace : 'Optional[str]' = None )","title":"Job"},{"location":"reference/gcip/core/job/#attributes","text":"Name Type Description Default script None The script to be executed. None name None The name of the job. None View Source class Job () : \"\"\"Represents a Gitlab CI Job Attributes: script: The script to be executed. name: The name of the job. \"\"\" def __init__ ( self , * args : Any , script : Union [ AnyStr, List[str ] ] , name : Optional [ str ] = None , namespace : Optional [ str ] = None , ) : self . _stage = \"\" self . _name = \"\" self . _image : Optional [ Image ] = None self . _variables : Dict [ str, str ] = {} self . _tags : OrderedSetType = {} self . _rules : List [ Rule ] = [] self . _needs : List [ Union[Need, Job, JobSequence ] ] = [] self . _scripts : List [ str ] self . _artifacts_paths : OrderedSetType = {} self . _cache : Optional [ Cache ] = None self . _parents : List [ JobSequence ] = list () self . _original : Optional [ Job ] \"\"\"Only set if you get a :meth:`copy()` of this job\"\"\" if namespace and name : self . _name = f \"{namespace}-{name}\" self . _stage = namespace elif namespace : self . _name = namespace self . _stage = namespace elif name : self . _name = name # default for unset stages is 'test' -> https : // docs . gitlab . com / ee / ci / yaml / #stages self . _stage = \"test\" else : raise ValueError ( \"At least one of the parameters `name` or `namespace` have to be set.\" ) self . _name = self . _name . replace ( \"_\" , \"-\" ) self . _stage = self . _stage . replace ( \"-\" , \"_\" ) if isinstance ( script , str ) : self . _scripts = [ script ] elif isinstance ( script , list ) : self . _scripts = script else : raise AttributeError ( \"script parameter must be of type string or list of strings\" ) @property def name ( self ) -> str : return self . _name @property def stage ( self ) -> str : return self . _stage def _extend_name ( self , name : Optional [ str ] ) -> None : if name : self . _name += \"-\" + name . replace ( \"_\" , \"-\" ) def _extend_stage ( self , stage : Optional [ str ] ) -> None : if stage : self . _stage += \"_\" + stage . replace ( \"-\" , \"_\" ) def _extend_namespace ( self , namespace : Optional [ str ] ) -> None : if namespace : self . _extend_name ( namespace ) self . _extend_stage ( namespace ) def _add_parent ( self , parent : JobSequence ) -> None : self . _parents . append ( parent ) def prepend_scripts ( self , * scripts : str ) -> Job : self . _scripts = list ( scripts ) + self . _scripts return self def append_scripts ( self , * scripts : str ) -> Job : self . _scripts . extend ( scripts ) return self def add_variables ( self , ** variables : str ) -> Job : self . _variables . update ( variables ) return self def add_tags ( self , * tags : str ) -> Job : for tag in tags : self . _tags [ tag ] = None return self def add_artifacts_paths ( self , * paths : str ) -> Job : for path in paths : self . _artifacts_paths [ path ] = None return self def set_cache ( self , cache : Optional [ Cache ] ) -> Job : \"\"\"Sets the cache for the Job. Args: cache (Cache): Cache to use for this Job. Returns: JobSequence: Returns the modified :class:`Job` object. \"\"\" if cache : self . _cache = cache return self def append_rules ( self , * rules : Rule ) -> Job : self . _rules . extend ( rules ) return self def prepend_rules ( self , * rules : Rule ) -> Job : self . _rules = list ( rules ) + self . _rules return self def add_needs ( self , * needs : Union [ Need, Job, JobSequence ] ) -> Job : self . _needs . extend ( needs ) return self def set_image ( self , image : Optional [ Union[Image, str ] ] ) -> Job : \"\"\"Sets the image of this job. For a simple container image you can provide the origin of the image. If you want to set the entrypoint, you have to provide an Image object instead. Args: image (Optional[Union[Image, str]]): Can be either `string` or `Image`. Returns: Job: Returns the modified :class:`Job` object. \"\"\" if image : if isinstance ( image , str ) : image = Image ( image ) self . _image = image return self def _get_all_instance_names ( self ) -> Set [ str ] : instance_names : Set [ str ] = set () for parent in self . _parents : for postfix in parent . _get_all_instance_names ( self ) : if postfix : instance_names . add ( f \"{self._name}-{postfix}\" . replace ( \"-#unset#\" , \"\" )) else : instance_names . add ( self . _name ) return instance_names def copy ( self ) -> Job : return self . _copy_into ( Job ( name = \".\" , script = copy . deepcopy ( self . _scripts ))) def _copy_into ( self , job : Job ) -> Job : job . _original = self job . _name = self . _name job . _stage = self . _stage job . set_image ( self . _image ) job . add_variables ( ** copy . deepcopy ( self . _variables )) job . add_tags ( * list ( self . _tags . keys ())) job . add_artifacts_paths ( * list ( self . _artifacts_paths . keys ())) job . set_cache ( self . _cache ) job . append_rules ( * self . _rules ) job . add_needs ( * self . _needs ) job . _parents = self . _parents . copy () return job def render ( self ) -> Dict [ str, Any ] : from . job_sequence import \\ JobSequence # late import to avoid circular dependencies rendered_job : Dict [ str, Any ] = {} if self . _image : rendered_job . update ( { \"image\" : self . _image . render () } ) if self . _needs : need_jobs : List [ Job ] = list () rendered_needs : List [ Dict[str, Union[str, bool ] ]] = list () for need in self . _needs : if isinstance ( need , Job ) : need_jobs . append ( need ) elif isinstance ( need , JobSequence ) : for job in need . last_jobs_executed : need_jobs . append ( job ) elif isinstance ( need , Need ) : rendered_needs . append ( need . render ()) else : raise TypeError ( f \"Need '{need}' is of type {type(need)}.\" ) job_names : Set [ str ] = set () for job in need_jobs : job_names . update ( job . _get_all_instance_names ()) for name in job_names : rendered_needs . append ( Need ( name ). render ()) # sort needs by the name of the referenced job rendered_needs = sorted ( rendered_needs , key = itemgetter ( \"job\" )) rendered_job . update ( { \"needs\" : rendered_needs } ) rendered_job . update ( { \"stage\" : self . _stage , \"script\" : self . _scripts , } ) if self . _variables : rendered_job [ \"variables\" ] = self . _variables if self . _rules : rendered_rules = [] for rule in self . _rules : rendered_rules . append ( rule . render ()) rendered_job . update ( { \"rules\" : rendered_rules } ) if self . _artifacts_paths . keys () : rendered_job . update ( { \"artifacts\" : { \"paths\" : list ( self . _artifacts_paths . keys ()), }} ) if self . _cache : rendered_job . update ( { \"cache\" : self . _cache . render () } ) if self . _tags . keys () : rendered_job [ \"tags\" ] = list ( self . _tags . keys ()) return rendered_job","title":"Attributes"},{"location":"reference/gcip/core/job/#descendants","text":"gcip.core.job.TriggerJob","title":"Descendants"},{"location":"reference/gcip/core/job/#instance-variables","text":"name stage","title":"Instance variables"},{"location":"reference/gcip/core/job/#methods","text":"","title":"Methods"},{"location":"reference/gcip/core/job/#add_artifacts_paths","text":"def add_artifacts_paths ( self , * paths : 'str' ) -> 'Job' View Source def add_artifacts_paths ( self , * paths : str ) -> Job : for path in paths : self . _artifacts_paths [ path ] = None return self","title":"add_artifacts_paths"},{"location":"reference/gcip/core/job/#add_needs","text":"def add_needs ( self , * needs : 'Union[Need, Job, JobSequence]' ) -> 'Job' View Source def add_needs ( self , * needs : Union [ Need , Job , JobSequence ]) -> Job : self . _needs . extend ( needs ) return self","title":"add_needs"},{"location":"reference/gcip/core/job/#add_tags","text":"def add_tags ( self , * tags : 'str' ) -> 'Job' View Source def add_tags ( self , * tags : str ) -> Job : for tag in tags : self . _tags [ tag ] = None return self","title":"add_tags"},{"location":"reference/gcip/core/job/#add_variables","text":"def add_variables ( self , ** variables : 'str' ) -> 'Job' View Source def add_variables ( self , ** variables : str ) -> Job : self . _variables . update ( variables ) return self","title":"add_variables"},{"location":"reference/gcip/core/job/#append_rules","text":"def append_rules ( self , * rules : 'Rule' ) -> 'Job' View Source def append_rules ( self , * rules : Rule ) -> Job : self . _rules . extend ( rules ) return self","title":"append_rules"},{"location":"reference/gcip/core/job/#append_scripts","text":"def append_scripts ( self , * scripts : 'str' ) -> 'Job' View Source def append_scripts ( self , * scripts : str ) -> Job : self . _scripts . extend ( scripts ) return self","title":"append_scripts"},{"location":"reference/gcip/core/job/#copy","text":"def copy ( self ) -> 'Job' View Source def copy ( self ) -> Job : return self . _copy_into ( Job ( name = \".\" , script = copy . deepcopy ( self . _scripts )))","title":"copy"},{"location":"reference/gcip/core/job/#prepend_rules","text":"def prepend_rules ( self , * rules : 'Rule' ) -> 'Job' View Source def prepend_rules ( self , * rules : Rule ) -> Job : self . _rules = list ( rules ) + self . _rules return self","title":"prepend_rules"},{"location":"reference/gcip/core/job/#prepend_scripts","text":"def prepend_scripts ( self , * scripts : 'str' ) -> 'Job' View Source def prepend_scripts ( self , * scripts : str ) -> Job : self . _scripts = list ( scripts ) + self . _scripts return self","title":"prepend_scripts"},{"location":"reference/gcip/core/job/#render","text":"def render ( self ) -> 'Dict[str, Any]' View Source def render ( self ) -> Dict [ str , Any ]: from .job_sequence import \\ JobSequence # late import to avoid circular dependencies rendered_job : Dict [ str , Any ] = {} if self . _image : rendered_job . update ({ \"image\" : self . _image . render ()}) if self . _needs : need_jobs : List [ Job ] = list () rendered_needs : List [ Dict [ str , Union [ str , bool ]]] = list () for need in self . _needs : if isinstance ( need , Job ): need_jobs . append ( need ) elif isinstance ( need , JobSequence ): for job in need . last_jobs_executed : need_jobs . append ( job ) elif isinstance ( need , Need ): rendered_needs . append ( need . render ()) else : raise TypeError ( f \"Need '{need}' is of type {type(need)}.\" ) job_names : Set [ str ] = set () for job in need_jobs : job_names . update ( job . _get_all_instance_names ()) for name in job_names : rendered_needs . append ( Need ( name ) . render ()) # sort needs by the name of the referenced job rendered_needs = sorted ( rendered_needs , key = itemgetter ( \"job\" )) rendered_job . update ({ \"needs\" : rendered_needs }) rendered_job . update ({ \"stage\" : self . _stage , \"script\" : self . _scripts , }) if self . _variables : rendered_job [ \"variables\" ] = self . _variables if self . _rules : rendered_rules = [] for rule in self . _rules : rendered_rules . append ( rule . render ()) rendered_job . update ({ \"rules\" : rendered_rules }) if self . _artifacts_paths . keys (): rendered_job . update ({ \"artifacts\" : { \"paths\" : list ( self . _artifacts_paths . keys ()), }}) if self . _cache : rendered_job . update ({ \"cache\" : self . _cache . render ()}) if self . _tags . keys (): rendered_job [ \"tags\" ] = list ( self . _tags . keys ()) return rendered_job","title":"render"},{"location":"reference/gcip/core/job/#set_cache","text":"def set_cache ( self , cache : 'Optional[Cache]' ) -> 'Job' Sets the cache for the Job. Parameters: Name Type Description Default cache Cache Cache to use for this Job. None Returns: Type Description JobSequence Returns the modified :class: Job object. View Source def set _cache ( self , cache : Optional [ Cache ] ) -> Job : \" \"\" Sets the cache for the Job. Args: cache (Cache): Cache to use for this Job. Returns: JobSequence: Returns the modified :class:`Job` object. \"\" \" if cache : self . _cache = cache return self","title":"set_cache"},{"location":"reference/gcip/core/job/#set_image","text":"def set_image ( self , image : 'Optional[Union[Image, str]]' ) -> 'Job' Sets the image of this job. For a simple container image you can provide the origin of the image. If you want to set the entrypoint, you have to provide an Image object instead. Parameters: Name Type Description Default image Optional[Union[Image, str]] Can be either string or Image . None Returns: Type Description Job Returns the modified :class: Job object. View Source def set _image ( self , image : Optional [ Union [ Image , str ]] ) -> Job : \" \"\" Sets the image of this job. For a simple container image you can provide the origin of the image. If you want to set the entrypoint, you have to provide an Image object instead. Args: image (Optional[Union[Image, str]]): Can be either `string` or `Image`. Returns: Job: Returns the modified :class:`Job` object. \"\" \" if image : if isinstance ( image , str ) : image = Image ( image ) self . _image = image return self","title":"set_image"},{"location":"reference/gcip/core/job/#triggerjob","text":"class TriggerJob ( * args : 'Any' , name : 'Optional[str]' = None , namespace : 'Optional[str]' = None , project : 'Optional[str]' = None , branch : 'Optional[str]' = None , includes : 'Union[Include, List[Include], None]' = None , strategy : 'Optional[TriggerStrategy]' = None , ** kwargs : 'Mapping[Any, Any]' )","title":"TriggerJob"},{"location":"reference/gcip/core/job/#attributes_1","text":"Name Type Description Default script None The script to be executed. None name None The name of the job. None View Source class TriggerJob ( Job ) : def __init__ ( self , * args : Any , name : Optional [ str ] = None , namespace : Optional [ str ] = None , project : Optional [ str ] = None , branch : Optional [ str ] = None , includes : Union [ Include, List[Include ] , None ] = None , strategy : Optional [ TriggerStrategy ] = None , ** kwargs : Mapping [ Any, Any ] , ) -> None : \"\"\" Class to create a Gitlab CI Trigger. You can create either a \" Parent - child \" or a \" Multi - project \" pipeline trigger. Args: project (Optional[str]): Used to create Multi-project pipeline trigger, exclusive to ``includes`` given Gitlab project name. e.g 'team1/project1'. Defaults to None. branch (Optional[str]): If ``project`` is given, you can specify which branch of ``project`` to trigger. Defaults to None. includes (Optional[List[Include]]): Used to create Parent-child pipeline trigger, exclusiv to ``project``. Defaults to None. strategy (Optional[TriggerStrategy]): Strategy of how the job behaves from the upstream pipeline. If :class:`TriggerStrategy.DEPEND`, any triggered job failed this job failed as well. Defaults to None. Raises: ValueError: If ``project`` and ``includes`` is given at the same time. ValueError: There is a Gitlab CI limitation, in \" Parent - child \" pipelines it is only allowed to add max. three includes. \"\"\" if includes and project : raise ValueError (( \"You cannot specify 'include' and 'project' together. Either 'include' or 'project' is possible.\" )) if not includes and not project : raise ValueError ( \"Neither 'includes' nor 'project' is given.\" ) super (). __init__ ( name = name , namespace = namespace , script = \"none\" ) self . _project = project self . _branch = branch self . _strategy = strategy if not includes : self . _includes = None elif isinstance ( includes , Include ) : self . _includes = [ includes ] elif isinstance ( includes , list ) : if len ( includes ) > 3 : raise ValueError ( ( \"The length of 'includes' is limited to three.\" \"See https://docs.gitlab.com/ee/ci/parent_child_pipelines.html for more information.\" ) ) self . _includes = includes else : raise AttributeError ( \"script parameter must be of type string or list of strings\" ) def copy ( self ) -> TriggerJob : job_copy = TriggerJob ( name = \".\" , project = \".\" ) super (). _copy_into ( job_copy ) job_copy . _project = self . _project job_copy . _branch = self . _branch job_copy . _includes = self . _includes job_copy . _strategy = self . _strategy return job_copy def render ( self ) -> Dict [ Any, Any ] : rendered_job = super (). render () # remove unsupported keywords from TriggerJob rendered_job . pop ( \"script\" ) if \"image\" in rendered_job : rendered_job . pop ( \"image\" ) if \"tags\" in rendered_job : rendered_job . pop ( \"tags\" ) if \"artifacts\" in rendered_job : rendered_job . pop ( \"artifacts\" ) if \"cache\" in rendered_job : rendered_job . pop ( \"cache\" ) trigger : Dict [ str, Union[str, List[Dict[str, str ] ]]] = {} # Child pipelines if self . _includes : trigger . update ( { \"include\" : [ include.render() for include in self._includes ] , } ) # Multiproject pipelines if self . _project : trigger . update ( { \"project\" : self . _project , } ) if self . _branch : trigger . update ( { \"branch\" : self . _branch } ) if self . _strategy : trigger . update ( { \"strategy\" : self . _strategy . value } ) rendered_job = { \"trigger\" : trigger , ** rendered_job } return rendered_job","title":"Attributes"},{"location":"reference/gcip/core/job/#ancestors-in-mro","text":"gcip.core.job.Job","title":"Ancestors (in MRO)"},{"location":"reference/gcip/core/job/#instance-variables_1","text":"name stage","title":"Instance variables"},{"location":"reference/gcip/core/job/#methods_1","text":"","title":"Methods"},{"location":"reference/gcip/core/job/#add_artifacts_paths_1","text":"def add_artifacts_paths ( self , * paths : 'str' ) -> 'Job' View Source def add_artifacts_paths ( self , * paths : str ) -> Job : for path in paths : self . _artifacts_paths [ path ] = None return self","title":"add_artifacts_paths"},{"location":"reference/gcip/core/job/#add_needs_1","text":"def add_needs ( self , * needs : 'Union[Need, Job, JobSequence]' ) -> 'Job' View Source def add_needs ( self , * needs : Union [ Need , Job , JobSequence ]) -> Job : self . _needs . extend ( needs ) return self","title":"add_needs"},{"location":"reference/gcip/core/job/#add_tags_1","text":"def add_tags ( self , * tags : 'str' ) -> 'Job' View Source def add_tags ( self , * tags : str ) -> Job : for tag in tags : self . _tags [ tag ] = None return self","title":"add_tags"},{"location":"reference/gcip/core/job/#add_variables_1","text":"def add_variables ( self , ** variables : 'str' ) -> 'Job' View Source def add_variables ( self , ** variables : str ) -> Job : self . _variables . update ( variables ) return self","title":"add_variables"},{"location":"reference/gcip/core/job/#append_rules_1","text":"def append_rules ( self , * rules : 'Rule' ) -> 'Job' View Source def append_rules ( self , * rules : Rule ) -> Job : self . _rules . extend ( rules ) return self","title":"append_rules"},{"location":"reference/gcip/core/job/#append_scripts_1","text":"def append_scripts ( self , * scripts : 'str' ) -> 'Job' View Source def append_scripts ( self , * scripts : str ) -> Job : self . _scripts . extend ( scripts ) return self","title":"append_scripts"},{"location":"reference/gcip/core/job/#copy_1","text":"def copy ( self ) -> 'TriggerJob' View Source def copy ( self ) -> TriggerJob : job_copy = TriggerJob ( name = \".\" , project = \".\" ) super (). _copy_into ( job_copy ) job_copy . _project = self . _project job_copy . _branch = self . _branch job_copy . _includes = self . _includes job_copy . _strategy = self . _strategy return job_copy","title":"copy"},{"location":"reference/gcip/core/job/#prepend_rules_1","text":"def prepend_rules ( self , * rules : 'Rule' ) -> 'Job' View Source def prepend_rules ( self , * rules : Rule ) -> Job : self . _rules = list ( rules ) + self . _rules return self","title":"prepend_rules"},{"location":"reference/gcip/core/job/#prepend_scripts_1","text":"def prepend_scripts ( self , * scripts : 'str' ) -> 'Job' View Source def prepend_scripts ( self , * scripts : str ) -> Job : self . _scripts = list ( scripts ) + self . _scripts return self","title":"prepend_scripts"},{"location":"reference/gcip/core/job/#render_1","text":"def render ( self ) -> 'Dict[Any, Any]' View Source def render ( self ) -> Dict [ Any , Any ]: rendered_job = super (). render () # remove unsupported keywords from TriggerJob rendered_job . pop ( \"script\" ) if \"image\" in rendered_job : rendered_job . pop ( \"image\" ) if \"tags\" in rendered_job : rendered_job . pop ( \"tags\" ) if \"artifacts\" in rendered_job : rendered_job . pop ( \"artifacts\" ) if \"cache\" in rendered_job : rendered_job . pop ( \"cache\" ) trigger : Dict [ str , Union [ str , List [ Dict [ str , str ]]]] = {} # Child pipelines if self . _includes : trigger . update ( { \"include\" : [ include . render () for include in self . _includes ], } ) # Multiproject pipelines if self . _project : trigger . update ( { \"project\" : self . _project , } ) if self . _branch : trigger . update ( { \"branch\" : self . _branch } ) if self . _strategy : trigger . update ( { \"strategy\" : self . _strategy . value } ) rendered_job = { \"trigger\" : trigger , ** rendered_job } return rendered_job","title":"render"},{"location":"reference/gcip/core/job/#set_cache_1","text":"def set_cache ( self , cache : 'Optional[Cache]' ) -> 'Job' Sets the cache for the Job. Parameters: Name Type Description Default cache Cache Cache to use for this Job. None Returns: Type Description JobSequence Returns the modified :class: Job object. View Source def set _cache ( self , cache : Optional [ Cache ] ) -> Job : \" \"\" Sets the cache for the Job. Args: cache (Cache): Cache to use for this Job. Returns: JobSequence: Returns the modified :class:`Job` object. \"\" \" if cache : self . _cache = cache return self","title":"set_cache"},{"location":"reference/gcip/core/job/#set_image_1","text":"def set_image ( self , image : 'Optional[Union[Image, str]]' ) -> 'Job' Sets the image of this job. For a simple container image you can provide the origin of the image. If you want to set the entrypoint, you have to provide an Image object instead. Parameters: Name Type Description Default image Optional[Union[Image, str]] Can be either string or Image . None Returns: Type Description Job Returns the modified :class: Job object. View Source def set _image ( self , image : Optional [ Union [ Image , str ]] ) -> Job : \" \"\" Sets the image of this job. For a simple container image you can provide the origin of the image. If you want to set the entrypoint, you have to provide an Image object instead. Args: image (Optional[Union[Image, str]]): Can be either `string` or `Image`. Returns: Job: Returns the modified :class:`Job` object. \"\" \" if image : if isinstance ( image , str ) : image = Image ( image ) self . _image = image return self","title":"set_image"},{"location":"reference/gcip/core/job/#triggerstrategy","text":"class TriggerStrategy ( / , * args , ** kwargs ) View Source class TriggerStrategy ( Enum ) : \" \"\" Class with static values for ``TriggerStrategy`` used together with :class:`gcip.core.job.TriggerJob`. To construct an object. \"\" \" DEPEND = \"depend\"","title":"TriggerStrategy"},{"location":"reference/gcip/core/job/#ancestors-in-mro_1","text":"enum.Enum","title":"Ancestors (in MRO)"},{"location":"reference/gcip/core/job/#class-variables","text":"DEPEND name value","title":"Class variables"},{"location":"reference/gcip/core/job_sequence/","text":"Module gcip.core.job_sequence None None View Source from __future__ import annotations import copy from typing import ( Set , Dict , List , Union , Optional , TypedDict , ) from . import OrderedSetType from .job import Job from .need import Need from .rule import Rule from .cache import Cache from .image import Image __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' class ChildDict ( TypedDict ): object : Union [ Job , JobSequence ] namespace : Optional [ str ] name : Optional [ str ] class JobSequence (): def __init__ ( self ) -> None : super () . __init__ () self . _children : List [ ChildDict ] = list () self . _image_for_initialization : Optional [ Union [ Image , str ]] = None self . _image_for_replacement : Optional [ Union [ Image , str ]] = None self . _variables : Dict [ str , str ] = {} self . _variables_for_initialization : Dict [ str , str ] = {} self . _variables_for_replacement : Dict [ str , str ] = {} self . _tags : OrderedSetType = {} self . _tags_for_initialization : OrderedSetType = {} self . _tags_for_replacement : OrderedSetType = {} self . _artifacts_paths : OrderedSetType = {} self . _cache : Optional [ Cache ] = None self . _cache_for_initialization : Optional [ Cache ] = None self . _scripts_to_prepend : List [ str ] = [] self . _scripts_to_append : List [ str ] = [] self . _rules_to_append : List [ Rule ] = [] self . _rules_to_prepend : List [ Rule ] = [] self . _rules_for_initialization : List [ Rule ] = [] self . _rules_for_replacement : List [ Rule ] = [] self . _needs : List [ Union [ Job , Need ]] = [] self . _parents : List [ JobSequence ] = list () def _add_parent ( self , parent : JobSequence ) -> None : self . _parents . append ( parent ) def add_children ( self , * jobs_or_sequences : Union [ Job , JobSequence ], namespace : Optional [ str ] = None , name : Optional [ str ] = None ) -> JobSequence : for child in jobs_or_sequences : child . _add_parent ( self ) self . _children . append ({ \"object\" : child , \"namespace\" : namespace , \"name\" : name }) return self def add_variables ( self , ** variables : str ) -> JobSequence : self . _variables . update ( variables ) return self def initialize_variables ( self , ** variables : str ) -> JobSequence : \"\"\" Works like :meth:`initialize_tags` but for variales. Args: variables (str): A keyword argument list which key-value-pairs will be applied as variable-value-pairs to all downstream :class:`Job` s without variables already set. \"\"\" self . _variables_for_initialization . update ( variables ) return self def override_variables ( self , ** variables : str ) -> JobSequence : \"\"\" Works like :meth:`override_tags` but for variables. Args: variables (str): A keyword argument list which key-value-pairs will be set as variable-value-pairs to all downstream :class:`Job` s. \"\"\" self . _variables_for_replacement . update ( variables ) return self def set_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache for the corresponding JobSequence. This will override any previously set chaches on this sequence or child sequences/jobs. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache = cache return self def initialize_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache of child sequences/jobs only if not set before. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache_for_initialization = cache return self def add_tags ( self , * tags : str ) -> JobSequence : for tag in tags : self . _tags [ tag ] = None return self def initialize_tags ( self , * tags : str ) -> JobSequence : \"\"\" Adds tags to downstream :class:`Job` s only if they haven't tags added yet. :meth:`initialize_tags` would be extended by :meth:`add_tags` and overridden by :meth:`override_tags` if one of the other methods is called too. Args: tags (str): One or more strings that will be applied to :class:`Job` s with empty tag list. \"\"\" for tag in tags : self . _tags_for_initialization [ tag ] = None return self def override_tags ( self , * tags : str ) -> JobSequence : \"\"\" Will replace all tags from downstream :class:`Job` s. :meth:`override_tags` will also override tags set by :meth:`initialize_tags` but be extended by :meth:`add_tags` when one of the other methods is called too. Args: tags (str): One or more strings that will be set as tags to all downstream :class:`Job` s. \"\"\" for tag in tags : self . _tags_for_replacement [ tag ] = None return self def add_artifacts_paths ( self , * paths : str ) -> JobSequence : for path in paths : self . _artifacts_paths [ path ] = None return self def append_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_append . extend ( rules ) return self def prepend_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_prepend = list ( rules ) + self . _rules_to_prepend return self def initialize_rules ( self , * rules : Rule ) -> JobSequence : \"\"\" Works like :meth:`initialize_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be applied to :class:`Job` s with empty rules list. \"\"\" self . _rules_for_initialization . extend ( rules ) return self def override_rules ( self , * rules : Rule ) -> JobSequence : \"\"\" Works like :meth:`override_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be replace all downstream :class:`Job` s rules. \"\"\" self . _rules_for_replacement . extend ( rules ) return self def add_needs ( self , * needs : Union [ Job , Need ]) -> JobSequence : \"\"\" Only the first job of the sequence get the ``need`` appended to, as well as all following jobs with the same stage. \"\"\" self . _needs . extend ( needs ) return self def prepend_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_prepend = list ( scripts ) + self . _scripts_to_prepend return self def append_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_append . extend ( scripts ) return self def initialize_image ( self , image : Union [ Image , str ]) -> JobSequence : \"\"\"Initializes given `image` to all downstream `Job`s which do not have an `image` set. Args: image (Union[Image, str]): The image to set to all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\"\" if image : self . _image_for_initialization = image return self def override_image ( self , image : Union [ Image , str ]) -> JobSequence : \"\"\"Initializes and override's `image` to all downstream `Job`s. In consequence, all downstream `Job`s will be started with `image`. Args: image (str): The image to set for all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\"\" if image : self . _image_for_replacement = image return self def _get_all_instance_names ( self , child : Union [ Job , JobSequence ]) -> Set [ str ]: instance_names : Set [ str ] = set () for parent in self . _parents : instance_names . update ( parent . _get_all_instance_names ( self )) child_instance_names : Set [ str ] = set () child_instance_name : str for item in self . _children : if item [ \"object\" ] == child : if item [ \"namespace\" ] is not None : if item [ \"name\" ]: child_instance_name = f \"{item['namespace']}-{item['name']}\" else : child_instance_name = item [ \"namespace\" ] elif item [ \"name\" ] is not None : child_instance_name = item [ \"name\" ] else : child_instance_name = \"#unset#\" # all job names have '-' instead of '_' child_instance_names . add ( child_instance_name . replace ( \"_\" , \"-\" )) return_values : Set [ str ] = set () # add instane names of this sequence to all instance # names of its children if instance_names : for child_instance_name in child_instance_names : for instance_name in instance_names : return_values . add ( f \"{child_instance_name}-{instance_name}\" ) else : return_values = child_instance_names return return_values @property def last_jobs_executed ( self ) -> List [ Job ]: all_jobs = self . populated_jobs stages : Dict [ str , None ] = {} for job in all_jobs : # use the keys of dictionary as ordered set stages [ job . stage ] = None last_stage = list ( stages . keys ())[ - 1 ] last_executed_jobs : List [ Job ] = list () for job in all_jobs : if job . _stage == last_stage : if job . _original : last_executed_jobs . append ( job . _original ) else : raise AttributeError ( \"job._original is None, because the job is not a copy of another job\" ) return last_executed_jobs @property def populated_jobs ( self ) -> List [ Job ]: all_jobs : List [ Job ] = [] for child in self . _children : if isinstance ( child [ \"object\" ], JobSequence ): for job_copy in child [ \"object\" ] . populated_jobs : job_copy . _extend_namespace ( child [ \"namespace\" ]) job_copy . _extend_name ( child [ \"name\" ]) all_jobs . append ( job_copy ) elif isinstance ( child [ \"object\" ], Job ): job_copy = child [ \"object\" ] . copy () job_copy . _extend_namespace ( child [ \"namespace\" ]) job_copy . _extend_name ( child [ \"name\" ]) all_jobs . append ( job_copy ) if len ( all_jobs ) > 0 : first_job = all_jobs [ 0 ] first_job . add_needs ( * self . _needs ) for job in all_jobs [ 1 :]: if job . _stage == first_job . stage : job . add_needs ( * self . _needs ) for job in all_jobs : if self . _image_for_initialization and not job . _image : job . set_image ( self . _image_for_initialization ) if self . _image_for_replacement : job . set_image ( self . _image_for_replacement ) if self . _variables_for_initialization and not job . _variables : job . _variables = copy . deepcopy ( self . _variables_for_initialization ) if self . _variables_for_replacement : job . _variables = copy . deepcopy ( self . _variables_for_replacement ) job . add_variables ( ** copy . deepcopy ( self . _variables )) if self . _cache_for_initialization and not job . _cache : job . _cache = copy . deepcopy ( self . _cache_for_initialization ) job . set_cache ( copy . deepcopy ( self . _cache )) if self . _tags_for_initialization and not job . _tags : job . _tags = copy . deepcopy ( self . _tags_for_initialization ) if self . _tags_for_replacement : job . _tags = copy . deepcopy ( self . _tags_for_replacement ) job . add_tags ( * list ( self . _tags . keys ())) job . add_artifacts_paths ( * list ( self . _artifacts_paths . keys ())) if self . _rules_for_initialization and not job . _rules : job . _rules = copy . deepcopy ( self . _rules_for_initialization ) if self . _rules_for_replacement : job . _rules = copy . deepcopy ( self . _rules_for_replacement ) job . append_rules ( * self . _rules_to_append ) job . prepend_rules ( * self . _rules_to_prepend ) job . prepend_scripts ( * self . _scripts_to_prepend ) job . append_scripts ( * self . _scripts_to_append ) return all_jobs Classes ChildDict class ChildDict ( / , * args , ** kwargs ) View Source class ChildDict ( TypedDict ) : object : Union [ Job, JobSequence ] namespace : Optional [ str ] name : Optional [ str ] Ancestors (in MRO) builtins.dict Methods clear def clear ( ... ) D.clear() -> None. Remove all items from D. copy def copy ( ... ) D.copy() -> a shallow copy of D fromkeys def fromkeys ( iterable , value = None , / ) Create a new dictionary with keys from iterable and values set to value. get def get ( self , key , default = None , / ) Return the value for key if key is in the dictionary, else default. items def items ( ... ) D.items() -> a set-like object providing a view on D's items keys def keys ( ... ) D.keys() -> a set-like object providing a view on D's keys pop def pop ( ... ) D.pop(k[,d]) -> v, remove specified key and return the corresponding value. If key is not found, default is returned if given, otherwise KeyError is raised popitem def popitem ( self , / ) Remove and return a (key, value) pair as a 2-tuple. Pairs are returned in LIFO (last-in, first-out) order. Raises KeyError if the dict is empty. setdefault def setdefault ( self , key , default = None , / ) Insert key with a value of default if key is not in the dictionary. Return the value for key if key is in the dictionary, else default. update def update ( ... ) D.update([E, ]**F) -> None. Update D from dict/iterable E and F. If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k] values def values ( ... ) D.values() -> an object providing a view on D's values JobSequence class JobSequence ( ) View Source class JobSequence (): def __init__ ( self ) -> None : super () . __init__ () self . _children : List [ ChildDict ] = list () self . _image_for_initialization : Optional [ Union [ Image , str ]] = None self . _image_for_replacement : Optional [ Union [ Image , str ]] = None self . _variables : Dict [ str , str ] = {} self . _variables_for_initialization : Dict [ str , str ] = {} self . _variables_for_replacement : Dict [ str , str ] = {} self . _tags : OrderedSetType = {} self . _tags_for_initialization : OrderedSetType = {} self . _tags_for_replacement : OrderedSetType = {} self . _artifacts_paths : OrderedSetType = {} self . _cache : Optional [ Cache ] = None self . _cache_for_initialization : Optional [ Cache ] = None self . _scripts_to_prepend : List [ str ] = [] self . _scripts_to_append : List [ str ] = [] self . _rules_to_append : List [ Rule ] = [] self . _rules_to_prepend : List [ Rule ] = [] self . _rules_for_initialization : List [ Rule ] = [] self . _rules_for_replacement : List [ Rule ] = [] self . _needs : List [ Union [ Job , Need ]] = [] self . _parents : List [ JobSequence ] = list () def _add_parent ( self , parent : JobSequence ) -> None : self . _parents . append ( parent ) def add_children ( self , * jobs_or_sequences : Union [ Job , JobSequence ], namespace : Optional [ str ] = None , name : Optional [ str ] = None ) -> JobSequence : for child in jobs_or_sequences : child . _add_parent ( self ) self . _children . append ({ \"object\" : child , \"namespace\" : namespace , \"name\" : name }) return self def add_variables ( self , ** variables : str ) -> JobSequence : self . _variables . update ( variables ) return self def initialize_variables ( self , ** variables : str ) -> JobSequence : \"\"\" Works like :meth:`initialize_tags` but for variales. Args: variables (str): A keyword argument list which key-value-pairs will be applied as variable-value-pairs to all downstream :class:`Job` s without variables already set. \"\"\" self . _variables_for_initialization . update ( variables ) return self def override_variables ( self , ** variables : str ) -> JobSequence : \"\"\" Works like :meth:`override_tags` but for variables. Args: variables (str): A keyword argument list which key-value-pairs will be set as variable-value-pairs to all downstream :class:`Job` s. \"\"\" self . _variables_for_replacement . update ( variables ) return self def set_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache for the corresponding JobSequence. This will override any previously set chaches on this sequence or child sequences/jobs. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache = cache return self def initialize_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache of child sequences/jobs only if not set before. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache_for_initialization = cache return self def add_tags ( self , * tags : str ) -> JobSequence : for tag in tags : self . _tags [ tag ] = None return self def initialize_tags ( self , * tags : str ) -> JobSequence : \"\"\" Adds tags to downstream :class:`Job` s only if they haven't tags added yet. :meth:`initialize_tags` would be extended by :meth:`add_tags` and overridden by :meth:`override_tags` if one of the other methods is called too. Args: tags (str): One or more strings that will be applied to :class:`Job` s with empty tag list. \"\"\" for tag in tags : self . _tags_for_initialization [ tag ] = None return self def override_tags ( self , * tags : str ) -> JobSequence : \"\"\" Will replace all tags from downstream :class:`Job` s. :meth:`override_tags` will also override tags set by :meth:`initialize_tags` but be extended by :meth:`add_tags` when one of the other methods is called too. Args: tags (str): One or more strings that will be set as tags to all downstream :class:`Job` s. \"\"\" for tag in tags : self . _tags_for_replacement [ tag ] = None return self def add_artifacts_paths ( self , * paths : str ) -> JobSequence : for path in paths : self . _artifacts_paths [ path ] = None return self def append_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_append . extend ( rules ) return self def prepend_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_prepend = list ( rules ) + self . _rules_to_prepend return self def initialize_rules ( self , * rules : Rule ) -> JobSequence : \"\"\" Works like :meth:`initialize_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be applied to :class:`Job` s with empty rules list. \"\"\" self . _rules_for_initialization . extend ( rules ) return self def override_rules ( self , * rules : Rule ) -> JobSequence : \"\"\" Works like :meth:`override_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be replace all downstream :class:`Job` s rules. \"\"\" self . _rules_for_replacement . extend ( rules ) return self def add_needs ( self , * needs : Union [ Job , Need ]) -> JobSequence : \"\"\" Only the first job of the sequence get the ``need`` appended to, as well as all following jobs with the same stage. \"\"\" self . _needs . extend ( needs ) return self def prepend_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_prepend = list ( scripts ) + self . _scripts_to_prepend return self def append_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_append . extend ( scripts ) return self def initialize_image ( self , image : Union [ Image , str ]) -> JobSequence : \"\"\"Initializes given `image` to all downstream `Job`s which do not have an `image` set. Args: image (Union[Image, str]): The image to set to all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\"\" if image : self . _image_for_initialization = image return self def override_image ( self , image : Union [ Image , str ]) -> JobSequence : \"\"\"Initializes and override's `image` to all downstream `Job`s. In consequence, all downstream `Job`s will be started with `image`. Args: image (str): The image to set for all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\"\" if image : self . _image_for_replacement = image return self def _get_all_instance_names ( self , child : Union [ Job , JobSequence ]) -> Set [ str ]: instance_names : Set [ str ] = set () for parent in self . _parents : instance_names . update ( parent . _get_all_instance_names ( self )) child_instance_names : Set [ str ] = set () child_instance_name : str for item in self . _children : if item [ \"object\" ] == child : if item [ \"namespace\" ] is not None : if item [ \"name\" ]: child_instance_name = f \"{item['namespace']}-{item['name']}\" else : child_instance_name = item [ \"namespace\" ] elif item [ \"name\" ] is not None : child_instance_name = item [ \"name\" ] else : child_instance_name = \"#unset#\" # all job names have '-' instead of '_' child_instance_names . add ( child_instance_name . replace ( \"_\" , \"-\" )) return_values : Set [ str ] = set () # add instane names of this sequence to all instance # names of its children if instance_names : for child_instance_name in child_instance_names : for instance_name in instance_names : return_values . add ( f \"{child_instance_name}-{instance_name}\" ) else : return_values = child_instance_names return return_values @ property def last_jobs_executed ( self ) -> List [ Job ]: all_jobs = self . populated_jobs stages : Dict [ str , None ] = {} for job in all_jobs : # use the keys of dictionary as ordered set stages [ job . stage ] = None last_stage = list ( stages . keys ())[ - 1 ] last_executed_jobs : List [ Job ] = list () for job in all_jobs : if job . _stage == last_stage : if job . _original : last_executed_jobs . append ( job . _original ) else : raise AttributeError ( \"job._original is None, because the job is not a copy of another job\" ) return last_executed_jobs @ property def populated_jobs ( self ) -> List [ Job ]: all_jobs : List [ Job ] = [] for child in self . _children : if isinstance ( child [ \"object\" ], JobSequence ): for job_copy in child [ \"object\" ] . populated_jobs : job_copy . _extend_namespace ( child [ \"namespace\" ]) job_copy . _extend_name ( child [ \"name\" ]) all_jobs . append ( job_copy ) elif isinstance ( child [ \"object\" ], Job ): job_copy = child [ \"object\" ] . copy () job_copy . _extend_namespace ( child [ \"namespace\" ]) job_copy . _extend_name ( child [ \"name\" ]) all_jobs . append ( job_copy ) if len ( all_jobs ) > 0 : first_job = all_jobs [ 0 ] first_job . add_needs ( * self . _needs ) for job in all_jobs [ 1 :]: if job . _stage == first_job . stage : job . add_needs ( * self . _needs ) for job in all_jobs : if self . _image_for_initialization and not job . _image : job . set_image ( self . _image_for_initialization ) if self . _image_for_replacement : job . set_image ( self . _image_for_replacement ) if self . _variables_for_initialization and not job . _variables : job . _variables = copy . deepcopy ( self . _variables_for_initialization ) if self . _variables_for_replacement : job . _variables = copy . deepcopy ( self . _variables_for_replacement ) job . add_variables ( ** copy . deepcopy ( self . _variables )) if self . _cache_for_initialization and not job . _cache : job . _cache = copy . deepcopy ( self . _cache_for_initialization ) job . set_cache ( copy . deepcopy ( self . _cache )) if self . _tags_for_initialization and not job . _tags : job . _tags = copy . deepcopy ( self . _tags_for_initialization ) if self . _tags_for_replacement : job . _tags = copy . deepcopy ( self . _tags_for_replacement ) job . add_tags ( * list ( self . _tags . keys ())) job . add_artifacts_paths ( * list ( self . _artifacts_paths . keys ())) if self . _rules_for_initialization and not job . _rules : job . _rules = copy . deepcopy ( self . _rules_for_initialization ) if self . _rules_for_replacement : job . _rules = copy . deepcopy ( self . _rules_for_replacement ) job . append_rules ( * self . _rules_to_append ) job . prepend_rules ( * self . _rules_to_prepend ) job . prepend_scripts ( * self . _scripts_to_prepend ) job . append_scripts ( * self . _scripts_to_append ) return all_jobs Descendants gcip.core.pipeline.Pipeline Instance variables last_jobs_executed populated_jobs Methods add_artifacts_paths def add_artifacts_paths ( self , * paths : 'str' ) -> 'JobSequence' View Source def add_artifacts_paths ( self , * paths : str ) -> JobSequence : for path in paths : self . _artifacts_paths [ path ] = None return self add_children def add_children ( self , * jobs_or_sequences : 'Union[Job, JobSequence]' , namespace : 'Optional[str]' = None , name : 'Optional[str]' = None ) -> 'JobSequence' View Source def add_children ( self , * jobs_or_sequences : Union [ Job, JobSequence ] , namespace : Optional [ str ] = None , name : Optional [ str ] = None ) -> JobSequence : for child in jobs_or_sequences : child . _add_parent ( self ) self . _children . append ( { \"object\" : child , \"namespace\" : namespace , \"name\" : name } ) return self add_needs def add_needs ( self , * needs : 'Union[Job, Need]' ) -> 'JobSequence' Only the first job of the sequence get the need appended to, as well as all following jobs with the same stage. View Source def add_needs ( self , * needs : Union [ Job , Need ] ) -> JobSequence : \" \"\" Only the first job of the sequence get the ``need`` appended to, as well as all following jobs with the same stage. \"\" \" self . _needs . extend ( needs ) return self add_tags def add_tags ( self , * tags : 'str' ) -> 'JobSequence' View Source def add_tags ( self , * tags : str ) -> JobSequence : for tag in tags : self . _tags [ tag ] = None return self add_variables def add_variables ( self , ** variables : 'str' ) -> 'JobSequence' View Source def add_variables ( self , ** variables : str ) -> JobSequence : self . _variables . update ( variables ) return self append_rules def append_rules ( self , * rules : 'Rule' ) -> 'JobSequence' View Source def append_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_append . extend ( rules ) return self append_scripts def append_scripts ( self , * scripts : 'str' ) -> 'JobSequence' View Source def append_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_append . extend ( scripts ) return self initialize_cache def initialize_cache ( self , cache : 'Cache' ) -> 'JobSequence' Sets the cache of child sequences/jobs only if not set before. Parameters: Name Type Description Default cache Cache Cache to use for the JobSequence and its Jobs. None Returns: Type Description JobSequence Returns the modified Sequence object. View Source def initialize_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache of child sequences/jobs only if not set before. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache_for_initialization = cache return self initialize_image def initialize_image ( self , image : 'Union[Image, str]' ) -> 'JobSequence' Initializes given image to all downstream Job s which do not have an image set. Parameters: Name Type Description Default image Union[Image, str] The image to set to all downstream :class: Job 's. None Returns: Type Description JobSequence Modified sequence object. View Source def initialize_image ( self , image : Union [ Image , str ] ) -> JobSequence : \" \"\" Initializes given `image` to all downstream `Job`s which do not have an `image` set. Args: image (Union[Image, str]): The image to set to all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\" \" if image : self . _image_for_initialization = image return self initialize_rules def initialize_rules ( self , * rules : 'Rule' ) -> 'JobSequence' Works like :meth: initialize_tags but for rules. Parameters: Name Type Description Default rules Rule A list of :class: Rule s that will be applied to :class: Job s with empty rules list. None View Source def initialize_rules ( self , * rules : Rule ) -> JobSequence : \" \"\" Works like :meth:`initialize_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be applied to :class:`Job` s with empty rules list. \"\" \" self . _rules_for_initialization . extend ( rules ) return self initialize_tags def initialize_tags ( self , * tags : 'str' ) -> 'JobSequence' Adds tags to downstream :class: Job s only if they haven't tags added yet. View Source def initialize_tags ( self , * tags : str ) -> JobSequence : \" \"\" Adds tags to downstream :class:`Job` s only if they haven't tags added yet. :meth:`initialize_tags` would be extended by :meth:`add_tags` and overridden by :meth:`override_tags` if one of the other methods is called too. Args: tags (str): One or more strings that will be applied to :class:`Job` s with empty tag list. \"\" \" for tag in tags : self . _tags_for_initialization [ tag ] = None return self initialize_variables def initialize_variables ( self , ** variables : 'str' ) -> 'JobSequence' Works like :meth: initialize_tags but for variales. Parameters: Name Type Description Default variables str A keyword argument list which key-value-pairs will be applied as variable-value-pairs to all downstream :class: Job s without variables already set. None View Source def initialize_variables ( self , ** variables : str ) -> JobSequence : \" \"\" Works like :meth:`initialize_tags` but for variales. Args: variables (str): A keyword argument list which key-value-pairs will be applied as variable-value-pairs to all downstream :class:`Job` s without variables already set. \"\" \" self . _variables_for_initialization . update ( variables ) return self override_image def override_image ( self , image : 'Union[Image, str]' ) -> 'JobSequence' Initializes and override's image to all downstream Job s. In consequence, all downstream Job s will be started with image . Parameters: Name Type Description Default image str The image to set for all downstream :class: Job 's. None Returns: Type Description JobSequence Modified sequence object. View Source def override_image ( self , image : Union [ Image , str ] ) -> JobSequence : \" \"\" Initializes and override's `image` to all downstream `Job`s. In consequence, all downstream `Job`s will be started with `image`. Args: image (str): The image to set for all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\" \" if image : self . _image_for_replacement = image return self override_rules def override_rules ( self , * rules : 'Rule' ) -> 'JobSequence' Works like :meth: override_tags but for rules. Parameters: Name Type Description Default rules Rule A list of :class: Rule s that will be replace all downstream :class: Job s rules. None View Source def override_rules ( self , * rules : Rule ) -> JobSequence : \" \"\" Works like :meth:`override_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be replace all downstream :class:`Job` s rules. \"\" \" self . _rules_for_replacement . extend ( rules ) return self override_tags def override_tags ( self , * tags : 'str' ) -> 'JobSequence' Will replace all tags from downstream :class: Job s. View Source def override_tags ( self , * tags : str ) -> JobSequence : \" \"\" Will replace all tags from downstream :class:`Job` s. :meth:`override_tags` will also override tags set by :meth:`initialize_tags` but be extended by :meth:`add_tags` when one of the other methods is called too. Args: tags (str): One or more strings that will be set as tags to all downstream :class:`Job` s. \"\" \" for tag in tags : self . _tags_for_replacement [ tag ] = None return self override_variables def override_variables ( self , ** variables : 'str' ) -> 'JobSequence' Works like :meth: override_tags but for variables. Parameters: Name Type Description Default variables str A keyword argument list which key-value-pairs will be set as variable-value-pairs to all downstream :class: Job s. None View Source def override_variables ( self , ** variables : str ) -> JobSequence : \" \"\" Works like :meth:`override_tags` but for variables. Args: variables (str): A keyword argument list which key-value-pairs will be set as variable-value-pairs to all downstream :class:`Job` s. \"\" \" self . _variables_for_replacement . update ( variables ) return self prepend_rules def prepend_rules ( self , * rules : 'Rule' ) -> 'JobSequence' View Source def prepend_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_prepend = list ( rules ) + self . _rules_to_prepend return self prepend_scripts def prepend_scripts ( self , * scripts : 'str' ) -> 'JobSequence' View Source def prepend_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_prepend = list ( scripts ) + self . _scripts_to_prepend return self set_cache def set_cache ( self , cache : 'Cache' ) -> 'JobSequence' Sets the cache for the corresponding JobSequence. This will override any previously set chaches on this sequence or child sequences/jobs. Parameters: Name Type Description Default cache Cache Cache to use for the JobSequence and its Jobs. None Returns: Type Description JobSequence Returns the modified Sequence object. View Source def set_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache for the corresponding JobSequence. This will override any previously set chaches on this sequence or child sequences/jobs. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache = cache return self","title":"Job Sequence"},{"location":"reference/gcip/core/job_sequence/#module-gcipcorejob_sequence","text":"None None View Source from __future__ import annotations import copy from typing import ( Set , Dict , List , Union , Optional , TypedDict , ) from . import OrderedSetType from .job import Job from .need import Need from .rule import Rule from .cache import Cache from .image import Image __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' class ChildDict ( TypedDict ): object : Union [ Job , JobSequence ] namespace : Optional [ str ] name : Optional [ str ] class JobSequence (): def __init__ ( self ) -> None : super () . __init__ () self . _children : List [ ChildDict ] = list () self . _image_for_initialization : Optional [ Union [ Image , str ]] = None self . _image_for_replacement : Optional [ Union [ Image , str ]] = None self . _variables : Dict [ str , str ] = {} self . _variables_for_initialization : Dict [ str , str ] = {} self . _variables_for_replacement : Dict [ str , str ] = {} self . _tags : OrderedSetType = {} self . _tags_for_initialization : OrderedSetType = {} self . _tags_for_replacement : OrderedSetType = {} self . _artifacts_paths : OrderedSetType = {} self . _cache : Optional [ Cache ] = None self . _cache_for_initialization : Optional [ Cache ] = None self . _scripts_to_prepend : List [ str ] = [] self . _scripts_to_append : List [ str ] = [] self . _rules_to_append : List [ Rule ] = [] self . _rules_to_prepend : List [ Rule ] = [] self . _rules_for_initialization : List [ Rule ] = [] self . _rules_for_replacement : List [ Rule ] = [] self . _needs : List [ Union [ Job , Need ]] = [] self . _parents : List [ JobSequence ] = list () def _add_parent ( self , parent : JobSequence ) -> None : self . _parents . append ( parent ) def add_children ( self , * jobs_or_sequences : Union [ Job , JobSequence ], namespace : Optional [ str ] = None , name : Optional [ str ] = None ) -> JobSequence : for child in jobs_or_sequences : child . _add_parent ( self ) self . _children . append ({ \"object\" : child , \"namespace\" : namespace , \"name\" : name }) return self def add_variables ( self , ** variables : str ) -> JobSequence : self . _variables . update ( variables ) return self def initialize_variables ( self , ** variables : str ) -> JobSequence : \"\"\" Works like :meth:`initialize_tags` but for variales. Args: variables (str): A keyword argument list which key-value-pairs will be applied as variable-value-pairs to all downstream :class:`Job` s without variables already set. \"\"\" self . _variables_for_initialization . update ( variables ) return self def override_variables ( self , ** variables : str ) -> JobSequence : \"\"\" Works like :meth:`override_tags` but for variables. Args: variables (str): A keyword argument list which key-value-pairs will be set as variable-value-pairs to all downstream :class:`Job` s. \"\"\" self . _variables_for_replacement . update ( variables ) return self def set_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache for the corresponding JobSequence. This will override any previously set chaches on this sequence or child sequences/jobs. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache = cache return self def initialize_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache of child sequences/jobs only if not set before. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache_for_initialization = cache return self def add_tags ( self , * tags : str ) -> JobSequence : for tag in tags : self . _tags [ tag ] = None return self def initialize_tags ( self , * tags : str ) -> JobSequence : \"\"\" Adds tags to downstream :class:`Job` s only if they haven't tags added yet. :meth:`initialize_tags` would be extended by :meth:`add_tags` and overridden by :meth:`override_tags` if one of the other methods is called too. Args: tags (str): One or more strings that will be applied to :class:`Job` s with empty tag list. \"\"\" for tag in tags : self . _tags_for_initialization [ tag ] = None return self def override_tags ( self , * tags : str ) -> JobSequence : \"\"\" Will replace all tags from downstream :class:`Job` s. :meth:`override_tags` will also override tags set by :meth:`initialize_tags` but be extended by :meth:`add_tags` when one of the other methods is called too. Args: tags (str): One or more strings that will be set as tags to all downstream :class:`Job` s. \"\"\" for tag in tags : self . _tags_for_replacement [ tag ] = None return self def add_artifacts_paths ( self , * paths : str ) -> JobSequence : for path in paths : self . _artifacts_paths [ path ] = None return self def append_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_append . extend ( rules ) return self def prepend_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_prepend = list ( rules ) + self . _rules_to_prepend return self def initialize_rules ( self , * rules : Rule ) -> JobSequence : \"\"\" Works like :meth:`initialize_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be applied to :class:`Job` s with empty rules list. \"\"\" self . _rules_for_initialization . extend ( rules ) return self def override_rules ( self , * rules : Rule ) -> JobSequence : \"\"\" Works like :meth:`override_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be replace all downstream :class:`Job` s rules. \"\"\" self . _rules_for_replacement . extend ( rules ) return self def add_needs ( self , * needs : Union [ Job , Need ]) -> JobSequence : \"\"\" Only the first job of the sequence get the ``need`` appended to, as well as all following jobs with the same stage. \"\"\" self . _needs . extend ( needs ) return self def prepend_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_prepend = list ( scripts ) + self . _scripts_to_prepend return self def append_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_append . extend ( scripts ) return self def initialize_image ( self , image : Union [ Image , str ]) -> JobSequence : \"\"\"Initializes given `image` to all downstream `Job`s which do not have an `image` set. Args: image (Union[Image, str]): The image to set to all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\"\" if image : self . _image_for_initialization = image return self def override_image ( self , image : Union [ Image , str ]) -> JobSequence : \"\"\"Initializes and override's `image` to all downstream `Job`s. In consequence, all downstream `Job`s will be started with `image`. Args: image (str): The image to set for all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\"\" if image : self . _image_for_replacement = image return self def _get_all_instance_names ( self , child : Union [ Job , JobSequence ]) -> Set [ str ]: instance_names : Set [ str ] = set () for parent in self . _parents : instance_names . update ( parent . _get_all_instance_names ( self )) child_instance_names : Set [ str ] = set () child_instance_name : str for item in self . _children : if item [ \"object\" ] == child : if item [ \"namespace\" ] is not None : if item [ \"name\" ]: child_instance_name = f \"{item['namespace']}-{item['name']}\" else : child_instance_name = item [ \"namespace\" ] elif item [ \"name\" ] is not None : child_instance_name = item [ \"name\" ] else : child_instance_name = \"#unset#\" # all job names have '-' instead of '_' child_instance_names . add ( child_instance_name . replace ( \"_\" , \"-\" )) return_values : Set [ str ] = set () # add instane names of this sequence to all instance # names of its children if instance_names : for child_instance_name in child_instance_names : for instance_name in instance_names : return_values . add ( f \"{child_instance_name}-{instance_name}\" ) else : return_values = child_instance_names return return_values @property def last_jobs_executed ( self ) -> List [ Job ]: all_jobs = self . populated_jobs stages : Dict [ str , None ] = {} for job in all_jobs : # use the keys of dictionary as ordered set stages [ job . stage ] = None last_stage = list ( stages . keys ())[ - 1 ] last_executed_jobs : List [ Job ] = list () for job in all_jobs : if job . _stage == last_stage : if job . _original : last_executed_jobs . append ( job . _original ) else : raise AttributeError ( \"job._original is None, because the job is not a copy of another job\" ) return last_executed_jobs @property def populated_jobs ( self ) -> List [ Job ]: all_jobs : List [ Job ] = [] for child in self . _children : if isinstance ( child [ \"object\" ], JobSequence ): for job_copy in child [ \"object\" ] . populated_jobs : job_copy . _extend_namespace ( child [ \"namespace\" ]) job_copy . _extend_name ( child [ \"name\" ]) all_jobs . append ( job_copy ) elif isinstance ( child [ \"object\" ], Job ): job_copy = child [ \"object\" ] . copy () job_copy . _extend_namespace ( child [ \"namespace\" ]) job_copy . _extend_name ( child [ \"name\" ]) all_jobs . append ( job_copy ) if len ( all_jobs ) > 0 : first_job = all_jobs [ 0 ] first_job . add_needs ( * self . _needs ) for job in all_jobs [ 1 :]: if job . _stage == first_job . stage : job . add_needs ( * self . _needs ) for job in all_jobs : if self . _image_for_initialization and not job . _image : job . set_image ( self . _image_for_initialization ) if self . _image_for_replacement : job . set_image ( self . _image_for_replacement ) if self . _variables_for_initialization and not job . _variables : job . _variables = copy . deepcopy ( self . _variables_for_initialization ) if self . _variables_for_replacement : job . _variables = copy . deepcopy ( self . _variables_for_replacement ) job . add_variables ( ** copy . deepcopy ( self . _variables )) if self . _cache_for_initialization and not job . _cache : job . _cache = copy . deepcopy ( self . _cache_for_initialization ) job . set_cache ( copy . deepcopy ( self . _cache )) if self . _tags_for_initialization and not job . _tags : job . _tags = copy . deepcopy ( self . _tags_for_initialization ) if self . _tags_for_replacement : job . _tags = copy . deepcopy ( self . _tags_for_replacement ) job . add_tags ( * list ( self . _tags . keys ())) job . add_artifacts_paths ( * list ( self . _artifacts_paths . keys ())) if self . _rules_for_initialization and not job . _rules : job . _rules = copy . deepcopy ( self . _rules_for_initialization ) if self . _rules_for_replacement : job . _rules = copy . deepcopy ( self . _rules_for_replacement ) job . append_rules ( * self . _rules_to_append ) job . prepend_rules ( * self . _rules_to_prepend ) job . prepend_scripts ( * self . _scripts_to_prepend ) job . append_scripts ( * self . _scripts_to_append ) return all_jobs","title":"Module gcip.core.job_sequence"},{"location":"reference/gcip/core/job_sequence/#classes","text":"","title":"Classes"},{"location":"reference/gcip/core/job_sequence/#childdict","text":"class ChildDict ( / , * args , ** kwargs ) View Source class ChildDict ( TypedDict ) : object : Union [ Job, JobSequence ] namespace : Optional [ str ] name : Optional [ str ]","title":"ChildDict"},{"location":"reference/gcip/core/job_sequence/#ancestors-in-mro","text":"builtins.dict","title":"Ancestors (in MRO)"},{"location":"reference/gcip/core/job_sequence/#methods","text":"","title":"Methods"},{"location":"reference/gcip/core/job_sequence/#clear","text":"def clear ( ... ) D.clear() -> None. Remove all items from D.","title":"clear"},{"location":"reference/gcip/core/job_sequence/#copy","text":"def copy ( ... ) D.copy() -> a shallow copy of D","title":"copy"},{"location":"reference/gcip/core/job_sequence/#fromkeys","text":"def fromkeys ( iterable , value = None , / ) Create a new dictionary with keys from iterable and values set to value.","title":"fromkeys"},{"location":"reference/gcip/core/job_sequence/#get","text":"def get ( self , key , default = None , / ) Return the value for key if key is in the dictionary, else default.","title":"get"},{"location":"reference/gcip/core/job_sequence/#items","text":"def items ( ... ) D.items() -> a set-like object providing a view on D's items","title":"items"},{"location":"reference/gcip/core/job_sequence/#keys","text":"def keys ( ... ) D.keys() -> a set-like object providing a view on D's keys","title":"keys"},{"location":"reference/gcip/core/job_sequence/#pop","text":"def pop ( ... ) D.pop(k[,d]) -> v, remove specified key and return the corresponding value. If key is not found, default is returned if given, otherwise KeyError is raised","title":"pop"},{"location":"reference/gcip/core/job_sequence/#popitem","text":"def popitem ( self , / ) Remove and return a (key, value) pair as a 2-tuple. Pairs are returned in LIFO (last-in, first-out) order. Raises KeyError if the dict is empty.","title":"popitem"},{"location":"reference/gcip/core/job_sequence/#setdefault","text":"def setdefault ( self , key , default = None , / ) Insert key with a value of default if key is not in the dictionary. Return the value for key if key is in the dictionary, else default.","title":"setdefault"},{"location":"reference/gcip/core/job_sequence/#update","text":"def update ( ... ) D.update([E, ]**F) -> None. Update D from dict/iterable E and F. If E is present and has a .keys() method, then does: for k in E: D[k] = E[k] If E is present and lacks a .keys() method, then does: for k, v in E: D[k] = v In either case, this is followed by: for k in F: D[k] = F[k]","title":"update"},{"location":"reference/gcip/core/job_sequence/#values","text":"def values ( ... ) D.values() -> an object providing a view on D's values","title":"values"},{"location":"reference/gcip/core/job_sequence/#jobsequence","text":"class JobSequence ( ) View Source class JobSequence (): def __init__ ( self ) -> None : super () . __init__ () self . _children : List [ ChildDict ] = list () self . _image_for_initialization : Optional [ Union [ Image , str ]] = None self . _image_for_replacement : Optional [ Union [ Image , str ]] = None self . _variables : Dict [ str , str ] = {} self . _variables_for_initialization : Dict [ str , str ] = {} self . _variables_for_replacement : Dict [ str , str ] = {} self . _tags : OrderedSetType = {} self . _tags_for_initialization : OrderedSetType = {} self . _tags_for_replacement : OrderedSetType = {} self . _artifacts_paths : OrderedSetType = {} self . _cache : Optional [ Cache ] = None self . _cache_for_initialization : Optional [ Cache ] = None self . _scripts_to_prepend : List [ str ] = [] self . _scripts_to_append : List [ str ] = [] self . _rules_to_append : List [ Rule ] = [] self . _rules_to_prepend : List [ Rule ] = [] self . _rules_for_initialization : List [ Rule ] = [] self . _rules_for_replacement : List [ Rule ] = [] self . _needs : List [ Union [ Job , Need ]] = [] self . _parents : List [ JobSequence ] = list () def _add_parent ( self , parent : JobSequence ) -> None : self . _parents . append ( parent ) def add_children ( self , * jobs_or_sequences : Union [ Job , JobSequence ], namespace : Optional [ str ] = None , name : Optional [ str ] = None ) -> JobSequence : for child in jobs_or_sequences : child . _add_parent ( self ) self . _children . append ({ \"object\" : child , \"namespace\" : namespace , \"name\" : name }) return self def add_variables ( self , ** variables : str ) -> JobSequence : self . _variables . update ( variables ) return self def initialize_variables ( self , ** variables : str ) -> JobSequence : \"\"\" Works like :meth:`initialize_tags` but for variales. Args: variables (str): A keyword argument list which key-value-pairs will be applied as variable-value-pairs to all downstream :class:`Job` s without variables already set. \"\"\" self . _variables_for_initialization . update ( variables ) return self def override_variables ( self , ** variables : str ) -> JobSequence : \"\"\" Works like :meth:`override_tags` but for variables. Args: variables (str): A keyword argument list which key-value-pairs will be set as variable-value-pairs to all downstream :class:`Job` s. \"\"\" self . _variables_for_replacement . update ( variables ) return self def set_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache for the corresponding JobSequence. This will override any previously set chaches on this sequence or child sequences/jobs. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache = cache return self def initialize_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache of child sequences/jobs only if not set before. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache_for_initialization = cache return self def add_tags ( self , * tags : str ) -> JobSequence : for tag in tags : self . _tags [ tag ] = None return self def initialize_tags ( self , * tags : str ) -> JobSequence : \"\"\" Adds tags to downstream :class:`Job` s only if they haven't tags added yet. :meth:`initialize_tags` would be extended by :meth:`add_tags` and overridden by :meth:`override_tags` if one of the other methods is called too. Args: tags (str): One or more strings that will be applied to :class:`Job` s with empty tag list. \"\"\" for tag in tags : self . _tags_for_initialization [ tag ] = None return self def override_tags ( self , * tags : str ) -> JobSequence : \"\"\" Will replace all tags from downstream :class:`Job` s. :meth:`override_tags` will also override tags set by :meth:`initialize_tags` but be extended by :meth:`add_tags` when one of the other methods is called too. Args: tags (str): One or more strings that will be set as tags to all downstream :class:`Job` s. \"\"\" for tag in tags : self . _tags_for_replacement [ tag ] = None return self def add_artifacts_paths ( self , * paths : str ) -> JobSequence : for path in paths : self . _artifacts_paths [ path ] = None return self def append_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_append . extend ( rules ) return self def prepend_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_prepend = list ( rules ) + self . _rules_to_prepend return self def initialize_rules ( self , * rules : Rule ) -> JobSequence : \"\"\" Works like :meth:`initialize_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be applied to :class:`Job` s with empty rules list. \"\"\" self . _rules_for_initialization . extend ( rules ) return self def override_rules ( self , * rules : Rule ) -> JobSequence : \"\"\" Works like :meth:`override_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be replace all downstream :class:`Job` s rules. \"\"\" self . _rules_for_replacement . extend ( rules ) return self def add_needs ( self , * needs : Union [ Job , Need ]) -> JobSequence : \"\"\" Only the first job of the sequence get the ``need`` appended to, as well as all following jobs with the same stage. \"\"\" self . _needs . extend ( needs ) return self def prepend_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_prepend = list ( scripts ) + self . _scripts_to_prepend return self def append_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_append . extend ( scripts ) return self def initialize_image ( self , image : Union [ Image , str ]) -> JobSequence : \"\"\"Initializes given `image` to all downstream `Job`s which do not have an `image` set. Args: image (Union[Image, str]): The image to set to all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\"\" if image : self . _image_for_initialization = image return self def override_image ( self , image : Union [ Image , str ]) -> JobSequence : \"\"\"Initializes and override's `image` to all downstream `Job`s. In consequence, all downstream `Job`s will be started with `image`. Args: image (str): The image to set for all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\"\" if image : self . _image_for_replacement = image return self def _get_all_instance_names ( self , child : Union [ Job , JobSequence ]) -> Set [ str ]: instance_names : Set [ str ] = set () for parent in self . _parents : instance_names . update ( parent . _get_all_instance_names ( self )) child_instance_names : Set [ str ] = set () child_instance_name : str for item in self . _children : if item [ \"object\" ] == child : if item [ \"namespace\" ] is not None : if item [ \"name\" ]: child_instance_name = f \"{item['namespace']}-{item['name']}\" else : child_instance_name = item [ \"namespace\" ] elif item [ \"name\" ] is not None : child_instance_name = item [ \"name\" ] else : child_instance_name = \"#unset#\" # all job names have '-' instead of '_' child_instance_names . add ( child_instance_name . replace ( \"_\" , \"-\" )) return_values : Set [ str ] = set () # add instane names of this sequence to all instance # names of its children if instance_names : for child_instance_name in child_instance_names : for instance_name in instance_names : return_values . add ( f \"{child_instance_name}-{instance_name}\" ) else : return_values = child_instance_names return return_values @ property def last_jobs_executed ( self ) -> List [ Job ]: all_jobs = self . populated_jobs stages : Dict [ str , None ] = {} for job in all_jobs : # use the keys of dictionary as ordered set stages [ job . stage ] = None last_stage = list ( stages . keys ())[ - 1 ] last_executed_jobs : List [ Job ] = list () for job in all_jobs : if job . _stage == last_stage : if job . _original : last_executed_jobs . append ( job . _original ) else : raise AttributeError ( \"job._original is None, because the job is not a copy of another job\" ) return last_executed_jobs @ property def populated_jobs ( self ) -> List [ Job ]: all_jobs : List [ Job ] = [] for child in self . _children : if isinstance ( child [ \"object\" ], JobSequence ): for job_copy in child [ \"object\" ] . populated_jobs : job_copy . _extend_namespace ( child [ \"namespace\" ]) job_copy . _extend_name ( child [ \"name\" ]) all_jobs . append ( job_copy ) elif isinstance ( child [ \"object\" ], Job ): job_copy = child [ \"object\" ] . copy () job_copy . _extend_namespace ( child [ \"namespace\" ]) job_copy . _extend_name ( child [ \"name\" ]) all_jobs . append ( job_copy ) if len ( all_jobs ) > 0 : first_job = all_jobs [ 0 ] first_job . add_needs ( * self . _needs ) for job in all_jobs [ 1 :]: if job . _stage == first_job . stage : job . add_needs ( * self . _needs ) for job in all_jobs : if self . _image_for_initialization and not job . _image : job . set_image ( self . _image_for_initialization ) if self . _image_for_replacement : job . set_image ( self . _image_for_replacement ) if self . _variables_for_initialization and not job . _variables : job . _variables = copy . deepcopy ( self . _variables_for_initialization ) if self . _variables_for_replacement : job . _variables = copy . deepcopy ( self . _variables_for_replacement ) job . add_variables ( ** copy . deepcopy ( self . _variables )) if self . _cache_for_initialization and not job . _cache : job . _cache = copy . deepcopy ( self . _cache_for_initialization ) job . set_cache ( copy . deepcopy ( self . _cache )) if self . _tags_for_initialization and not job . _tags : job . _tags = copy . deepcopy ( self . _tags_for_initialization ) if self . _tags_for_replacement : job . _tags = copy . deepcopy ( self . _tags_for_replacement ) job . add_tags ( * list ( self . _tags . keys ())) job . add_artifacts_paths ( * list ( self . _artifacts_paths . keys ())) if self . _rules_for_initialization and not job . _rules : job . _rules = copy . deepcopy ( self . _rules_for_initialization ) if self . _rules_for_replacement : job . _rules = copy . deepcopy ( self . _rules_for_replacement ) job . append_rules ( * self . _rules_to_append ) job . prepend_rules ( * self . _rules_to_prepend ) job . prepend_scripts ( * self . _scripts_to_prepend ) job . append_scripts ( * self . _scripts_to_append ) return all_jobs","title":"JobSequence"},{"location":"reference/gcip/core/job_sequence/#descendants","text":"gcip.core.pipeline.Pipeline","title":"Descendants"},{"location":"reference/gcip/core/job_sequence/#instance-variables","text":"last_jobs_executed populated_jobs","title":"Instance variables"},{"location":"reference/gcip/core/job_sequence/#methods_1","text":"","title":"Methods"},{"location":"reference/gcip/core/job_sequence/#add_artifacts_paths","text":"def add_artifacts_paths ( self , * paths : 'str' ) -> 'JobSequence' View Source def add_artifacts_paths ( self , * paths : str ) -> JobSequence : for path in paths : self . _artifacts_paths [ path ] = None return self","title":"add_artifacts_paths"},{"location":"reference/gcip/core/job_sequence/#add_children","text":"def add_children ( self , * jobs_or_sequences : 'Union[Job, JobSequence]' , namespace : 'Optional[str]' = None , name : 'Optional[str]' = None ) -> 'JobSequence' View Source def add_children ( self , * jobs_or_sequences : Union [ Job, JobSequence ] , namespace : Optional [ str ] = None , name : Optional [ str ] = None ) -> JobSequence : for child in jobs_or_sequences : child . _add_parent ( self ) self . _children . append ( { \"object\" : child , \"namespace\" : namespace , \"name\" : name } ) return self","title":"add_children"},{"location":"reference/gcip/core/job_sequence/#add_needs","text":"def add_needs ( self , * needs : 'Union[Job, Need]' ) -> 'JobSequence' Only the first job of the sequence get the need appended to, as well as all following jobs with the same stage. View Source def add_needs ( self , * needs : Union [ Job , Need ] ) -> JobSequence : \" \"\" Only the first job of the sequence get the ``need`` appended to, as well as all following jobs with the same stage. \"\" \" self . _needs . extend ( needs ) return self","title":"add_needs"},{"location":"reference/gcip/core/job_sequence/#add_tags","text":"def add_tags ( self , * tags : 'str' ) -> 'JobSequence' View Source def add_tags ( self , * tags : str ) -> JobSequence : for tag in tags : self . _tags [ tag ] = None return self","title":"add_tags"},{"location":"reference/gcip/core/job_sequence/#add_variables","text":"def add_variables ( self , ** variables : 'str' ) -> 'JobSequence' View Source def add_variables ( self , ** variables : str ) -> JobSequence : self . _variables . update ( variables ) return self","title":"add_variables"},{"location":"reference/gcip/core/job_sequence/#append_rules","text":"def append_rules ( self , * rules : 'Rule' ) -> 'JobSequence' View Source def append_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_append . extend ( rules ) return self","title":"append_rules"},{"location":"reference/gcip/core/job_sequence/#append_scripts","text":"def append_scripts ( self , * scripts : 'str' ) -> 'JobSequence' View Source def append_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_append . extend ( scripts ) return self","title":"append_scripts"},{"location":"reference/gcip/core/job_sequence/#initialize_cache","text":"def initialize_cache ( self , cache : 'Cache' ) -> 'JobSequence' Sets the cache of child sequences/jobs only if not set before. Parameters: Name Type Description Default cache Cache Cache to use for the JobSequence and its Jobs. None Returns: Type Description JobSequence Returns the modified Sequence object. View Source def initialize_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache of child sequences/jobs only if not set before. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache_for_initialization = cache return self","title":"initialize_cache"},{"location":"reference/gcip/core/job_sequence/#initialize_image","text":"def initialize_image ( self , image : 'Union[Image, str]' ) -> 'JobSequence' Initializes given image to all downstream Job s which do not have an image set. Parameters: Name Type Description Default image Union[Image, str] The image to set to all downstream :class: Job 's. None Returns: Type Description JobSequence Modified sequence object. View Source def initialize_image ( self , image : Union [ Image , str ] ) -> JobSequence : \" \"\" Initializes given `image` to all downstream `Job`s which do not have an `image` set. Args: image (Union[Image, str]): The image to set to all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\" \" if image : self . _image_for_initialization = image return self","title":"initialize_image"},{"location":"reference/gcip/core/job_sequence/#initialize_rules","text":"def initialize_rules ( self , * rules : 'Rule' ) -> 'JobSequence' Works like :meth: initialize_tags but for rules. Parameters: Name Type Description Default rules Rule A list of :class: Rule s that will be applied to :class: Job s with empty rules list. None View Source def initialize_rules ( self , * rules : Rule ) -> JobSequence : \" \"\" Works like :meth:`initialize_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be applied to :class:`Job` s with empty rules list. \"\" \" self . _rules_for_initialization . extend ( rules ) return self","title":"initialize_rules"},{"location":"reference/gcip/core/job_sequence/#initialize_tags","text":"def initialize_tags ( self , * tags : 'str' ) -> 'JobSequence' Adds tags to downstream :class: Job s only if they haven't tags added yet. View Source def initialize_tags ( self , * tags : str ) -> JobSequence : \" \"\" Adds tags to downstream :class:`Job` s only if they haven't tags added yet. :meth:`initialize_tags` would be extended by :meth:`add_tags` and overridden by :meth:`override_tags` if one of the other methods is called too. Args: tags (str): One or more strings that will be applied to :class:`Job` s with empty tag list. \"\" \" for tag in tags : self . _tags_for_initialization [ tag ] = None return self","title":"initialize_tags"},{"location":"reference/gcip/core/job_sequence/#initialize_variables","text":"def initialize_variables ( self , ** variables : 'str' ) -> 'JobSequence' Works like :meth: initialize_tags but for variales. Parameters: Name Type Description Default variables str A keyword argument list which key-value-pairs will be applied as variable-value-pairs to all downstream :class: Job s without variables already set. None View Source def initialize_variables ( self , ** variables : str ) -> JobSequence : \" \"\" Works like :meth:`initialize_tags` but for variales. Args: variables (str): A keyword argument list which key-value-pairs will be applied as variable-value-pairs to all downstream :class:`Job` s without variables already set. \"\" \" self . _variables_for_initialization . update ( variables ) return self","title":"initialize_variables"},{"location":"reference/gcip/core/job_sequence/#override_image","text":"def override_image ( self , image : 'Union[Image, str]' ) -> 'JobSequence' Initializes and override's image to all downstream Job s. In consequence, all downstream Job s will be started with image . Parameters: Name Type Description Default image str The image to set for all downstream :class: Job 's. None Returns: Type Description JobSequence Modified sequence object. View Source def override_image ( self , image : Union [ Image , str ] ) -> JobSequence : \" \"\" Initializes and override's `image` to all downstream `Job`s. In consequence, all downstream `Job`s will be started with `image`. Args: image (str): The image to set for all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\" \" if image : self . _image_for_replacement = image return self","title":"override_image"},{"location":"reference/gcip/core/job_sequence/#override_rules","text":"def override_rules ( self , * rules : 'Rule' ) -> 'JobSequence' Works like :meth: override_tags but for rules. Parameters: Name Type Description Default rules Rule A list of :class: Rule s that will be replace all downstream :class: Job s rules. None View Source def override_rules ( self , * rules : Rule ) -> JobSequence : \" \"\" Works like :meth:`override_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be replace all downstream :class:`Job` s rules. \"\" \" self . _rules_for_replacement . extend ( rules ) return self","title":"override_rules"},{"location":"reference/gcip/core/job_sequence/#override_tags","text":"def override_tags ( self , * tags : 'str' ) -> 'JobSequence' Will replace all tags from downstream :class: Job s. View Source def override_tags ( self , * tags : str ) -> JobSequence : \" \"\" Will replace all tags from downstream :class:`Job` s. :meth:`override_tags` will also override tags set by :meth:`initialize_tags` but be extended by :meth:`add_tags` when one of the other methods is called too. Args: tags (str): One or more strings that will be set as tags to all downstream :class:`Job` s. \"\" \" for tag in tags : self . _tags_for_replacement [ tag ] = None return self","title":"override_tags"},{"location":"reference/gcip/core/job_sequence/#override_variables","text":"def override_variables ( self , ** variables : 'str' ) -> 'JobSequence' Works like :meth: override_tags but for variables. Parameters: Name Type Description Default variables str A keyword argument list which key-value-pairs will be set as variable-value-pairs to all downstream :class: Job s. None View Source def override_variables ( self , ** variables : str ) -> JobSequence : \" \"\" Works like :meth:`override_tags` but for variables. Args: variables (str): A keyword argument list which key-value-pairs will be set as variable-value-pairs to all downstream :class:`Job` s. \"\" \" self . _variables_for_replacement . update ( variables ) return self","title":"override_variables"},{"location":"reference/gcip/core/job_sequence/#prepend_rules","text":"def prepend_rules ( self , * rules : 'Rule' ) -> 'JobSequence' View Source def prepend_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_prepend = list ( rules ) + self . _rules_to_prepend return self","title":"prepend_rules"},{"location":"reference/gcip/core/job_sequence/#prepend_scripts","text":"def prepend_scripts ( self , * scripts : 'str' ) -> 'JobSequence' View Source def prepend_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_prepend = list ( scripts ) + self . _scripts_to_prepend return self","title":"prepend_scripts"},{"location":"reference/gcip/core/job_sequence/#set_cache","text":"def set_cache ( self , cache : 'Cache' ) -> 'JobSequence' Sets the cache for the corresponding JobSequence. This will override any previously set chaches on this sequence or child sequences/jobs. Parameters: Name Type Description Default cache Cache Cache to use for the JobSequence and its Jobs. None Returns: Type Description JobSequence Returns the modified Sequence object. View Source def set_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache for the corresponding JobSequence. This will override any previously set chaches on this sequence or child sequences/jobs. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache = cache return self","title":"set_cache"},{"location":"reference/gcip/core/need/","text":"Module gcip.core.need None None View Source from __future__ import annotations from typing import Dict , Union , Optional class Need ( object ): def __init__ ( self , job : str , * , project : Optional [ str ] = None , ref : Optional [ str ] = None , artifacts : bool = True , ): \"\"\" Class to add `needs` to :class:`Job` The `needs` key-word adds a possibility to allow out-of-order Gitlab CI jobs. A job which needed another job runs directly after `another job` as finished successfully. For more in depth information see `Gitlab CI Reference needs`_, `Directed Acyclic Graph`_. Args: job (str): A job's name as :class:`str`. project (Optional[str]): Remote Gitlab Project to add the `dependency` from. Defaults to None. ref (Optional[str]): Branch of the remote project to depend on. Defaults to None. artifacts (bool): Download artifacts generated by ``job``. Defaults to True. Raises: ValueError: If ``ref`` is set but ``project`` is missing. .. _Gitlab CI Reference needs: https://docs.gitlab.com/ee/ci/yaml/#needs .. _Directed Acyclic Graph: https://docs.gitlab.com/ee/ci/directed_acyclic_graph/index.html \"\"\" if ref and not project : raise ValueError ( \"'ref' parameter requires the 'project' parameter.\" ) self . _job = job self . _project = project self . _ref = ref self . _artifacts = artifacts if self . _project and not self . _ref : self . _ref = \"main\" def render ( self ) -> Dict [ str , Union [ str , bool ]]: \"\"\" Renders the :class:`Need` object. Returns the :obj:`dict` representation of the object \"\"\" rendered_need : Dict [ str , Union [ str , bool ]] = { \"job\" : self . _job , \"artifacts\" : self . _artifacts } if self . _project and self . _ref : rendered_need . update ({ \"project\" : self . _project , \"ref\" : self . _ref }) return rendered_need Classes Need class Need ( job : 'str' , * , project : 'Optional[str]' = None , ref : 'Optional[str]' = None , artifacts : 'bool' = True ) View Source class Need ( object ) : def __init__ ( self , job : str , * , project : Optional [ str ] = None , ref : Optional [ str ] = None , artifacts : bool = True , ) : \" \"\" Class to add `needs` to :class:`Job` The `needs` key-word adds a possibility to allow out-of-order Gitlab CI jobs. A job which needed another job runs directly after `another job` as finished successfully. For more in depth information see `Gitlab CI Reference needs`_, `Directed Acyclic Graph`_. Args: job (str): A job's name as :class:`str`. project (Optional[str]): Remote Gitlab Project to add the `dependency` from. Defaults to None. ref (Optional[str]): Branch of the remote project to depend on. Defaults to None. artifacts (bool): Download artifacts generated by ``job``. Defaults to True. Raises: ValueError: If ``ref`` is set but ``project`` is missing. .. _Gitlab CI Reference needs: https://docs.gitlab.com/ee/ci/yaml/#needs .. _Directed Acyclic Graph: https://docs.gitlab.com/ee/ci/directed_acyclic_graph/index.html \"\" \" if ref and not project : raise ValueError ( \"'ref' parameter requires the 'project' parameter.\" ) self . _job = job self . _project = project self . _ref = ref self . _artifacts = artifacts if self . _project and not self . _ref : self . _ref = \"main\" def render ( self ) -> Dict [ str , Union [ str , bool ]] : \" \"\" Renders the :class:`Need` object. Returns the :obj:`dict` representation of the object \"\" \" rendered_need : Dict [ str , Union [ str , bool ]] = { \"job\" : self . _job , \"artifacts\" : self . _artifacts } if self . _project and self . _ref : rendered_need . update ( { \"project\" : self . _project , \"ref\" : self . _ref } ) return rendered_need Methods render def render ( self ) -> 'Dict[str, Union[str, bool]]' Renders the :class: Need object. Returns the :obj: dict representation of the object View Source def render ( self ) -> Dict [ str , Union [ str , bool ]] : \" \"\" Renders the :class:`Need` object. Returns the :obj:`dict` representation of the object \"\" \" rendered_need : Dict [ str , Union [ str , bool ]] = { \"job\" : self . _job , \"artifacts\" : self . _artifacts } if self . _project and self . _ref : rendered_need . update ( { \"project\" : self . _project , \"ref\" : self . _ref } ) return rendered_need","title":"Need"},{"location":"reference/gcip/core/need/#module-gcipcoreneed","text":"None None View Source from __future__ import annotations from typing import Dict , Union , Optional class Need ( object ): def __init__ ( self , job : str , * , project : Optional [ str ] = None , ref : Optional [ str ] = None , artifacts : bool = True , ): \"\"\" Class to add `needs` to :class:`Job` The `needs` key-word adds a possibility to allow out-of-order Gitlab CI jobs. A job which needed another job runs directly after `another job` as finished successfully. For more in depth information see `Gitlab CI Reference needs`_, `Directed Acyclic Graph`_. Args: job (str): A job's name as :class:`str`. project (Optional[str]): Remote Gitlab Project to add the `dependency` from. Defaults to None. ref (Optional[str]): Branch of the remote project to depend on. Defaults to None. artifacts (bool): Download artifacts generated by ``job``. Defaults to True. Raises: ValueError: If ``ref`` is set but ``project`` is missing. .. _Gitlab CI Reference needs: https://docs.gitlab.com/ee/ci/yaml/#needs .. _Directed Acyclic Graph: https://docs.gitlab.com/ee/ci/directed_acyclic_graph/index.html \"\"\" if ref and not project : raise ValueError ( \"'ref' parameter requires the 'project' parameter.\" ) self . _job = job self . _project = project self . _ref = ref self . _artifacts = artifacts if self . _project and not self . _ref : self . _ref = \"main\" def render ( self ) -> Dict [ str , Union [ str , bool ]]: \"\"\" Renders the :class:`Need` object. Returns the :obj:`dict` representation of the object \"\"\" rendered_need : Dict [ str , Union [ str , bool ]] = { \"job\" : self . _job , \"artifacts\" : self . _artifacts } if self . _project and self . _ref : rendered_need . update ({ \"project\" : self . _project , \"ref\" : self . _ref }) return rendered_need","title":"Module gcip.core.need"},{"location":"reference/gcip/core/need/#classes","text":"","title":"Classes"},{"location":"reference/gcip/core/need/#need","text":"class Need ( job : 'str' , * , project : 'Optional[str]' = None , ref : 'Optional[str]' = None , artifacts : 'bool' = True ) View Source class Need ( object ) : def __init__ ( self , job : str , * , project : Optional [ str ] = None , ref : Optional [ str ] = None , artifacts : bool = True , ) : \" \"\" Class to add `needs` to :class:`Job` The `needs` key-word adds a possibility to allow out-of-order Gitlab CI jobs. A job which needed another job runs directly after `another job` as finished successfully. For more in depth information see `Gitlab CI Reference needs`_, `Directed Acyclic Graph`_. Args: job (str): A job's name as :class:`str`. project (Optional[str]): Remote Gitlab Project to add the `dependency` from. Defaults to None. ref (Optional[str]): Branch of the remote project to depend on. Defaults to None. artifacts (bool): Download artifacts generated by ``job``. Defaults to True. Raises: ValueError: If ``ref`` is set but ``project`` is missing. .. _Gitlab CI Reference needs: https://docs.gitlab.com/ee/ci/yaml/#needs .. _Directed Acyclic Graph: https://docs.gitlab.com/ee/ci/directed_acyclic_graph/index.html \"\" \" if ref and not project : raise ValueError ( \"'ref' parameter requires the 'project' parameter.\" ) self . _job = job self . _project = project self . _ref = ref self . _artifacts = artifacts if self . _project and not self . _ref : self . _ref = \"main\" def render ( self ) -> Dict [ str , Union [ str , bool ]] : \" \"\" Renders the :class:`Need` object. Returns the :obj:`dict` representation of the object \"\" \" rendered_need : Dict [ str , Union [ str , bool ]] = { \"job\" : self . _job , \"artifacts\" : self . _artifacts } if self . _project and self . _ref : rendered_need . update ( { \"project\" : self . _project , \"ref\" : self . _ref } ) return rendered_need","title":"Need"},{"location":"reference/gcip/core/need/#methods","text":"","title":"Methods"},{"location":"reference/gcip/core/need/#render","text":"def render ( self ) -> 'Dict[str, Union[str, bool]]' Renders the :class: Need object. Returns the :obj: dict representation of the object View Source def render ( self ) -> Dict [ str , Union [ str , bool ]] : \" \"\" Renders the :class:`Need` object. Returns the :obj:`dict` representation of the object \"\" \" rendered_need : Dict [ str , Union [ str , bool ]] = { \"job\" : self . _job , \"artifacts\" : self . _artifacts } if self . _project and self . _ref : rendered_need . update ( { \"project\" : self . _project , \"ref\" : self . _ref } ) return rendered_need","title":"render"},{"location":"reference/gcip/core/pipeline/","text":"Module gcip.core.pipeline None None View Source from typing import Any , Dict , List , Union , Optional from . import OrderedSetType from .include import Include from .job_sequence import JobSequence __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' class Pipeline ( JobSequence ): def __init__ ( self , * , includes : Optional [ Union [ Include , List [ Include ]]] = None ): \"\"\" Pipeline class creates an empty Gitlab pipeline. Args: includes (Optional[Union[Include, List[Include]]]): You can add global Gitlab includes. See `Gitlab CI Reference include`_. Defaults to None. Raises: ValueError: If ``includes`` is not of type :class:`list` or :class:`list` of :class:`Includes` .. _Gitlab CI Reference include: https://docs.gitlab.com/ee/ci/yaml/#include \"\"\" if not includes : self . _includes = [] elif isinstance ( includes , Include ): self . _includes = [ includes ] elif isinstance ( includes , list ): self . _includes = includes else : raise ValueError ( \"Parameter include must of type gcip.Include or List[gcip.Include]\" ) super () . __init__ () def render ( self ) -> Dict [ str , Any ]: stages : OrderedSetType = {} pipline : Dict [ str , Any ] = {} job_copies = self . populated_jobs for job in job_copies : # use the keys of dictionary as ordered set stages [ job . stage ] = None if self . _includes : pipline [ \"include\" ] = [ include . render () for include in self . _includes ] pipline [ \"stages\" ] = list ( stages . keys ()) for job in job_copies : pipline [ job . name ] = job . render () return pipline def add_include ( self , include : Include ) -> None : self . _includes . append ( include ) def dump_yaml ( self ) -> None : import yaml print ( yaml . dump ( self . render (), default_flow_style = False , sort_keys = False )) def write_yaml ( self , filename : str = \"generated-config.yml\" ) -> None : import yaml with open ( filename , \"w\" ) as generated_config : generated_config . write ( yaml . dump ( self . render (), default_flow_style = False , sort_keys = False )) Classes Pipeline class Pipeline ( * , includes : Union [ gcip . core . include . Include , List [ gcip . core . include . Include ], NoneType ] = None ) View Source class Pipeline ( JobSequence ) : def __init__ ( self , * , includes : Optional [ Union [ Include , List [ Include ]]] = None ) : \" \"\" Pipeline class creates an empty Gitlab pipeline. Args: includes (Optional[Union[Include, List[Include]]]): You can add global Gitlab includes. See `Gitlab CI Reference include`_. Defaults to None. Raises: ValueError: If ``includes`` is not of type :class:`list` or :class:`list` of :class:`Includes` .. _Gitlab CI Reference include: https://docs.gitlab.com/ee/ci/yaml/#include \"\" \" if not includes : self . _includes = [] elif isinstance ( includes , Include ) : self . _includes = [ includes ] elif isinstance ( includes , list ) : self . _includes = includes else : raise ValueError ( \"Parameter include must of type gcip.Include or List[gcip.Include]\" ) super (). __init__ () def render ( self ) -> Dict [ str , Any ] : stages : OrderedSetType = {} pipline : Dict [ str , Any ] = {} job_copies = self . populated_jobs for job in job_copies : # use the keys of dictionary as ordered set stages [ job . stage ] = None if self . _includes : pipline [ \"include\" ] = [ include . render () for include in self . _includes ] pipline [ \"stages\" ] = list ( stages . keys ()) for job in job_copies : pipline [ job . name ] = job . render () return pipline def add_include ( self , include : Include ) -> None : self . _includes . append ( include ) def dump_yaml ( self ) -> None : import yaml print ( yaml . dump ( self . render (), default_flow_style = False , sort_keys = False )) def write_yaml ( self , filename : str = \"generated-config.yml\" ) -> None : import yaml with open ( filename , \"w\" ) as generated_config : generated_config . write ( yaml . dump ( self . render (), default_flow_style = False , sort_keys = False )) Ancestors (in MRO) gcip.core.job_sequence.JobSequence Instance variables last_jobs_executed populated_jobs Methods add_artifacts_paths def add_artifacts_paths ( self , * paths : 'str' ) -> 'JobSequence' View Source def add_artifacts_paths ( self , * paths : str ) -> JobSequence : for path in paths : self . _artifacts_paths [ path ] = None return self add_children def add_children ( self , * jobs_or_sequences : 'Union[Job, JobSequence]' , namespace : 'Optional[str]' = None , name : 'Optional[str]' = None ) -> 'JobSequence' View Source def add_children ( self , * jobs_or_sequences : Union [ Job, JobSequence ] , namespace : Optional [ str ] = None , name : Optional [ str ] = None ) -> JobSequence : for child in jobs_or_sequences : child . _add_parent ( self ) self . _children . append ( { \"object\" : child , \"namespace\" : namespace , \"name\" : name } ) return self add_include def add_include ( self , include : gcip . core . include . Include ) -> None View Source def add_include ( self , include : Include ) -> None : self . _includes . append ( include ) add_needs def add_needs ( self , * needs : 'Union[Job, Need]' ) -> 'JobSequence' Only the first job of the sequence get the need appended to, as well as all following jobs with the same stage. View Source def add_needs ( self , * needs : Union [ Job , Need ] ) -> JobSequence : \" \"\" Only the first job of the sequence get the ``need`` appended to, as well as all following jobs with the same stage. \"\" \" self . _needs . extend ( needs ) return self add_tags def add_tags ( self , * tags : 'str' ) -> 'JobSequence' View Source def add_tags ( self , * tags : str ) -> JobSequence : for tag in tags : self . _tags [ tag ] = None return self add_variables def add_variables ( self , ** variables : 'str' ) -> 'JobSequence' View Source def add_variables ( self , ** variables : str ) -> JobSequence : self . _variables . update ( variables ) return self append_rules def append_rules ( self , * rules : 'Rule' ) -> 'JobSequence' View Source def append_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_append . extend ( rules ) return self append_scripts def append_scripts ( self , * scripts : 'str' ) -> 'JobSequence' View Source def append_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_append . extend ( scripts ) return self dump_yaml def dump_yaml ( self ) -> None View Source def dump_yaml ( self ) -> None : import yaml print ( yaml . dump ( self . render (), default_flow_style = False , sort_keys = False )) initialize_cache def initialize_cache ( self , cache : 'Cache' ) -> 'JobSequence' Sets the cache of child sequences/jobs only if not set before. Parameters: Name Type Description Default cache Cache Cache to use for the JobSequence and its Jobs. None Returns: Type Description JobSequence Returns the modified Sequence object. View Source def initialize_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache of child sequences/jobs only if not set before. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache_for_initialization = cache return self initialize_image def initialize_image ( self , image : 'Union[Image, str]' ) -> 'JobSequence' Initializes given image to all downstream Job s which do not have an image set. Parameters: Name Type Description Default image Union[Image, str] The image to set to all downstream :class: Job 's. None Returns: Type Description JobSequence Modified sequence object. View Source def initialize_image ( self , image : Union [ Image , str ] ) -> JobSequence : \" \"\" Initializes given `image` to all downstream `Job`s which do not have an `image` set. Args: image (Union[Image, str]): The image to set to all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\" \" if image : self . _image_for_initialization = image return self initialize_rules def initialize_rules ( self , * rules : 'Rule' ) -> 'JobSequence' Works like :meth: initialize_tags but for rules. Parameters: Name Type Description Default rules Rule A list of :class: Rule s that will be applied to :class: Job s with empty rules list. None View Source def initialize_rules ( self , * rules : Rule ) -> JobSequence : \" \"\" Works like :meth:`initialize_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be applied to :class:`Job` s with empty rules list. \"\" \" self . _rules_for_initialization . extend ( rules ) return self initialize_tags def initialize_tags ( self , * tags : 'str' ) -> 'JobSequence' Adds tags to downstream :class: Job s only if they haven't tags added yet. View Source def initialize_tags ( self , * tags : str ) -> JobSequence : \" \"\" Adds tags to downstream :class:`Job` s only if they haven't tags added yet. :meth:`initialize_tags` would be extended by :meth:`add_tags` and overridden by :meth:`override_tags` if one of the other methods is called too. Args: tags (str): One or more strings that will be applied to :class:`Job` s with empty tag list. \"\" \" for tag in tags : self . _tags_for_initialization [ tag ] = None return self initialize_variables def initialize_variables ( self , ** variables : 'str' ) -> 'JobSequence' Works like :meth: initialize_tags but for variales. Parameters: Name Type Description Default variables str A keyword argument list which key-value-pairs will be applied as variable-value-pairs to all downstream :class: Job s without variables already set. None View Source def initialize_variables ( self , ** variables : str ) -> JobSequence : \" \"\" Works like :meth:`initialize_tags` but for variales. Args: variables (str): A keyword argument list which key-value-pairs will be applied as variable-value-pairs to all downstream :class:`Job` s without variables already set. \"\" \" self . _variables_for_initialization . update ( variables ) return self override_image def override_image ( self , image : 'Union[Image, str]' ) -> 'JobSequence' Initializes and override's image to all downstream Job s. In consequence, all downstream Job s will be started with image . Parameters: Name Type Description Default image str The image to set for all downstream :class: Job 's. None Returns: Type Description JobSequence Modified sequence object. View Source def override_image ( self , image : Union [ Image , str ] ) -> JobSequence : \" \"\" Initializes and override's `image` to all downstream `Job`s. In consequence, all downstream `Job`s will be started with `image`. Args: image (str): The image to set for all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\" \" if image : self . _image_for_replacement = image return self override_rules def override_rules ( self , * rules : 'Rule' ) -> 'JobSequence' Works like :meth: override_tags but for rules. Parameters: Name Type Description Default rules Rule A list of :class: Rule s that will be replace all downstream :class: Job s rules. None View Source def override_rules ( self , * rules : Rule ) -> JobSequence : \" \"\" Works like :meth:`override_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be replace all downstream :class:`Job` s rules. \"\" \" self . _rules_for_replacement . extend ( rules ) return self override_tags def override_tags ( self , * tags : 'str' ) -> 'JobSequence' Will replace all tags from downstream :class: Job s. View Source def override_tags ( self , * tags : str ) -> JobSequence : \" \"\" Will replace all tags from downstream :class:`Job` s. :meth:`override_tags` will also override tags set by :meth:`initialize_tags` but be extended by :meth:`add_tags` when one of the other methods is called too. Args: tags (str): One or more strings that will be set as tags to all downstream :class:`Job` s. \"\" \" for tag in tags : self . _tags_for_replacement [ tag ] = None return self override_variables def override_variables ( self , ** variables : 'str' ) -> 'JobSequence' Works like :meth: override_tags but for variables. Parameters: Name Type Description Default variables str A keyword argument list which key-value-pairs will be set as variable-value-pairs to all downstream :class: Job s. None View Source def override_variables ( self , ** variables : str ) -> JobSequence : \" \"\" Works like :meth:`override_tags` but for variables. Args: variables (str): A keyword argument list which key-value-pairs will be set as variable-value-pairs to all downstream :class:`Job` s. \"\" \" self . _variables_for_replacement . update ( variables ) return self prepend_rules def prepend_rules ( self , * rules : 'Rule' ) -> 'JobSequence' View Source def prepend_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_prepend = list ( rules ) + self . _rules_to_prepend return self prepend_scripts def prepend_scripts ( self , * scripts : 'str' ) -> 'JobSequence' View Source def prepend_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_prepend = list ( scripts ) + self . _scripts_to_prepend return self render def render ( self ) -> Dict [ str , Any ] View Source def render ( self ) -> Dict [ str , Any ]: stages : OrderedSetType = {} pipline : Dict [ str , Any ] = {} job_copies = self . populated_jobs for job in job_copies : # use the keys of dictionary as ordered set stages [ job . stage ] = None if self . _includes : pipline [ \"include\" ] = [ include . render () for include in self . _includes ] pipline [ \"stages\" ] = list ( stages . keys ()) for job in job_copies : pipline [ job . name ] = job . render () return pipline set_cache def set_cache ( self , cache : 'Cache' ) -> 'JobSequence' Sets the cache for the corresponding JobSequence. This will override any previously set chaches on this sequence or child sequences/jobs. Parameters: Name Type Description Default cache Cache Cache to use for the JobSequence and its Jobs. None Returns: Type Description JobSequence Returns the modified Sequence object. View Source def set_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache for the corresponding JobSequence. This will override any previously set chaches on this sequence or child sequences/jobs. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache = cache return self write_yaml def write_yaml ( self , filename : str = 'generated-config.yml' ) -> None View Source def write_yaml ( self , filename : str = \"generated-config.yml\" ) -> None : import yaml with open ( filename , \"w\" ) as generated_config : generated_config . write ( yaml . dump ( self . render (), default_flow_style = False , sort_keys = False ))","title":"Pipeline"},{"location":"reference/gcip/core/pipeline/#module-gcipcorepipeline","text":"None None View Source from typing import Any , Dict , List , Union , Optional from . import OrderedSetType from .include import Include from .job_sequence import JobSequence __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' class Pipeline ( JobSequence ): def __init__ ( self , * , includes : Optional [ Union [ Include , List [ Include ]]] = None ): \"\"\" Pipeline class creates an empty Gitlab pipeline. Args: includes (Optional[Union[Include, List[Include]]]): You can add global Gitlab includes. See `Gitlab CI Reference include`_. Defaults to None. Raises: ValueError: If ``includes`` is not of type :class:`list` or :class:`list` of :class:`Includes` .. _Gitlab CI Reference include: https://docs.gitlab.com/ee/ci/yaml/#include \"\"\" if not includes : self . _includes = [] elif isinstance ( includes , Include ): self . _includes = [ includes ] elif isinstance ( includes , list ): self . _includes = includes else : raise ValueError ( \"Parameter include must of type gcip.Include or List[gcip.Include]\" ) super () . __init__ () def render ( self ) -> Dict [ str , Any ]: stages : OrderedSetType = {} pipline : Dict [ str , Any ] = {} job_copies = self . populated_jobs for job in job_copies : # use the keys of dictionary as ordered set stages [ job . stage ] = None if self . _includes : pipline [ \"include\" ] = [ include . render () for include in self . _includes ] pipline [ \"stages\" ] = list ( stages . keys ()) for job in job_copies : pipline [ job . name ] = job . render () return pipline def add_include ( self , include : Include ) -> None : self . _includes . append ( include ) def dump_yaml ( self ) -> None : import yaml print ( yaml . dump ( self . render (), default_flow_style = False , sort_keys = False )) def write_yaml ( self , filename : str = \"generated-config.yml\" ) -> None : import yaml with open ( filename , \"w\" ) as generated_config : generated_config . write ( yaml . dump ( self . render (), default_flow_style = False , sort_keys = False ))","title":"Module gcip.core.pipeline"},{"location":"reference/gcip/core/pipeline/#classes","text":"","title":"Classes"},{"location":"reference/gcip/core/pipeline/#pipeline","text":"class Pipeline ( * , includes : Union [ gcip . core . include . Include , List [ gcip . core . include . Include ], NoneType ] = None ) View Source class Pipeline ( JobSequence ) : def __init__ ( self , * , includes : Optional [ Union [ Include , List [ Include ]]] = None ) : \" \"\" Pipeline class creates an empty Gitlab pipeline. Args: includes (Optional[Union[Include, List[Include]]]): You can add global Gitlab includes. See `Gitlab CI Reference include`_. Defaults to None. Raises: ValueError: If ``includes`` is not of type :class:`list` or :class:`list` of :class:`Includes` .. _Gitlab CI Reference include: https://docs.gitlab.com/ee/ci/yaml/#include \"\" \" if not includes : self . _includes = [] elif isinstance ( includes , Include ) : self . _includes = [ includes ] elif isinstance ( includes , list ) : self . _includes = includes else : raise ValueError ( \"Parameter include must of type gcip.Include or List[gcip.Include]\" ) super (). __init__ () def render ( self ) -> Dict [ str , Any ] : stages : OrderedSetType = {} pipline : Dict [ str , Any ] = {} job_copies = self . populated_jobs for job in job_copies : # use the keys of dictionary as ordered set stages [ job . stage ] = None if self . _includes : pipline [ \"include\" ] = [ include . render () for include in self . _includes ] pipline [ \"stages\" ] = list ( stages . keys ()) for job in job_copies : pipline [ job . name ] = job . render () return pipline def add_include ( self , include : Include ) -> None : self . _includes . append ( include ) def dump_yaml ( self ) -> None : import yaml print ( yaml . dump ( self . render (), default_flow_style = False , sort_keys = False )) def write_yaml ( self , filename : str = \"generated-config.yml\" ) -> None : import yaml with open ( filename , \"w\" ) as generated_config : generated_config . write ( yaml . dump ( self . render (), default_flow_style = False , sort_keys = False ))","title":"Pipeline"},{"location":"reference/gcip/core/pipeline/#ancestors-in-mro","text":"gcip.core.job_sequence.JobSequence","title":"Ancestors (in MRO)"},{"location":"reference/gcip/core/pipeline/#instance-variables","text":"last_jobs_executed populated_jobs","title":"Instance variables"},{"location":"reference/gcip/core/pipeline/#methods","text":"","title":"Methods"},{"location":"reference/gcip/core/pipeline/#add_artifacts_paths","text":"def add_artifacts_paths ( self , * paths : 'str' ) -> 'JobSequence' View Source def add_artifacts_paths ( self , * paths : str ) -> JobSequence : for path in paths : self . _artifacts_paths [ path ] = None return self","title":"add_artifacts_paths"},{"location":"reference/gcip/core/pipeline/#add_children","text":"def add_children ( self , * jobs_or_sequences : 'Union[Job, JobSequence]' , namespace : 'Optional[str]' = None , name : 'Optional[str]' = None ) -> 'JobSequence' View Source def add_children ( self , * jobs_or_sequences : Union [ Job, JobSequence ] , namespace : Optional [ str ] = None , name : Optional [ str ] = None ) -> JobSequence : for child in jobs_or_sequences : child . _add_parent ( self ) self . _children . append ( { \"object\" : child , \"namespace\" : namespace , \"name\" : name } ) return self","title":"add_children"},{"location":"reference/gcip/core/pipeline/#add_include","text":"def add_include ( self , include : gcip . core . include . Include ) -> None View Source def add_include ( self , include : Include ) -> None : self . _includes . append ( include )","title":"add_include"},{"location":"reference/gcip/core/pipeline/#add_needs","text":"def add_needs ( self , * needs : 'Union[Job, Need]' ) -> 'JobSequence' Only the first job of the sequence get the need appended to, as well as all following jobs with the same stage. View Source def add_needs ( self , * needs : Union [ Job , Need ] ) -> JobSequence : \" \"\" Only the first job of the sequence get the ``need`` appended to, as well as all following jobs with the same stage. \"\" \" self . _needs . extend ( needs ) return self","title":"add_needs"},{"location":"reference/gcip/core/pipeline/#add_tags","text":"def add_tags ( self , * tags : 'str' ) -> 'JobSequence' View Source def add_tags ( self , * tags : str ) -> JobSequence : for tag in tags : self . _tags [ tag ] = None return self","title":"add_tags"},{"location":"reference/gcip/core/pipeline/#add_variables","text":"def add_variables ( self , ** variables : 'str' ) -> 'JobSequence' View Source def add_variables ( self , ** variables : str ) -> JobSequence : self . _variables . update ( variables ) return self","title":"add_variables"},{"location":"reference/gcip/core/pipeline/#append_rules","text":"def append_rules ( self , * rules : 'Rule' ) -> 'JobSequence' View Source def append_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_append . extend ( rules ) return self","title":"append_rules"},{"location":"reference/gcip/core/pipeline/#append_scripts","text":"def append_scripts ( self , * scripts : 'str' ) -> 'JobSequence' View Source def append_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_append . extend ( scripts ) return self","title":"append_scripts"},{"location":"reference/gcip/core/pipeline/#dump_yaml","text":"def dump_yaml ( self ) -> None View Source def dump_yaml ( self ) -> None : import yaml print ( yaml . dump ( self . render (), default_flow_style = False , sort_keys = False ))","title":"dump_yaml"},{"location":"reference/gcip/core/pipeline/#initialize_cache","text":"def initialize_cache ( self , cache : 'Cache' ) -> 'JobSequence' Sets the cache of child sequences/jobs only if not set before. Parameters: Name Type Description Default cache Cache Cache to use for the JobSequence and its Jobs. None Returns: Type Description JobSequence Returns the modified Sequence object. View Source def initialize_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache of child sequences/jobs only if not set before. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache_for_initialization = cache return self","title":"initialize_cache"},{"location":"reference/gcip/core/pipeline/#initialize_image","text":"def initialize_image ( self , image : 'Union[Image, str]' ) -> 'JobSequence' Initializes given image to all downstream Job s which do not have an image set. Parameters: Name Type Description Default image Union[Image, str] The image to set to all downstream :class: Job 's. None Returns: Type Description JobSequence Modified sequence object. View Source def initialize_image ( self , image : Union [ Image , str ] ) -> JobSequence : \" \"\" Initializes given `image` to all downstream `Job`s which do not have an `image` set. Args: image (Union[Image, str]): The image to set to all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\" \" if image : self . _image_for_initialization = image return self","title":"initialize_image"},{"location":"reference/gcip/core/pipeline/#initialize_rules","text":"def initialize_rules ( self , * rules : 'Rule' ) -> 'JobSequence' Works like :meth: initialize_tags but for rules. Parameters: Name Type Description Default rules Rule A list of :class: Rule s that will be applied to :class: Job s with empty rules list. None View Source def initialize_rules ( self , * rules : Rule ) -> JobSequence : \" \"\" Works like :meth:`initialize_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be applied to :class:`Job` s with empty rules list. \"\" \" self . _rules_for_initialization . extend ( rules ) return self","title":"initialize_rules"},{"location":"reference/gcip/core/pipeline/#initialize_tags","text":"def initialize_tags ( self , * tags : 'str' ) -> 'JobSequence' Adds tags to downstream :class: Job s only if they haven't tags added yet. View Source def initialize_tags ( self , * tags : str ) -> JobSequence : \" \"\" Adds tags to downstream :class:`Job` s only if they haven't tags added yet. :meth:`initialize_tags` would be extended by :meth:`add_tags` and overridden by :meth:`override_tags` if one of the other methods is called too. Args: tags (str): One or more strings that will be applied to :class:`Job` s with empty tag list. \"\" \" for tag in tags : self . _tags_for_initialization [ tag ] = None return self","title":"initialize_tags"},{"location":"reference/gcip/core/pipeline/#initialize_variables","text":"def initialize_variables ( self , ** variables : 'str' ) -> 'JobSequence' Works like :meth: initialize_tags but for variales. Parameters: Name Type Description Default variables str A keyword argument list which key-value-pairs will be applied as variable-value-pairs to all downstream :class: Job s without variables already set. None View Source def initialize_variables ( self , ** variables : str ) -> JobSequence : \" \"\" Works like :meth:`initialize_tags` but for variales. Args: variables (str): A keyword argument list which key-value-pairs will be applied as variable-value-pairs to all downstream :class:`Job` s without variables already set. \"\" \" self . _variables_for_initialization . update ( variables ) return self","title":"initialize_variables"},{"location":"reference/gcip/core/pipeline/#override_image","text":"def override_image ( self , image : 'Union[Image, str]' ) -> 'JobSequence' Initializes and override's image to all downstream Job s. In consequence, all downstream Job s will be started with image . Parameters: Name Type Description Default image str The image to set for all downstream :class: Job 's. None Returns: Type Description JobSequence Modified sequence object. View Source def override_image ( self , image : Union [ Image , str ] ) -> JobSequence : \" \"\" Initializes and override's `image` to all downstream `Job`s. In consequence, all downstream `Job`s will be started with `image`. Args: image (str): The image to set for all downstream :class:`Job`'s. Returns: JobSequence: Modified `sequence` object. \"\" \" if image : self . _image_for_replacement = image return self","title":"override_image"},{"location":"reference/gcip/core/pipeline/#override_rules","text":"def override_rules ( self , * rules : 'Rule' ) -> 'JobSequence' Works like :meth: override_tags but for rules. Parameters: Name Type Description Default rules Rule A list of :class: Rule s that will be replace all downstream :class: Job s rules. None View Source def override_rules ( self , * rules : Rule ) -> JobSequence : \" \"\" Works like :meth:`override_tags` but for rules. Args: rules (Rule): A list of :class:`Rule` s that will be replace all downstream :class:`Job` s rules. \"\" \" self . _rules_for_replacement . extend ( rules ) return self","title":"override_rules"},{"location":"reference/gcip/core/pipeline/#override_tags","text":"def override_tags ( self , * tags : 'str' ) -> 'JobSequence' Will replace all tags from downstream :class: Job s. View Source def override_tags ( self , * tags : str ) -> JobSequence : \" \"\" Will replace all tags from downstream :class:`Job` s. :meth:`override_tags` will also override tags set by :meth:`initialize_tags` but be extended by :meth:`add_tags` when one of the other methods is called too. Args: tags (str): One or more strings that will be set as tags to all downstream :class:`Job` s. \"\" \" for tag in tags : self . _tags_for_replacement [ tag ] = None return self","title":"override_tags"},{"location":"reference/gcip/core/pipeline/#override_variables","text":"def override_variables ( self , ** variables : 'str' ) -> 'JobSequence' Works like :meth: override_tags but for variables. Parameters: Name Type Description Default variables str A keyword argument list which key-value-pairs will be set as variable-value-pairs to all downstream :class: Job s. None View Source def override_variables ( self , ** variables : str ) -> JobSequence : \" \"\" Works like :meth:`override_tags` but for variables. Args: variables (str): A keyword argument list which key-value-pairs will be set as variable-value-pairs to all downstream :class:`Job` s. \"\" \" self . _variables_for_replacement . update ( variables ) return self","title":"override_variables"},{"location":"reference/gcip/core/pipeline/#prepend_rules","text":"def prepend_rules ( self , * rules : 'Rule' ) -> 'JobSequence' View Source def prepend_rules ( self , * rules : Rule ) -> JobSequence : self . _rules_to_prepend = list ( rules ) + self . _rules_to_prepend return self","title":"prepend_rules"},{"location":"reference/gcip/core/pipeline/#prepend_scripts","text":"def prepend_scripts ( self , * scripts : 'str' ) -> 'JobSequence' View Source def prepend_scripts ( self , * scripts : str ) -> JobSequence : self . _scripts_to_prepend = list ( scripts ) + self . _scripts_to_prepend return self","title":"prepend_scripts"},{"location":"reference/gcip/core/pipeline/#render","text":"def render ( self ) -> Dict [ str , Any ] View Source def render ( self ) -> Dict [ str , Any ]: stages : OrderedSetType = {} pipline : Dict [ str , Any ] = {} job_copies = self . populated_jobs for job in job_copies : # use the keys of dictionary as ordered set stages [ job . stage ] = None if self . _includes : pipline [ \"include\" ] = [ include . render () for include in self . _includes ] pipline [ \"stages\" ] = list ( stages . keys ()) for job in job_copies : pipline [ job . name ] = job . render () return pipline","title":"render"},{"location":"reference/gcip/core/pipeline/#set_cache","text":"def set_cache ( self , cache : 'Cache' ) -> 'JobSequence' Sets the cache for the corresponding JobSequence. This will override any previously set chaches on this sequence or child sequences/jobs. Parameters: Name Type Description Default cache Cache Cache to use for the JobSequence and its Jobs. None Returns: Type Description JobSequence Returns the modified Sequence object. View Source def set_cache ( self , cache : Cache ) -> JobSequence : \"\"\"Sets the cache for the corresponding JobSequence. This will override any previously set chaches on this sequence or child sequences/jobs. Args: cache (Cache): Cache to use for the JobSequence and its Jobs. Returns: JobSequence: Returns the modified Sequence object. \"\"\" self . _cache = cache return self","title":"set_cache"},{"location":"reference/gcip/core/pipeline/#write_yaml","text":"def write_yaml ( self , filename : str = 'generated-config.yml' ) -> None View Source def write_yaml ( self , filename : str = \"generated-config.yml\" ) -> None : import yaml with open ( filename , \"w\" ) as generated_config : generated_config . write ( yaml . dump ( self . render (), default_flow_style = False , sort_keys = False ))","title":"write_yaml"},{"location":"reference/gcip/core/rule/","text":"Module gcip.core.rule None None View Source from __future__ import annotations from enum import Enum from typing import Any , Dict , Union , Optional __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' class WhenStatement ( Enum ): ALWAYS = \"always\" DELAYED = \"delayed\" MANUAL = \"manual\" NEVER = \"never\" ON_FAILURE = \"on_failure\" ON_SUCCESS = \"on_success\" class Rule (): def __init__ ( self , * args : Any , if_statement : Optional [ str ] = None , when : WhenStatement = WhenStatement . ON_SUCCESS , allow_failure : bool = False , ) -> None : self . _if = if_statement self . _when = when self . _allow_failure = allow_failure def never ( self ) -> Rule : self . _when = WhenStatement . NEVER return self def render ( self ) -> Dict [ str , Union [ str , bool ]]: rendered_rule : Dict [ str , Union [ str , bool ]] = {} if self . _if : rendered_rule . update ({ \"if\" : self . _if }) rendered_rule . update ({ \"when\" : self . _when . value , \"allow_failure\" : self . _allow_failure , }) return rendered_rule Classes Rule class Rule ( * args : 'Any' , if_statement : 'Optional[str]' = None , when : 'WhenStatement' = < WhenStatement . ON_SUCCESS : 'on_success' > , allow_failure : 'bool' = False ) View Source class Rule () : def __init__ ( self , * args : Any , if_statement : Optional [ str ] = None , when : WhenStatement = WhenStatement . ON_SUCCESS , allow_failure : bool = False , ) -> None : self . _if = if_statement self . _when = when self . _allow_failure = allow_failure def never ( self ) -> Rule : self . _when = WhenStatement . NEVER return self def render ( self ) -> Dict [ str, Union[str, bool ] ]: rendered_rule : Dict [ str, Union[str, bool ] ] = {} if self . _if : rendered_rule . update ( { \"if\" : self . _if } ) rendered_rule . update ( { \"when\" : self . _when . value , \"allow_failure\" : self . _allow_failure , } ) return rendered_rule Methods never def never ( self ) -> 'Rule' View Source def never ( self ) -> Rule : self . _when = WhenStatement . NEVER return self render def render ( self ) -> 'Dict[str, Union[str, bool]]' View Source def render ( self ) -> Dict [ str , Union [ str , bool ]]: rendered_rule : Dict [ str , Union [ str , bool ]] = {} if self . _if : rendered_rule . update ( { \"if\" : self . _if } ) rendered_rule . update ( { \"when\" : self . _when . value , \"allow_failure\" : self . _allow_failure , } ) return rendered_rule WhenStatement class WhenStatement ( / , * args , ** kwargs ) View Source class WhenStatement ( Enum ): ALWAYS = \"always\" DELAYED = \"delayed\" MANUAL = \"manual\" NEVER = \"never\" ON_FAILURE = \"on_failure\" ON_SUCCESS = \"on_success\" Ancestors (in MRO) enum.Enum Class variables ALWAYS DELAYED MANUAL NEVER ON_FAILURE ON_SUCCESS name value","title":"Rule"},{"location":"reference/gcip/core/rule/#module-gcipcorerule","text":"None None View Source from __future__ import annotations from enum import Enum from typing import Any , Dict , Union , Optional __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" , \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' class WhenStatement ( Enum ): ALWAYS = \"always\" DELAYED = \"delayed\" MANUAL = \"manual\" NEVER = \"never\" ON_FAILURE = \"on_failure\" ON_SUCCESS = \"on_success\" class Rule (): def __init__ ( self , * args : Any , if_statement : Optional [ str ] = None , when : WhenStatement = WhenStatement . ON_SUCCESS , allow_failure : bool = False , ) -> None : self . _if = if_statement self . _when = when self . _allow_failure = allow_failure def never ( self ) -> Rule : self . _when = WhenStatement . NEVER return self def render ( self ) -> Dict [ str , Union [ str , bool ]]: rendered_rule : Dict [ str , Union [ str , bool ]] = {} if self . _if : rendered_rule . update ({ \"if\" : self . _if }) rendered_rule . update ({ \"when\" : self . _when . value , \"allow_failure\" : self . _allow_failure , }) return rendered_rule","title":"Module gcip.core.rule"},{"location":"reference/gcip/core/rule/#classes","text":"","title":"Classes"},{"location":"reference/gcip/core/rule/#rule","text":"class Rule ( * args : 'Any' , if_statement : 'Optional[str]' = None , when : 'WhenStatement' = < WhenStatement . ON_SUCCESS : 'on_success' > , allow_failure : 'bool' = False ) View Source class Rule () : def __init__ ( self , * args : Any , if_statement : Optional [ str ] = None , when : WhenStatement = WhenStatement . ON_SUCCESS , allow_failure : bool = False , ) -> None : self . _if = if_statement self . _when = when self . _allow_failure = allow_failure def never ( self ) -> Rule : self . _when = WhenStatement . NEVER return self def render ( self ) -> Dict [ str, Union[str, bool ] ]: rendered_rule : Dict [ str, Union[str, bool ] ] = {} if self . _if : rendered_rule . update ( { \"if\" : self . _if } ) rendered_rule . update ( { \"when\" : self . _when . value , \"allow_failure\" : self . _allow_failure , } ) return rendered_rule","title":"Rule"},{"location":"reference/gcip/core/rule/#methods","text":"","title":"Methods"},{"location":"reference/gcip/core/rule/#never","text":"def never ( self ) -> 'Rule' View Source def never ( self ) -> Rule : self . _when = WhenStatement . NEVER return self","title":"never"},{"location":"reference/gcip/core/rule/#render","text":"def render ( self ) -> 'Dict[str, Union[str, bool]]' View Source def render ( self ) -> Dict [ str , Union [ str , bool ]]: rendered_rule : Dict [ str , Union [ str , bool ]] = {} if self . _if : rendered_rule . update ( { \"if\" : self . _if } ) rendered_rule . update ( { \"when\" : self . _when . value , \"allow_failure\" : self . _allow_failure , } ) return rendered_rule","title":"render"},{"location":"reference/gcip/core/rule/#whenstatement","text":"class WhenStatement ( / , * args , ** kwargs ) View Source class WhenStatement ( Enum ): ALWAYS = \"always\" DELAYED = \"delayed\" MANUAL = \"manual\" NEVER = \"never\" ON_FAILURE = \"on_failure\" ON_SUCCESS = \"on_success\"","title":"WhenStatement"},{"location":"reference/gcip/core/rule/#ancestors-in-mro","text":"enum.Enum","title":"Ancestors (in MRO)"},{"location":"reference/gcip/core/rule/#class-variables","text":"ALWAYS DELAYED MANUAL NEVER ON_FAILURE ON_SUCCESS name value","title":"Class variables"},{"location":"reference/gcip/core/variables/","text":"Module gcip.core.variables None None View Source import os from typing import Any # In Python >= 3.9 it is also possible to use @classmethods and @property # together, so that there are no parantheses necessarry. # See https://stackoverflow.com/questions/128573/using-property-on-classmethods\u00b4 class EnvProxy (): def __init__ ( self , key : str ) -> None : self . key = key def __get__ ( self , obj : Any , objtype : Any = None ) -> str : return os . getenv ( self . key ) class PredefinedVariables (): \"\"\" Gitlab CI predefined variables. https://docs.gitlab.com/ee/ci/variables/predefined_variables.html \"\"\" CHAT_CHANNEL = EnvProxy ( \"CHAT_CHANNEL\" ) \"\"\" Source chat channel which triggered the ChatOps command. Added in GitLab 10.6 Available in GitLab Runner all \"\"\" CHAT_INPUT = EnvProxy ( \"CHAT_INPUT\" ) \"\"\" Additional arguments passed in the ChatOps command. Added in GitLab 10.6 Available in GitLab Runner all \"\"\" CI = EnvProxy ( \"CI\" ) \"\"\" Mark that job is executed in CI environment. Added in GitLab all Available in GitLab Runner 0.4 \"\"\" CI_API_V4_URL = EnvProxy ( \"CI_API_V4_URL\" ) \"\"\" The GitLab API v4 root URL. Added in GitLab 11.7 Available in GitLab Runner all \"\"\" CI_BUILDS_DIR = EnvProxy ( \"CI_BUILDS_DIR\" ) \"\"\" Top-level directory where builds are executed. Added in GitLab all Available in GitLab Runner 11.10 \"\"\" CI_COMMIT_BEFORE_SHA = EnvProxy ( \"CI_COMMIT_BEFORE_SHA\" ) \"\"\" The previous latest commit present on a branch. Is always 0000000000000000000000000000000000000000 in pipelines for merge requests. Added in GitLab 11.2 Available in GitLab Runner all \"\"\" CI_COMMIT_DESCRIPTION = EnvProxy ( \"CI_COMMIT_DESCRIPTION\" ) \"\"\" The description of the commit the message without first line, if the title is shorter than 100 characters; full message in other case. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_COMMIT_MESSAGE = EnvProxy ( \"CI_COMMIT_MESSAGE\" ) \"\"\" The full commit message. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_COMMIT_REF_NAME = EnvProxy ( \"CI_COMMIT_REF_NAME\" ) \"\"\" The branch or tag name for which project is built. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_COMMIT_REF_PROTECTED = EnvProxy ( \"CI_COMMIT_REF_PROTECTED\" ) \"\"\" true if the job is running on a protected reference, false if not. Added in GitLab 11.11 Available in GitLab Runner all \"\"\" CI_COMMIT_REF_SLUG = EnvProxy ( \"CI_COMMIT_REF_SLUG\" ) \"\"\" $CI_COMMIT_REF_NAME in lowercase, shortened to 63 bytes, and with everything except 0-9 and a-z replaced with -. No leading / trailing -. Use in URLs, host names and domain names. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_COMMIT_SHA = EnvProxy ( \"CI_COMMIT_SHA\" ) \"\"\" The commit revision for which project is built. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_COMMIT_SHORT_SHA = EnvProxy ( \"CI_COMMIT_SHORT_SHA\" ) \"\"\" The first eight characters of CI_COMMIT_SHA. Added in GitLab 11.7 Available in GitLab Runner all \"\"\" CI_COMMIT_BRANCH = EnvProxy ( \"CI_COMMIT_BRANCH\" ) \"\"\" The commit branch name. Present in branch pipelines, including pipelines for the default branch. Not present in merge request pipelines or tag pipelines. Added in GitLab 12.6 Available in GitLab Runner 0.5 \"\"\" CI_COMMIT_TAG = EnvProxy ( \"CI_COMMIT_TAG\" ) \"\"\" The commit tag name. Present only when building tags. Added in GitLab 9.0 Available in GitLab Runner 0.5 \"\"\" CI_COMMIT_TITLE = EnvProxy ( \"CI_COMMIT_TITLE\" ) \"\"\" The title of the commit - the full first line of the message. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_COMMIT_TIMESTAMP = EnvProxy ( \"CI_COMMIT_TIMESTAMP\" ) \"\"\" The timestamp of the commit in the ISO 8601 format. Added in GitLab 13.4 Available in GitLab Runner all \"\"\" CI_CONCURRENT_ID = EnvProxy ( \"CI_CONCURRENT_ID\" ) \"\"\" Unique ID of build execution in a single executor. Added in GitLab all Available in GitLab Runner 11.10 \"\"\" CI_CONCURRENT_PROJECT_ID = EnvProxy ( \"CI_CONCURRENT_PROJECT_ID\" ) \"\"\" Unique ID of build execution in a single executor and project. Added in GitLab all Available in GitLab Runner 11.10 \"\"\" CI_CONFIG_PATH = EnvProxy ( \"CI_CONFIG_PATH\" ) \"\"\" The path to CI configuration file. Defaults to .gitlab-ci.yml. Added in GitLab 9.4 Available in GitLab Runner 0.5 \"\"\" CI_DEBUG_TRACE = EnvProxy ( \"CI_DEBUG_TRACE\" ) \"\"\" Whether debug logging (tracing) is enabled. Added in GitLab all Available in GitLab Runner 1.7 \"\"\" CI_DEFAULT_BRANCH = EnvProxy ( \"CI_DEFAULT_BRANCH\" ) \"\"\" The name of the default branch for the project. Added in GitLab 12.4 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX = EnvProxy ( \"CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX\" ) \"\"\" The image prefix for pulling images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_SERVER = EnvProxy ( \"CI_DEPENDENCY_PROXY_SERVER\" ) \"\"\" The server for logging in to the Dependency Proxy. This is equivalent to $CI_SERVER_HOST:$CI_SERVER_PORT. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_PASSWORD = EnvProxy ( \"CI_DEPENDENCY_PROXY_PASSWORD\" ) \"\"\" The password to use to pull images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_USER = EnvProxy ( \"CI_DEPENDENCY_PROXY_USER\" ) \"\"\" The username to use to pull images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPLOY_FREEZE = EnvProxy ( \"CI_DEPLOY_FREEZE\" ) \"\"\" Included with the value true if the pipeline runs during a deploy freeze window. Added in GitLab 13.2 Available in GitLab Runner all \"\"\" CI_DEPLOY_PASSWORD = EnvProxy ( \"CI_DEPLOY_PASSWORD\" ) \"\"\" Authentication password of the GitLab Deploy Token, only present if the Project has one related. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_DEPLOY_USER = EnvProxy ( \"CI_DEPLOY_USER\" ) \"\"\" Authentication username of the GitLab Deploy Token, only present if the Project has one related. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_DISPOSABLE_ENVIRONMENT = EnvProxy ( \"CI_DISPOSABLE_ENVIRONMENT\" ) \"\"\" Marks that the job is executed in a disposable environment (something that is created only for this job and disposed of/destroyed after the execution - all executors except shell and ssh). If the environment is disposable, it is set to true, otherwise it is not defined at all. Added in GitLab all Available in GitLab Runner 10.1 \"\"\" CI_ENVIRONMENT_NAME = EnvProxy ( \"CI_ENVIRONMENT_NAME\" ) \"\"\" The name of the environment for this job. Only present if environment:name is set. Added in GitLab 8.15 Available in GitLab Runner all \"\"\" CI_ENVIRONMENT_SLUG = EnvProxy ( \"CI_ENVIRONMENT_SLUG\" ) \"\"\" A simplified version of the environment name, suitable for inclusion in DNS, URLs, Kubernetes labels, and so on. Only present if environment:name is set. Added in GitLab 8.15 Available in GitLab Runner all \"\"\" CI_ENVIRONMENT_URL = EnvProxy ( \"CI_ENVIRONMENT_URL\" ) \"\"\" The URL of the environment for this job. Only present if environment:url is set. Added in GitLab 9.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_IID = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_IID\" ) \"\"\" Pull Request ID from GitHub if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_SOURCE_REPOSITORY = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_SOURCE_REPOSITORY\" ) \"\"\" The source repository name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 13.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_TARGET_REPOSITORY = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_TARGET_REPOSITORY\" ) \"\"\" The target repository name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 13.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_NAME = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_NAME\" ) \"\"\" The source branch name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_SHA = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the source branch of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_NAME = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_NAME\" ) \"\"\" The target branch name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_SHA = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the target branch of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_HAS_OPEN_REQUIREMENTS = EnvProxy ( \"CI_HAS_OPEN_REQUIREMENTS\" ) \"\"\" Included with the value true only if the pipeline\u2019s project has any open requirements. Not included if there are no open requirements for the pipeline\u2019s project. Added in GitLab 13.1 Available in GitLab Runner all \"\"\" CI_OPEN_MERGE_REQUESTS = EnvProxy ( \"CI_OPEN_MERGE_REQUESTS\" ) \"\"\" Available in branch and merge request pipelines. Contains a comma-separated list of up to four merge requests that use the current branch and project as the merge request source. For example gitlab-org/gitlab!333,gitlab-org/gitlab-foss!11. Added in GitLab 13.8 Available in GitLab Runner all \"\"\" CI_JOB_ID = EnvProxy ( \"CI_JOB_ID\" ) \"\"\" The unique ID of the current job that GitLab CI/CD uses internally. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_JOB_IMAGE = EnvProxy ( \"CI_JOB_IMAGE\" ) \"\"\" The name of the image running the CI job. Added in GitLab 12.9 Available in GitLab Runner 12.9 \"\"\" CI_JOB_MANUAL = EnvProxy ( \"CI_JOB_MANUAL\" ) \"\"\" The flag to indicate that job was manually started. Added in GitLab 8.12 Available in GitLab Runner all \"\"\" CI_JOB_NAME = EnvProxy ( \"CI_JOB_NAME\" ) \"\"\" The name of the job as defined in .gitlab-ci.yml. Added in GitLab 9.0 Available in GitLab Runner 0.5 \"\"\" CI_JOB_STAGE = EnvProxy ( \"CI_JOB_STAGE\" ) \"\"\" The name of the stage as defined in .gitlab-ci.yml. Added in GitLab 9.0 Available in GitLab Runner 0.5 \"\"\" CI_JOB_STATUS = EnvProxy ( \"CI_JOB_STATUS\" ) \"\"\" The state of the job as each runner stage is executed. Use with after_script where CI_JOB_STATUS can be either success, failed or canceled. Added in GitLab all Available in GitLab Runner 13.5 \"\"\" CI_JOB_TOKEN = EnvProxy ( \"CI_JOB_TOKEN\" ) \"\"\" Token used for authenticating with a few API endpoints and downloading dependent repositories. The token is valid as long as the job is running. Added in GitLab 9.0 Available in GitLab Runner 1.2 \"\"\" CI_JOB_JWT = EnvProxy ( \"CI_JOB_JWT\" ) \"\"\" RS256 JSON web token that can be used for authenticating with third party systems that support JWT authentication, for example HashiCorp\u2019s Vault. Added in GitLab 12.10 Available in GitLab Runner all \"\"\" CI_JOB_URL = EnvProxy ( \"CI_JOB_URL\" ) \"\"\" Job details URL. Added in GitLab 11.1 Available in GitLab Runner 0.5 \"\"\" CI_KUBERNETES_ACTIVE = EnvProxy ( \"CI_KUBERNETES_ACTIVE\" ) \"\"\" Included with the value true only if the pipeline has a Kubernetes cluster available for deployments. Not included if no cluster is available. Can be used as an alternative to only:kubernetes/except:kubernetes with rules:if. Added in GitLab 13.0 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_ASSIGNEES = EnvProxy ( \"CI_MERGE_REQUEST_ASSIGNEES\" ) \"\"\" Comma-separated list of username(s) of assignee(s) for the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_ID = EnvProxy ( \"CI_MERGE_REQUEST_ID\" ) \"\"\" The instance-level ID of the merge request. Only available if the pipelines are for merge requests and the merge request is created. This is a unique ID across all projects on GitLab. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_IID = EnvProxy ( \"CI_MERGE_REQUEST_IID\" ) \"\"\" The project-level IID (internal ID) of the merge request. Only available If the pipelines are for merge requests and the merge request is created. This ID is unique for the current project. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_LABELS = EnvProxy ( \"CI_MERGE_REQUEST_LABELS\" ) \"\"\" Comma-separated label names of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_MILESTONE = EnvProxy ( \"CI_MERGE_REQUEST_MILESTONE\" ) \"\"\" The milestone title of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_PROJECT_ID = EnvProxy ( \"CI_MERGE_REQUEST_PROJECT_ID\" ) \"\"\" The ID of the project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_PROJECT_PATH = EnvProxy ( \"CI_MERGE_REQUEST_PROJECT_PATH\" ) \"\"\" The path of the project of the merge request if the pipelines are for merge requests (for example namespace/awesome-project). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_PROJECT_URL = EnvProxy ( \"CI_MERGE_REQUEST_PROJECT_URL\" ) \"\"\" The URL of the project of the merge request if the pipelines are for merge requests (for example http://192.168.10.15:3000/namespace/awesome-project). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_REF_PATH = EnvProxy ( \"CI_MERGE_REQUEST_REF_PATH\" ) \"\"\" The ref path of the merge request if the pipelines are for merge requests. (for example refs/merge-requests/1/head). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_BRANCH_NAME = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_BRANCH_NAME\" ) \"\"\" The source branch name of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_BRANCH_SHA = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the source branch of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used, the merge request is created, and the pipeline is a merged result pipeline. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_PROJECT_ID = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_PROJECT_ID\" ) \"\"\" The ID of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_PROJECT_PATH = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_PROJECT_PATH\" ) \"\"\" The path of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_PROJECT_URL = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_PROJECT_URL\" ) \"\"\" The URL of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_TARGET_BRANCH_NAME = EnvProxy ( \"CI_MERGE_REQUEST_TARGET_BRANCH_NAME\" ) \"\"\" The target branch name of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_TARGET_BRANCH_SHA = EnvProxy ( \"CI_MERGE_REQUEST_TARGET_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the target branch of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used, the merge request is created, and the pipeline is a merged result pipeline. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_TITLE = EnvProxy ( \"CI_MERGE_REQUEST_TITLE\" ) \"\"\" The title of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_EVENT_TYPE = EnvProxy ( \"CI_MERGE_REQUEST_EVENT_TYPE\" ) \"\"\" The event type of the merge request, if the pipelines are for merge requests. Can be detached, merged_result or merge_train. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_DIFF_ID = EnvProxy ( \"CI_MERGE_REQUEST_DIFF_ID\" ) \"\"\" The version of the merge request diff, if the pipelines are for merge requests. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_DIFF_BASE_SHA = EnvProxy ( \"CI_MERGE_REQUEST_DIFF_BASE_SHA\" ) \"\"\" The base SHA of the merge request diff, if the pipelines are for merge requests. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_NODE_INDEX = EnvProxy ( \"CI_NODE_INDEX\" ) \"\"\" Index of the job in the job set. If the job is not parallelized, this variable is not set. Added in GitLab 11.5 Available in GitLab Runner all \"\"\" CI_NODE_TOTAL = EnvProxy ( \"CI_NODE_TOTAL\" ) \"\"\" Total number of instances of this job running in parallel. If the job is not parallelized, this variable is set to 1. Added in GitLab 11.5 Available in GitLab Runner all \"\"\" CI_PAGES_DOMAIN = EnvProxy ( \"CI_PAGES_DOMAIN\" ) \"\"\" The configured domain that hosts GitLab Pages. Added in GitLab 11.8 Available in GitLab Runner all \"\"\" CI_PAGES_URL = EnvProxy ( \"CI_PAGES_URL\" ) \"\"\" URL to GitLab Pages-built pages. Always belongs to a subdomain of CI_PAGES_DOMAIN. Added in GitLab 11.8 Available in GitLab Runner all \"\"\" CI_PIPELINE_ID = EnvProxy ( \"CI_PIPELINE_ID\" ) \"\"\" The instance-level ID of the current pipeline. This is a unique ID across all projects on GitLab. Added in GitLab 8.10 Available in GitLab Runner all \"\"\" CI_PIPELINE_IID = EnvProxy ( \"CI_PIPELINE_IID\" ) \"\"\" The project-level IID (internal ID) of the current pipeline. This ID is unique for the current project. Added in GitLab 11.0 Available in GitLab Runner all \"\"\" CI_PIPELINE_SOURCE = EnvProxy ( \"CI_PIPELINE_SOURCE\" ) \"\"\" Indicates how the pipeline was triggered. Possible options are push, web, schedule, api, external, chat, webide, merge_request_event, external_pull_request_event, parent_pipeline, trigger, or pipeline. For pipelines created before GitLab 9.5, this is displayed as unknown. Added in GitLab 10.0 Available in GitLab Runner all \"\"\" CI_PIPELINE_TRIGGERED = EnvProxy ( \"CI_PIPELINE_TRIGGERED\" ) \"\"\" The flag to indicate that job was triggered. Added in GitLab all Available in GitLab Runner all \"\"\" CI_PIPELINE_URL = EnvProxy ( \"CI_PIPELINE_URL\" ) \"\"\" Pipeline details URL. Added in GitLab 11.1 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_CONFIG_PATH = EnvProxy ( \"CI_PROJECT_CONFIG_PATH\" ) \"\"\" The CI configuration path for the project. Added in GitLab 13.8 Available in GitLab Runner all \"\"\" CI_PROJECT_DIR = EnvProxy ( \"CI_PROJECT_DIR\" ) \"\"\" The full path where the repository is cloned and where the job is run. If the GitLab Runner builds_dir parameter is set, this variable is set relative to the value of builds_dir. For more information, see Advanced configuration for GitLab Runner. Added in GitLab all Available in GitLab Runner all \"\"\" CI_PROJECT_ID = EnvProxy ( \"CI_PROJECT_ID\" ) \"\"\" The unique ID of the current project that GitLab CI/CD uses internally. Added in GitLab all Available in GitLab Runner all \"\"\" CI_PROJECT_NAME = EnvProxy ( \"CI_PROJECT_NAME\" ) \"\"\" The name of the directory for the project that is being built. For example, if the project URL is gitlab.example.com/group-name/project-1, the CI_PROJECT_NAME would be project-1. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_NAMESPACE = EnvProxy ( \"CI_PROJECT_NAMESPACE\" ) \"\"\" The project namespace (username or group name) that is being built. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_ROOT_NAMESPACE = EnvProxy ( \"CI_PROJECT_ROOT_NAMESPACE\" ) \"\"\" The root project namespace (username or group name) that is being built. For example, if CI_PROJECT_NAMESPACE is root-group/child-group/grandchild-group, CI_PROJECT_ROOT_NAMESPACE would be root-group. Added in GitLab 13.2 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_PATH = EnvProxy ( \"CI_PROJECT_PATH\" ) \"\"\" The namespace with project name. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_PATH_SLUG = EnvProxy ( \"CI_PROJECT_PATH_SLUG\" ) \"\"\" $CI_PROJECT_PATH in lowercase and with everything except 0-9 and a-z replaced with -. Use in URLs and domain names. Added in GitLab 9.3 Available in GitLab Runner all \"\"\" CI_PROJECT_REPOSITORY_LANGUAGES = EnvProxy ( \"CI_PROJECT_REPOSITORY_LANGUAGES\" ) \"\"\" Comma-separated, lowercase list of the languages used in the repository (for example ruby,javascript,html,css). Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_PROJECT_TITLE = EnvProxy ( \"CI_PROJECT_TITLE\" ) \"\"\" The human-readable project name as displayed in the GitLab web interface. Added in GitLab 12.4 Available in GitLab Runner all \"\"\" CI_PROJECT_URL = EnvProxy ( \"CI_PROJECT_URL\" ) \"\"\" The HTTP(S) address to access project. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_VISIBILITY = EnvProxy ( \"CI_PROJECT_VISIBILITY\" ) \"\"\" The project visibility (internal, private, public). Added in GitLab 10.3 Available in GitLab Runner all \"\"\" CI_REGISTRY = EnvProxy ( \"CI_REGISTRY\" ) \"\"\" GitLab Container Registry. This variable includes a :port value if one has been specified in the registry configuration. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_REGISTRY_IMAGE = EnvProxy ( \"CI_REGISTRY_IMAGE\" ) \"\"\" the address of the registry tied to the specific project. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_REGISTRY_PASSWORD = EnvProxy ( \"CI_REGISTRY_PASSWORD\" ) \"\"\" The password to use to push containers to the GitLab Container Registry, for the current project. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_REGISTRY_USER = EnvProxy ( \"CI_REGISTRY_USER\" ) \"\"\" The username to use to push containers to the GitLab Container Registry, for the current project. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_REPOSITORY_URL = EnvProxy ( \"CI_REPOSITORY_URL\" ) \"\"\" The URL to clone the Git repository. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_RUNNER_DESCRIPTION = EnvProxy ( \"CI_RUNNER_DESCRIPTION\" ) \"\"\" The description of the runner as saved in GitLab. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_RUNNER_EXECUTABLE_ARCH = EnvProxy ( \"CI_RUNNER_EXECUTABLE_ARCH\" ) \"\"\" The OS/architecture of the GitLab Runner executable (note that this is not necessarily the same as the environment of the executor). Added in GitLab all Available in GitLab Runner 10.6 \"\"\" CI_RUNNER_ID = EnvProxy ( \"CI_RUNNER_ID\" ) \"\"\" The unique ID of runner being used. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_RUNNER_REVISION = EnvProxy ( \"CI_RUNNER_REVISION\" ) \"\"\" GitLab Runner revision that is executing the current job. Added in GitLab all Available in GitLab Runner 10.6 \"\"\" CI_RUNNER_SHORT_TOKEN = EnvProxy ( \"CI_RUNNER_SHORT_TOKEN\" ) \"\"\" First eight characters of the runner\u2019s token used to authenticate new job requests. Used as the runner\u2019s unique ID. Added in GitLab all Available in GitLab Runner 12.3 \"\"\" CI_RUNNER_TAGS = EnvProxy ( \"CI_RUNNER_TAGS\" ) \"\"\" The defined runner tags. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_RUNNER_VERSION = EnvProxy ( \"CI_RUNNER_VERSION\" ) \"\"\" GitLab Runner version that is executing the current job. Added in GitLab all Available in GitLab Runner 10.6 \"\"\" CI_SERVER = EnvProxy ( \"CI_SERVER\" ) \"\"\" Mark that job is executed in CI environment. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_URL = EnvProxy ( \"CI_SERVER_URL\" ) \"\"\" The base URL of the GitLab instance, including protocol and port (like https://gitlab.example.com:8080). Added in GitLab 12.7 Available in GitLab Runner all \"\"\" CI_SERVER_HOST = EnvProxy ( \"CI_SERVER_HOST\" ) \"\"\" Host component of the GitLab instance URL, without protocol and port (like gitlab.example.com). Added in GitLab 12.1 Available in GitLab Runner all \"\"\" CI_SERVER_PORT = EnvProxy ( \"CI_SERVER_PORT\" ) \"\"\" Port component of the GitLab instance URL, without host and protocol (like 3000). Added in GitLab 12.8 Available in GitLab Runner all \"\"\" CI_SERVER_PROTOCOL = EnvProxy ( \"CI_SERVER_PROTOCOL\" ) \"\"\" Protocol component of the GitLab instance URL, without host and port (like https). Added in GitLab 12.8 Available in GitLab Runner all \"\"\" CI_SERVER_NAME = EnvProxy ( \"CI_SERVER_NAME\" ) \"\"\" The name of CI server that is used to coordinate jobs. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_REVISION = EnvProxy ( \"CI_SERVER_REVISION\" ) \"\"\" GitLab revision that is used to schedule jobs. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_VERSION = EnvProxy ( \"CI_SERVER_VERSION\" ) \"\"\" GitLab version that is used to schedule jobs. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_VERSION_MAJOR = EnvProxy ( \"CI_SERVER_VERSION_MAJOR\" ) \"\"\" GitLab version major component. Added in GitLab 11.4 Available in GitLab Runner all \"\"\" CI_SERVER_VERSION_MINOR = EnvProxy ( \"CI_SERVER_VERSION_MINOR\" ) \"\"\" GitLab version minor component. Added in GitLab 11.4 Available in GitLab Runner all \"\"\" CI_SERVER_VERSION_PATCH = EnvProxy ( \"CI_SERVER_VERSION_PATCH\" ) \"\"\" GitLab version patch component. Added in GitLab 11.4 Available in GitLab Runner all \"\"\" CI_SHARED_ENVIRONMENT = EnvProxy ( \"CI_SHARED_ENVIRONMENT\" ) \"\"\" Marks that the job is executed in a shared environment (something that is persisted across CI invocations like shell or ssh executor). If the environment is shared, it is set to true, otherwise it is not defined at all. Added in GitLab all Available in GitLab Runner 10.1 \"\"\" GITLAB_CI = EnvProxy ( \"GITLAB_CI\" ) \"\"\" Mark that job is executed in GitLab CI/CD environment. Added in GitLab all Available in GitLab Runner all \"\"\" GITLAB_FEATURES = EnvProxy ( \"GITLAB_FEATURES\" ) \"\"\" The comma separated list of licensed features available for your instance and plan. Added in GitLab 10.6 Available in GitLab Runner all \"\"\" GITLAB_USER_EMAIL = EnvProxy ( \"GITLAB_USER_EMAIL\" ) \"\"\" The email of the user who started the job. Added in GitLab 8.12 Available in GitLab Runner all \"\"\" GITLAB_USER_ID = EnvProxy ( \"GITLAB_USER_ID\" ) \"\"\" The ID of the user who started the job. Added in GitLab 8.12 Available in GitLab Runner all \"\"\" GITLAB_USER_LOGIN = EnvProxy ( \"GITLAB_USER_LOGIN\" ) \"\"\" The login username of the user who started the job. Added in GitLab 10.0 Available in GitLab Runner all \"\"\" GITLAB_USER_NAME = EnvProxy ( \"GITLAB_USER_NAME\" ) \"\"\" The real name of the user who started the job. Added in GitLab 10.0 Available in GitLab Runner all \"\"\" TRIGGER_PAYLOAD = EnvProxy ( \"TRIGGER_PAYLOAD\" ) \"\"\" This variable is available when a pipeline is triggered with a webhook Added in GitLab 13.9 Available in GitLab Runner all \"\"\" Classes EnvProxy class EnvProxy ( key : str ) View Source class EnvProxy (): def __init__ ( self , key: str ) -> None: self . key = key def __get__ ( self , obj: Any , objtype: Any = None ) -> str: return os . getenv ( self . key ) PredefinedVariables class PredefinedVariables ( / , * args , ** kwargs ) View Source class PredefinedVariables (): \"\"\" Gitlab CI predefined variables. https://docs.gitlab.com/ee/ci/variables/predefined_variables.html \"\"\" CHAT_CHANNEL = EnvProxy ( \"CHAT_CHANNEL\" ) \"\"\" Source chat channel which triggered the ChatOps command. Added in GitLab 10.6 Available in GitLab Runner all \"\"\" CHAT_INPUT = EnvProxy ( \"CHAT_INPUT\" ) \"\"\" Additional arguments passed in the ChatOps command. Added in GitLab 10.6 Available in GitLab Runner all \"\"\" CI = EnvProxy ( \"CI\" ) \"\"\" Mark that job is executed in CI environment. Added in GitLab all Available in GitLab Runner 0.4 \"\"\" CI_API_V4_URL = EnvProxy ( \"CI_API_V4_URL\" ) \"\"\" The GitLab API v4 root URL. Added in GitLab 11.7 Available in GitLab Runner all \"\"\" CI_BUILDS_DIR = EnvProxy ( \"CI_BUILDS_DIR\" ) \"\"\" Top-level directory where builds are executed. Added in GitLab all Available in GitLab Runner 11.10 \"\"\" CI_COMMIT_BEFORE_SHA = EnvProxy ( \"CI_COMMIT_BEFORE_SHA\" ) \"\"\" The previous latest commit present on a branch. Is always 0000000000000000000000000000000000000000 in pipelines for merge requests. Added in GitLab 11.2 Available in GitLab Runner all \"\"\" CI_COMMIT_DESCRIPTION = EnvProxy ( \"CI_COMMIT_DESCRIPTION\" ) \"\"\" The description of the commit the message without first line, if the title is shorter than 100 characters; full message in other case. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_COMMIT_MESSAGE = EnvProxy ( \"CI_COMMIT_MESSAGE\" ) \"\"\" The full commit message. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_COMMIT_REF_NAME = EnvProxy ( \"CI_COMMIT_REF_NAME\" ) \"\"\" The branch or tag name for which project is built. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_COMMIT_REF_PROTECTED = EnvProxy ( \"CI_COMMIT_REF_PROTECTED\" ) \"\"\" true if the job is running on a protected reference, false if not. Added in GitLab 11.11 Available in GitLab Runner all \"\"\" CI_COMMIT_REF_SLUG = EnvProxy ( \"CI_COMMIT_REF_SLUG\" ) \"\"\" $CI_COMMIT_REF_NAME in lowercase, shortened to 63 bytes, and with everything except 0-9 and a-z replaced with -. No leading / trailing -. Use in URLs, host names and domain names. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_COMMIT_SHA = EnvProxy ( \"CI_COMMIT_SHA\" ) \"\"\" The commit revision for which project is built. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_COMMIT_SHORT_SHA = EnvProxy ( \"CI_COMMIT_SHORT_SHA\" ) \"\"\" The first eight characters of CI_COMMIT_SHA. Added in GitLab 11.7 Available in GitLab Runner all \"\"\" CI_COMMIT_BRANCH = EnvProxy ( \"CI_COMMIT_BRANCH\" ) \"\"\" The commit branch name. Present in branch pipelines, including pipelines for the default branch. Not present in merge request pipelines or tag pipelines. Added in GitLab 12.6 Available in GitLab Runner 0.5 \"\"\" CI_COMMIT_TAG = EnvProxy ( \"CI_COMMIT_TAG\" ) \"\"\" The commit tag name. Present only when building tags. Added in GitLab 9.0 Available in GitLab Runner 0.5 \"\"\" CI_COMMIT_TITLE = EnvProxy ( \"CI_COMMIT_TITLE\" ) \"\"\" The title of the commit - the full first line of the message. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_COMMIT_TIMESTAMP = EnvProxy ( \"CI_COMMIT_TIMESTAMP\" ) \"\"\" The timestamp of the commit in the ISO 8601 format. Added in GitLab 13.4 Available in GitLab Runner all \"\"\" CI_CONCURRENT_ID = EnvProxy ( \"CI_CONCURRENT_ID\" ) \"\"\" Unique ID of build execution in a single executor. Added in GitLab all Available in GitLab Runner 11.10 \"\"\" CI_CONCURRENT_PROJECT_ID = EnvProxy ( \"CI_CONCURRENT_PROJECT_ID\" ) \"\"\" Unique ID of build execution in a single executor and project. Added in GitLab all Available in GitLab Runner 11.10 \"\"\" CI_CONFIG_PATH = EnvProxy ( \"CI_CONFIG_PATH\" ) \"\"\" The path to CI configuration file. Defaults to .gitlab-ci.yml. Added in GitLab 9.4 Available in GitLab Runner 0.5 \"\"\" CI_DEBUG_TRACE = EnvProxy ( \"CI_DEBUG_TRACE\" ) \"\"\" Whether debug logging (tracing) is enabled. Added in GitLab all Available in GitLab Runner 1.7 \"\"\" CI_DEFAULT_BRANCH = EnvProxy ( \"CI_DEFAULT_BRANCH\" ) \"\"\" The name of the default branch for the project. Added in GitLab 12.4 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX = EnvProxy ( \"CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX\" ) \"\"\" The image prefix for pulling images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_SERVER = EnvProxy ( \"CI_DEPENDENCY_PROXY_SERVER\" ) \"\"\" The server for logging in to the Dependency Proxy. This is equivalent to $CI_SERVER_HOST:$CI_SERVER_PORT. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_PASSWORD = EnvProxy ( \"CI_DEPENDENCY_PROXY_PASSWORD\" ) \"\"\" The password to use to pull images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_USER = EnvProxy ( \"CI_DEPENDENCY_PROXY_USER\" ) \"\"\" The username to use to pull images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPLOY_FREEZE = EnvProxy ( \"CI_DEPLOY_FREEZE\" ) \"\"\" Included with the value true if the pipeline runs during a deploy freeze window. Added in GitLab 13.2 Available in GitLab Runner all \"\"\" CI_DEPLOY_PASSWORD = EnvProxy ( \"CI_DEPLOY_PASSWORD\" ) \"\"\" Authentication password of the GitLab Deploy Token, only present if the Project has one related. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_DEPLOY_USER = EnvProxy ( \"CI_DEPLOY_USER\" ) \"\"\" Authentication username of the GitLab Deploy Token, only present if the Project has one related. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_DISPOSABLE_ENVIRONMENT = EnvProxy ( \"CI_DISPOSABLE_ENVIRONMENT\" ) \"\"\" Marks that the job is executed in a disposable environment (something that is created only for this job and disposed of/destroyed after the execution - all executors except shell and ssh). If the environment is disposable, it is set to true, otherwise it is not defined at all. Added in GitLab all Available in GitLab Runner 10.1 \"\"\" CI_ENVIRONMENT_NAME = EnvProxy ( \"CI_ENVIRONMENT_NAME\" ) \"\"\" The name of the environment for this job. Only present if environment:name is set. Added in GitLab 8.15 Available in GitLab Runner all \"\"\" CI_ENVIRONMENT_SLUG = EnvProxy ( \"CI_ENVIRONMENT_SLUG\" ) \"\"\" A simplified version of the environment name, suitable for inclusion in DNS, URLs, Kubernetes labels, and so on. Only present if environment:name is set. Added in GitLab 8.15 Available in GitLab Runner all \"\"\" CI_ENVIRONMENT_URL = EnvProxy ( \"CI_ENVIRONMENT_URL\" ) \"\"\" The URL of the environment for this job. Only present if environment:url is set. Added in GitLab 9.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_IID = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_IID\" ) \"\"\" Pull Request ID from GitHub if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_SOURCE_REPOSITORY = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_SOURCE_REPOSITORY\" ) \"\"\" The source repository name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 13.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_TARGET_REPOSITORY = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_TARGET_REPOSITORY\" ) \"\"\" The target repository name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 13.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_NAME = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_NAME\" ) \"\"\" The source branch name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_SHA = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the source branch of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_NAME = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_NAME\" ) \"\"\" The target branch name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_SHA = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the target branch of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_HAS_OPEN_REQUIREMENTS = EnvProxy ( \"CI_HAS_OPEN_REQUIREMENTS\" ) \"\"\" Included with the value true only if the pipeline\u2019s project has any open requirements. Not included if there are no open requirements for the pipeline\u2019s project. Added in GitLab 13.1 Available in GitLab Runner all \"\"\" CI_OPEN_MERGE_REQUESTS = EnvProxy ( \"CI_OPEN_MERGE_REQUESTS\" ) \"\"\" Available in branch and merge request pipelines. Contains a comma-separated list of up to four merge requests that use the current branch and project as the merge request source. For example gitlab-org/gitlab!333,gitlab-org/gitlab-foss!11. Added in GitLab 13.8 Available in GitLab Runner all \"\"\" CI_JOB_ID = EnvProxy ( \"CI_JOB_ID\" ) \"\"\" The unique ID of the current job that GitLab CI/CD uses internally. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_JOB_IMAGE = EnvProxy ( \"CI_JOB_IMAGE\" ) \"\"\" The name of the image running the CI job. Added in GitLab 12.9 Available in GitLab Runner 12.9 \"\"\" CI_JOB_MANUAL = EnvProxy ( \"CI_JOB_MANUAL\" ) \"\"\" The flag to indicate that job was manually started. Added in GitLab 8.12 Available in GitLab Runner all \"\"\" CI_JOB_NAME = EnvProxy ( \"CI_JOB_NAME\" ) \"\"\" The name of the job as defined in .gitlab-ci.yml. Added in GitLab 9.0 Available in GitLab Runner 0.5 \"\"\" CI_JOB_STAGE = EnvProxy ( \"CI_JOB_STAGE\" ) \"\"\" The name of the stage as defined in .gitlab-ci.yml. Added in GitLab 9.0 Available in GitLab Runner 0.5 \"\"\" CI_JOB_STATUS = EnvProxy ( \"CI_JOB_STATUS\" ) \"\"\" The state of the job as each runner stage is executed. Use with after_script where CI_JOB_STATUS can be either success, failed or canceled. Added in GitLab all Available in GitLab Runner 13.5 \"\"\" CI_JOB_TOKEN = EnvProxy ( \"CI_JOB_TOKEN\" ) \"\"\" Token used for authenticating with a few API endpoints and downloading dependent repositories. The token is valid as long as the job is running. Added in GitLab 9.0 Available in GitLab Runner 1.2 \"\"\" CI_JOB_JWT = EnvProxy ( \"CI_JOB_JWT\" ) \"\"\" RS256 JSON web token that can be used for authenticating with third party systems that support JWT authentication, for example HashiCorp\u2019s Vault. Added in GitLab 12.10 Available in GitLab Runner all \"\"\" CI_JOB_URL = EnvProxy ( \"CI_JOB_URL\" ) \"\"\" Job details URL. Added in GitLab 11.1 Available in GitLab Runner 0.5 \"\"\" CI_KUBERNETES_ACTIVE = EnvProxy ( \"CI_KUBERNETES_ACTIVE\" ) \"\"\" Included with the value true only if the pipeline has a Kubernetes cluster available for deployments. Not included if no cluster is available. Can be used as an alternative to only:kubernetes/except:kubernetes with rules:if. Added in GitLab 13.0 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_ASSIGNEES = EnvProxy ( \"CI_MERGE_REQUEST_ASSIGNEES\" ) \"\"\" Comma-separated list of username(s) of assignee(s) for the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_ID = EnvProxy ( \"CI_MERGE_REQUEST_ID\" ) \"\"\" The instance-level ID of the merge request. Only available if the pipelines are for merge requests and the merge request is created. This is a unique ID across all projects on GitLab. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_IID = EnvProxy ( \"CI_MERGE_REQUEST_IID\" ) \"\"\" The project-level IID (internal ID) of the merge request. Only available If the pipelines are for merge requests and the merge request is created. This ID is unique for the current project. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_LABELS = EnvProxy ( \"CI_MERGE_REQUEST_LABELS\" ) \"\"\" Comma-separated label names of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_MILESTONE = EnvProxy ( \"CI_MERGE_REQUEST_MILESTONE\" ) \"\"\" The milestone title of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_PROJECT_ID = EnvProxy ( \"CI_MERGE_REQUEST_PROJECT_ID\" ) \"\"\" The ID of the project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_PROJECT_PATH = EnvProxy ( \"CI_MERGE_REQUEST_PROJECT_PATH\" ) \"\"\" The path of the project of the merge request if the pipelines are for merge requests (for example namespace/awesome-project). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_PROJECT_URL = EnvProxy ( \"CI_MERGE_REQUEST_PROJECT_URL\" ) \"\"\" The URL of the project of the merge request if the pipelines are for merge requests (for example http://192.168.10.15:3000/namespace/awesome-project). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_REF_PATH = EnvProxy ( \"CI_MERGE_REQUEST_REF_PATH\" ) \"\"\" The ref path of the merge request if the pipelines are for merge requests. (for example refs/merge-requests/1/head). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_BRANCH_NAME = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_BRANCH_NAME\" ) \"\"\" The source branch name of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_BRANCH_SHA = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the source branch of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used, the merge request is created, and the pipeline is a merged result pipeline. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_PROJECT_ID = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_PROJECT_ID\" ) \"\"\" The ID of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_PROJECT_PATH = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_PROJECT_PATH\" ) \"\"\" The path of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_PROJECT_URL = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_PROJECT_URL\" ) \"\"\" The URL of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_TARGET_BRANCH_NAME = EnvProxy ( \"CI_MERGE_REQUEST_TARGET_BRANCH_NAME\" ) \"\"\" The target branch name of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_TARGET_BRANCH_SHA = EnvProxy ( \"CI_MERGE_REQUEST_TARGET_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the target branch of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used, the merge request is created, and the pipeline is a merged result pipeline. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_TITLE = EnvProxy ( \"CI_MERGE_REQUEST_TITLE\" ) \"\"\" The title of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_EVENT_TYPE = EnvProxy ( \"CI_MERGE_REQUEST_EVENT_TYPE\" ) \"\"\" The event type of the merge request, if the pipelines are for merge requests. Can be detached, merged_result or merge_train. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_DIFF_ID = EnvProxy ( \"CI_MERGE_REQUEST_DIFF_ID\" ) \"\"\" The version of the merge request diff, if the pipelines are for merge requests. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_DIFF_BASE_SHA = EnvProxy ( \"CI_MERGE_REQUEST_DIFF_BASE_SHA\" ) \"\"\" The base SHA of the merge request diff, if the pipelines are for merge requests. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_NODE_INDEX = EnvProxy ( \"CI_NODE_INDEX\" ) \"\"\" Index of the job in the job set. If the job is not parallelized, this variable is not set. Added in GitLab 11.5 Available in GitLab Runner all \"\"\" CI_NODE_TOTAL = EnvProxy ( \"CI_NODE_TOTAL\" ) \"\"\" Total number of instances of this job running in parallel. If the job is not parallelized, this variable is set to 1. Added in GitLab 11.5 Available in GitLab Runner all \"\"\" CI_PAGES_DOMAIN = EnvProxy ( \"CI_PAGES_DOMAIN\" ) \"\"\" The configured domain that hosts GitLab Pages. Added in GitLab 11.8 Available in GitLab Runner all \"\"\" CI_PAGES_URL = EnvProxy ( \"CI_PAGES_URL\" ) \"\"\" URL to GitLab Pages-built pages. Always belongs to a subdomain of CI_PAGES_DOMAIN. Added in GitLab 11.8 Available in GitLab Runner all \"\"\" CI_PIPELINE_ID = EnvProxy ( \"CI_PIPELINE_ID\" ) \"\"\" The instance-level ID of the current pipeline. This is a unique ID across all projects on GitLab. Added in GitLab 8.10 Available in GitLab Runner all \"\"\" CI_PIPELINE_IID = EnvProxy ( \"CI_PIPELINE_IID\" ) \"\"\" The project-level IID (internal ID) of the current pipeline. This ID is unique for the current project. Added in GitLab 11.0 Available in GitLab Runner all \"\"\" CI_PIPELINE_SOURCE = EnvProxy ( \"CI_PIPELINE_SOURCE\" ) \"\"\" Indicates how the pipeline was triggered. Possible options are push, web, schedule, api, external, chat, webide, merge_request_event, external_pull_request_event, parent_pipeline, trigger, or pipeline. For pipelines created before GitLab 9.5, this is displayed as unknown. Added in GitLab 10.0 Available in GitLab Runner all \"\"\" CI_PIPELINE_TRIGGERED = EnvProxy ( \"CI_PIPELINE_TRIGGERED\" ) \"\"\" The flag to indicate that job was triggered. Added in GitLab all Available in GitLab Runner all \"\"\" CI_PIPELINE_URL = EnvProxy ( \"CI_PIPELINE_URL\" ) \"\"\" Pipeline details URL. Added in GitLab 11.1 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_CONFIG_PATH = EnvProxy ( \"CI_PROJECT_CONFIG_PATH\" ) \"\"\" The CI configuration path for the project. Added in GitLab 13.8 Available in GitLab Runner all \"\"\" CI_PROJECT_DIR = EnvProxy ( \"CI_PROJECT_DIR\" ) \"\"\" The full path where the repository is cloned and where the job is run. If the GitLab Runner builds_dir parameter is set, this variable is set relative to the value of builds_dir. For more information, see Advanced configuration for GitLab Runner. Added in GitLab all Available in GitLab Runner all \"\"\" CI_PROJECT_ID = EnvProxy ( \"CI_PROJECT_ID\" ) \"\"\" The unique ID of the current project that GitLab CI/CD uses internally. Added in GitLab all Available in GitLab Runner all \"\"\" CI_PROJECT_NAME = EnvProxy ( \"CI_PROJECT_NAME\" ) \"\"\" The name of the directory for the project that is being built. For example, if the project URL is gitlab.example.com/group-name/project-1, the CI_PROJECT_NAME would be project-1. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_NAMESPACE = EnvProxy ( \"CI_PROJECT_NAMESPACE\" ) \"\"\" The project namespace (username or group name) that is being built. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_ROOT_NAMESPACE = EnvProxy ( \"CI_PROJECT_ROOT_NAMESPACE\" ) \"\"\" The root project namespace (username or group name) that is being built. For example, if CI_PROJECT_NAMESPACE is root-group/child-group/grandchild-group, CI_PROJECT_ROOT_NAMESPACE would be root-group. Added in GitLab 13.2 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_PATH = EnvProxy ( \"CI_PROJECT_PATH\" ) \"\"\" The namespace with project name. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_PATH_SLUG = EnvProxy ( \"CI_PROJECT_PATH_SLUG\" ) \"\"\" $CI_PROJECT_PATH in lowercase and with everything except 0-9 and a-z replaced with -. Use in URLs and domain names. Added in GitLab 9.3 Available in GitLab Runner all \"\"\" CI_PROJECT_REPOSITORY_LANGUAGES = EnvProxy ( \"CI_PROJECT_REPOSITORY_LANGUAGES\" ) \"\"\" Comma-separated, lowercase list of the languages used in the repository (for example ruby,javascript,html,css). Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_PROJECT_TITLE = EnvProxy ( \"CI_PROJECT_TITLE\" ) \"\"\" The human-readable project name as displayed in the GitLab web interface. Added in GitLab 12.4 Available in GitLab Runner all \"\"\" CI_PROJECT_URL = EnvProxy ( \"CI_PROJECT_URL\" ) \"\"\" The HTTP(S) address to access project. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_VISIBILITY = EnvProxy ( \"CI_PROJECT_VISIBILITY\" ) \"\"\" The project visibility (internal, private, public). Added in GitLab 10.3 Available in GitLab Runner all \"\"\" CI_REGISTRY = EnvProxy ( \"CI_REGISTRY\" ) \"\"\" GitLab Container Registry. This variable includes a :port value if one has been specified in the registry configuration. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_REGISTRY_IMAGE = EnvProxy ( \"CI_REGISTRY_IMAGE\" ) \"\"\" the address of the registry tied to the specific project. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_REGISTRY_PASSWORD = EnvProxy ( \"CI_REGISTRY_PASSWORD\" ) \"\"\" The password to use to push containers to the GitLab Container Registry, for the current project. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_REGISTRY_USER = EnvProxy ( \"CI_REGISTRY_USER\" ) \"\"\" The username to use to push containers to the GitLab Container Registry, for the current project. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_REPOSITORY_URL = EnvProxy ( \"CI_REPOSITORY_URL\" ) \"\"\" The URL to clone the Git repository. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_RUNNER_DESCRIPTION = EnvProxy ( \"CI_RUNNER_DESCRIPTION\" ) \"\"\" The description of the runner as saved in GitLab. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_RUNNER_EXECUTABLE_ARCH = EnvProxy ( \"CI_RUNNER_EXECUTABLE_ARCH\" ) \"\"\" The OS/architecture of the GitLab Runner executable (note that this is not necessarily the same as the environment of the executor). Added in GitLab all Available in GitLab Runner 10.6 \"\"\" CI_RUNNER_ID = EnvProxy ( \"CI_RUNNER_ID\" ) \"\"\" The unique ID of runner being used. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_RUNNER_REVISION = EnvProxy ( \"CI_RUNNER_REVISION\" ) \"\"\" GitLab Runner revision that is executing the current job. Added in GitLab all Available in GitLab Runner 10.6 \"\"\" CI_RUNNER_SHORT_TOKEN = EnvProxy ( \"CI_RUNNER_SHORT_TOKEN\" ) \"\"\" First eight characters of the runner\u2019s token used to authenticate new job requests. Used as the runner\u2019s unique ID. Added in GitLab all Available in GitLab Runner 12.3 \"\"\" CI_RUNNER_TAGS = EnvProxy ( \"CI_RUNNER_TAGS\" ) \"\"\" The defined runner tags. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_RUNNER_VERSION = EnvProxy ( \"CI_RUNNER_VERSION\" ) \"\"\" GitLab Runner version that is executing the current job. Added in GitLab all Available in GitLab Runner 10.6 \"\"\" CI_SERVER = EnvProxy ( \"CI_SERVER\" ) \"\"\" Mark that job is executed in CI environment. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_URL = EnvProxy ( \"CI_SERVER_URL\" ) \"\"\" The base URL of the GitLab instance, including protocol and port (like https://gitlab.example.com:8080). Added in GitLab 12.7 Available in GitLab Runner all \"\"\" CI_SERVER_HOST = EnvProxy ( \"CI_SERVER_HOST\" ) \"\"\" Host component of the GitLab instance URL, without protocol and port (like gitlab.example.com). Added in GitLab 12.1 Available in GitLab Runner all \"\"\" CI_SERVER_PORT = EnvProxy ( \"CI_SERVER_PORT\" ) \"\"\" Port component of the GitLab instance URL, without host and protocol (like 3000). Added in GitLab 12.8 Available in GitLab Runner all \"\"\" CI_SERVER_PROTOCOL = EnvProxy ( \"CI_SERVER_PROTOCOL\" ) \"\"\" Protocol component of the GitLab instance URL, without host and port (like https). Added in GitLab 12.8 Available in GitLab Runner all \"\"\" CI_SERVER_NAME = EnvProxy ( \"CI_SERVER_NAME\" ) \"\"\" The name of CI server that is used to coordinate jobs. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_REVISION = EnvProxy ( \"CI_SERVER_REVISION\" ) \"\"\" GitLab revision that is used to schedule jobs. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_VERSION = EnvProxy ( \"CI_SERVER_VERSION\" ) \"\"\" GitLab version that is used to schedule jobs. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_VERSION_MAJOR = EnvProxy ( \"CI_SERVER_VERSION_MAJOR\" ) \"\"\" GitLab version major component. Added in GitLab 11.4 Available in GitLab Runner all \"\"\" CI_SERVER_VERSION_MINOR = EnvProxy ( \"CI_SERVER_VERSION_MINOR\" ) \"\"\" GitLab version minor component. Added in GitLab 11.4 Available in GitLab Runner all \"\"\" CI_SERVER_VERSION_PATCH = EnvProxy ( \"CI_SERVER_VERSION_PATCH\" ) \"\"\" GitLab version patch component. Added in GitLab 11.4 Available in GitLab Runner all \"\"\" CI_SHARED_ENVIRONMENT = EnvProxy ( \"CI_SHARED_ENVIRONMENT\" ) \"\"\" Marks that the job is executed in a shared environment (something that is persisted across CI invocations like shell or ssh executor). If the environment is shared, it is set to true, otherwise it is not defined at all. Added in GitLab all Available in GitLab Runner 10.1 \"\"\" GITLAB_CI = EnvProxy ( \"GITLAB_CI\" ) \"\"\" Mark that job is executed in GitLab CI/CD environment. Added in GitLab all Available in GitLab Runner all \"\"\" GITLAB_FEATURES = EnvProxy ( \"GITLAB_FEATURES\" ) \"\"\" The comma separated list of licensed features available for your instance and plan. Added in GitLab 10.6 Available in GitLab Runner all \"\"\" GITLAB_USER_EMAIL = EnvProxy ( \"GITLAB_USER_EMAIL\" ) \"\"\" The email of the user who started the job. Added in GitLab 8.12 Available in GitLab Runner all \"\"\" GITLAB_USER_ID = EnvProxy ( \"GITLAB_USER_ID\" ) \"\"\" The ID of the user who started the job. Added in GitLab 8.12 Available in GitLab Runner all \"\"\" GITLAB_USER_LOGIN = EnvProxy ( \"GITLAB_USER_LOGIN\" ) \"\"\" The login username of the user who started the job. Added in GitLab 10.0 Available in GitLab Runner all \"\"\" GITLAB_USER_NAME = EnvProxy ( \"GITLAB_USER_NAME\" ) \"\"\" The real name of the user who started the job. Added in GitLab 10.0 Available in GitLab Runner all \"\"\" TRIGGER_PAYLOAD = EnvProxy ( \"TRIGGER_PAYLOAD\" ) \"\"\" This variable is available when a pipeline is triggered with a webhook Added in GitLab 13.9 Available in GitLab Runner all \"\"\" Class variables CHAT_CHANNEL Source chat channel which triggered the ChatOps command. Added in GitLab 10.6 Available in GitLab Runner all CHAT_INPUT Additional arguments passed in the ChatOps command. Added in GitLab 10.6 Available in GitLab Runner all CI Mark that job is executed in CI environment. Added in GitLab all Available in GitLab Runner 0.4 CI_API_V4_URL The GitLab API v4 root URL. Added in GitLab 11.7 Available in GitLab Runner all CI_BUILDS_DIR Top-level directory where builds are executed. Added in GitLab all Available in GitLab Runner 11.10 CI_COMMIT_BEFORE_SHA The previous latest commit present on a branch. Is always 0000000000000000000000000000000000000000 in pipelines for merge requests. Added in GitLab 11.2 Available in GitLab Runner all CI_COMMIT_BRANCH The commit branch name. Present in branch pipelines, including pipelines for the default branch. Not present in merge request pipelines or tag pipelines. Added in GitLab 12.6 Available in GitLab Runner 0.5 CI_COMMIT_DESCRIPTION The description of the commit the message without first line, if the title is shorter than 100 characters; full message in other case. Added in GitLab 10.8 Available in GitLab Runner all CI_COMMIT_MESSAGE The full commit message. Added in GitLab 10.8 Available in GitLab Runner all CI_COMMIT_REF_NAME The branch or tag name for which project is built. Added in GitLab 9.0 Available in GitLab Runner all CI_COMMIT_REF_PROTECTED true if the job is running on a protected reference, false if not. Added in GitLab 11.11 Available in GitLab Runner all CI_COMMIT_REF_SLUG $CI_COMMIT_REF_NAME in lowercase, shortened to 63 bytes, and with everything except 0-9 and a-z replaced with -. No leading / trailing -. Use in URLs, host names and domain names. Added in GitLab 9.0 Available in GitLab Runner all CI_COMMIT_SHA The commit revision for which project is built. Added in GitLab 9.0 Available in GitLab Runner all CI_COMMIT_SHORT_SHA The first eight characters of CI_COMMIT_SHA. Added in GitLab 11.7 Available in GitLab Runner all CI_COMMIT_TAG The commit tag name. Present only when building tags. Added in GitLab 9.0 Available in GitLab Runner 0.5 CI_COMMIT_TIMESTAMP The timestamp of the commit in the ISO 8601 format. Added in GitLab 13.4 Available in GitLab Runner all CI_COMMIT_TITLE The title of the commit - the full first line of the message. Added in GitLab 10.8 Available in GitLab Runner all CI_CONCURRENT_ID Unique ID of build execution in a single executor. Added in GitLab all Available in GitLab Runner 11.10 CI_CONCURRENT_PROJECT_ID Unique ID of build execution in a single executor and project. Added in GitLab all Available in GitLab Runner 11.10 CI_CONFIG_PATH The path to CI configuration file. Defaults to .gitlab-ci.yml. Added in GitLab 9.4 Available in GitLab Runner 0.5 CI_DEBUG_TRACE Whether debug logging (tracing) is enabled. Added in GitLab all Available in GitLab Runner 1.7 CI_DEFAULT_BRANCH The name of the default branch for the project. Added in GitLab 12.4 Available in GitLab Runner all CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX The image prefix for pulling images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all CI_DEPENDENCY_PROXY_PASSWORD The password to use to pull images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all CI_DEPENDENCY_PROXY_SERVER The server for logging in to the Dependency Proxy. This is equivalent to $CI_SERVER_HOST:$CI_SERVER_PORT. Added in GitLab 13.7 Available in GitLab Runner all CI_DEPENDENCY_PROXY_USER The username to use to pull images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all CI_DEPLOY_FREEZE Included with the value true if the pipeline runs during a deploy freeze window. Added in GitLab 13.2 Available in GitLab Runner all CI_DEPLOY_PASSWORD Authentication password of the GitLab Deploy Token, only present if the Project has one related. Added in GitLab 10.8 Available in GitLab Runner all CI_DEPLOY_USER Authentication username of the GitLab Deploy Token, only present if the Project has one related. Added in GitLab 10.8 Available in GitLab Runner all CI_DISPOSABLE_ENVIRONMENT Marks that the job is executed in a disposable environment (something that is created only for this job and disposed of/destroyed after the execution - all executors except shell and ssh). If the environment is disposable, it is set to true, otherwise it is not defined at all. Added in GitLab all Available in GitLab Runner 10.1 CI_ENVIRONMENT_NAME The name of the environment for this job. Only present if environment:name is set. Added in GitLab 8.15 Available in GitLab Runner all CI_ENVIRONMENT_SLUG A simplified version of the environment name, suitable for inclusion in DNS, URLs, Kubernetes labels, and so on. Only present if environment:name is set. Added in GitLab 8.15 Available in GitLab Runner all CI_ENVIRONMENT_URL The URL of the environment for this job. Only present if environment:url is set. Added in GitLab 9.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_IID Pull Request ID from GitHub if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_NAME The source branch name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_SHA The HEAD SHA of the source branch of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_SOURCE_REPOSITORY The source repository name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 13.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_NAME The target branch name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_SHA The HEAD SHA of the target branch of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_TARGET_REPOSITORY The target repository name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 13.3 Available in GitLab Runner all CI_HAS_OPEN_REQUIREMENTS Included with the value true only if the pipeline\u2019s project has any open requirements. Not included if there are no open requirements for the pipeline\u2019s project. Added in GitLab 13.1 Available in GitLab Runner all CI_JOB_ID The unique ID of the current job that GitLab CI/CD uses internally. Added in GitLab 9.0 Available in GitLab Runner all CI_JOB_IMAGE The name of the image running the CI job. Added in GitLab 12.9 Available in GitLab Runner 12.9 CI_JOB_JWT RS256 JSON web token that can be used for authenticating with third party systems that support JWT authentication, for example HashiCorp\u2019s Vault. Added in GitLab 12.10 Available in GitLab Runner all CI_JOB_MANUAL The flag to indicate that job was manually started. Added in GitLab 8.12 Available in GitLab Runner all CI_JOB_NAME The name of the job as defined in .gitlab-ci.yml. Added in GitLab 9.0 Available in GitLab Runner 0.5 CI_JOB_STAGE The name of the stage as defined in .gitlab-ci.yml. Added in GitLab 9.0 Available in GitLab Runner 0.5 CI_JOB_STATUS The state of the job as each runner stage is executed. Use with after_script where CI_JOB_STATUS can be either success, failed or canceled. Added in GitLab all Available in GitLab Runner 13.5 CI_JOB_TOKEN Token used for authenticating with a few API endpoints and downloading dependent repositories. The token is valid as long as the job is running. Added in GitLab 9.0 Available in GitLab Runner 1.2 CI_JOB_URL Job details URL. Added in GitLab 11.1 Available in GitLab Runner 0.5 CI_KUBERNETES_ACTIVE Included with the value true only if the pipeline has a Kubernetes cluster available for deployments. Not included if no cluster is available. Can be used as an alternative to only:kubernetes/except:kubernetes with rules:if. Added in GitLab 13.0 Available in GitLab Runner all CI_MERGE_REQUEST_ASSIGNEES Comma-separated list of username(s) of assignee(s) for the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all CI_MERGE_REQUEST_DIFF_BASE_SHA The base SHA of the merge request diff, if the pipelines are for merge requests. Added in GitLab 13.7 Available in GitLab Runner all CI_MERGE_REQUEST_DIFF_ID The version of the merge request diff, if the pipelines are for merge requests. Added in GitLab 13.7 Available in GitLab Runner all CI_MERGE_REQUEST_EVENT_TYPE The event type of the merge request, if the pipelines are for merge requests. Can be detached, merged_result or merge_train. Added in GitLab 12.3 Available in GitLab Runner all CI_MERGE_REQUEST_ID The instance-level ID of the merge request. Only available if the pipelines are for merge requests and the merge request is created. This is a unique ID across all projects on GitLab. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_IID The project-level IID (internal ID) of the merge request. Only available If the pipelines are for merge requests and the merge request is created. This ID is unique for the current project. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_LABELS Comma-separated label names of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all CI_MERGE_REQUEST_MILESTONE The milestone title of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all CI_MERGE_REQUEST_PROJECT_ID The ID of the project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_PROJECT_PATH The path of the project of the merge request if the pipelines are for merge requests (for example namespace/awesome-project). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_PROJECT_URL The URL of the project of the merge request if the pipelines are for merge requests (for example http://192.168.10.15:3000/namespace/awesome-project). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_REF_PATH The ref path of the merge request if the pipelines are for merge requests. (for example refs/merge-requests/1/head). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_SOURCE_BRANCH_NAME The source branch name of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_SOURCE_BRANCH_SHA The HEAD SHA of the source branch of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used, the merge request is created, and the pipeline is a merged result pipeline. Added in GitLab 11.9 Available in GitLab Runner all CI_MERGE_REQUEST_SOURCE_PROJECT_ID The ID of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_SOURCE_PROJECT_PATH The path of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_SOURCE_PROJECT_URL The URL of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_TARGET_BRANCH_NAME The target branch name of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_TARGET_BRANCH_SHA The HEAD SHA of the target branch of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used, the merge request is created, and the pipeline is a merged result pipeline. Added in GitLab 11.9 Available in GitLab Runner all CI_MERGE_REQUEST_TITLE The title of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all CI_NODE_INDEX Index of the job in the job set. If the job is not parallelized, this variable is not set. Added in GitLab 11.5 Available in GitLab Runner all CI_NODE_TOTAL Total number of instances of this job running in parallel. If the job is not parallelized, this variable is set to 1. Added in GitLab 11.5 Available in GitLab Runner all CI_OPEN_MERGE_REQUESTS Available in branch and merge request pipelines. Contains a comma-separated list of up to four merge requests that use the current branch and project as the merge request source. For example gitlab-org/gitlab!333,gitlab-org/gitlab-foss!11. Added in GitLab 13.8 Available in GitLab Runner all CI_PAGES_DOMAIN The configured domain that hosts GitLab Pages. Added in GitLab 11.8 Available in GitLab Runner all CI_PAGES_URL URL to GitLab Pages-built pages. Always belongs to a subdomain of CI_PAGES_DOMAIN. Added in GitLab 11.8 Available in GitLab Runner all CI_PIPELINE_ID The instance-level ID of the current pipeline. This is a unique ID across all projects on GitLab. Added in GitLab 8.10 Available in GitLab Runner all CI_PIPELINE_IID The project-level IID (internal ID) of the current pipeline. This ID is unique for the current project. Added in GitLab 11.0 Available in GitLab Runner all CI_PIPELINE_SOURCE Indicates how the pipeline was triggered. Possible options are push, web, schedule, api, external, chat, webide, merge_request_event, external_pull_request_event, parent_pipeline, trigger, or pipeline. For pipelines created before GitLab 9.5, this is displayed as unknown. Added in GitLab 10.0 Available in GitLab Runner all CI_PIPELINE_TRIGGERED The flag to indicate that job was triggered. Added in GitLab all Available in GitLab Runner all CI_PIPELINE_URL Pipeline details URL. Added in GitLab 11.1 Available in GitLab Runner 0.5 CI_PROJECT_CONFIG_PATH The CI configuration path for the project. Added in GitLab 13.8 Available in GitLab Runner all CI_PROJECT_DIR The full path where the repository is cloned and where the job is run. If the GitLab Runner builds_dir parameter is set, this variable is set relative to the value of builds_dir. For more information, see Advanced configuration for GitLab Runner. Added in GitLab all Available in GitLab Runner all CI_PROJECT_ID The unique ID of the current project that GitLab CI/CD uses internally. Added in GitLab all Available in GitLab Runner all CI_PROJECT_NAME The name of the directory for the project that is being built. For example, if the project URL is gitlab.example.com/group-name/project-1, the CI_PROJECT_NAME would be project-1. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_PROJECT_NAMESPACE The project namespace (username or group name) that is being built. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_PROJECT_PATH The namespace with project name. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_PROJECT_PATH_SLUG $CI_PROJECT_PATH in lowercase and with everything except 0-9 and a-z replaced with -. Use in URLs and domain names. Added in GitLab 9.3 Available in GitLab Runner all CI_PROJECT_REPOSITORY_LANGUAGES Comma-separated, lowercase list of the languages used in the repository (for example ruby,javascript,html,css). Added in GitLab 12.3 Available in GitLab Runner all CI_PROJECT_ROOT_NAMESPACE The root project namespace (username or group name) that is being built. For example, if CI_PROJECT_NAMESPACE is root-group/child-group/grandchild-group, CI_PROJECT_ROOT_NAMESPACE would be root-group. Added in GitLab 13.2 Available in GitLab Runner 0.5 CI_PROJECT_TITLE The human-readable project name as displayed in the GitLab web interface. Added in GitLab 12.4 Available in GitLab Runner all CI_PROJECT_URL The HTTP(S) address to access project. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_PROJECT_VISIBILITY The project visibility (internal, private, public). Added in GitLab 10.3 Available in GitLab Runner all CI_REGISTRY GitLab Container Registry. This variable includes a :port value if one has been specified in the registry configuration. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_REGISTRY_IMAGE the address of the registry tied to the specific project. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_REGISTRY_PASSWORD The password to use to push containers to the GitLab Container Registry, for the current project. Added in GitLab 9.0 Available in GitLab Runner all CI_REGISTRY_USER The username to use to push containers to the GitLab Container Registry, for the current project. Added in GitLab 9.0 Available in GitLab Runner all CI_REPOSITORY_URL The URL to clone the Git repository. Added in GitLab 9.0 Available in GitLab Runner all CI_RUNNER_DESCRIPTION The description of the runner as saved in GitLab. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_RUNNER_EXECUTABLE_ARCH The OS/architecture of the GitLab Runner executable (note that this is not necessarily the same as the environment of the executor). Added in GitLab all Available in GitLab Runner 10.6 CI_RUNNER_ID The unique ID of runner being used. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_RUNNER_REVISION GitLab Runner revision that is executing the current job. Added in GitLab all Available in GitLab Runner 10.6 CI_RUNNER_SHORT_TOKEN First eight characters of the runner\u2019s token used to authenticate new job requests. Used as the runner\u2019s unique ID. Added in GitLab all Available in GitLab Runner 12.3 CI_RUNNER_TAGS The defined runner tags. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_RUNNER_VERSION GitLab Runner version that is executing the current job. Added in GitLab all Available in GitLab Runner 10.6 CI_SERVER Mark that job is executed in CI environment. Added in GitLab all Available in GitLab Runner all CI_SERVER_HOST Host component of the GitLab instance URL, without protocol and port (like gitlab.example.com). Added in GitLab 12.1 Available in GitLab Runner all CI_SERVER_NAME The name of CI server that is used to coordinate jobs. Added in GitLab all Available in GitLab Runner all CI_SERVER_PORT Port component of the GitLab instance URL, without host and protocol (like 3000). Added in GitLab 12.8 Available in GitLab Runner all CI_SERVER_PROTOCOL Protocol component of the GitLab instance URL, without host and port (like https). Added in GitLab 12.8 Available in GitLab Runner all CI_SERVER_REVISION GitLab revision that is used to schedule jobs. Added in GitLab all Available in GitLab Runner all CI_SERVER_URL The base URL of the GitLab instance, including protocol and port (like https://gitlab.example.com:8080). Added in GitLab 12.7 Available in GitLab Runner all CI_SERVER_VERSION GitLab version that is used to schedule jobs. Added in GitLab all Available in GitLab Runner all CI_SERVER_VERSION_MAJOR GitLab version major component. Added in GitLab 11.4 Available in GitLab Runner all CI_SERVER_VERSION_MINOR GitLab version minor component. Added in GitLab 11.4 Available in GitLab Runner all CI_SERVER_VERSION_PATCH GitLab version patch component. Added in GitLab 11.4 Available in GitLab Runner all CI_SHARED_ENVIRONMENT Marks that the job is executed in a shared environment (something that is persisted across CI invocations like shell or ssh executor). If the environment is shared, it is set to true, otherwise it is not defined at all. Added in GitLab all Available in GitLab Runner 10.1 GITLAB_CI Mark that job is executed in GitLab CI/CD environment. Added in GitLab all Available in GitLab Runner all GITLAB_FEATURES The comma separated list of licensed features available for your instance and plan. Added in GitLab 10.6 Available in GitLab Runner all GITLAB_USER_EMAIL The email of the user who started the job. Added in GitLab 8.12 Available in GitLab Runner all GITLAB_USER_ID The ID of the user who started the job. Added in GitLab 8.12 Available in GitLab Runner all GITLAB_USER_LOGIN The login username of the user who started the job. Added in GitLab 10.0 Available in GitLab Runner all GITLAB_USER_NAME The real name of the user who started the job. Added in GitLab 10.0 Available in GitLab Runner all TRIGGER_PAYLOAD This variable is available when a pipeline is triggered with a webhook Added in GitLab 13.9 Available in GitLab Runner all","title":"Variables"},{"location":"reference/gcip/core/variables/#module-gcipcorevariables","text":"None None View Source import os from typing import Any # In Python >= 3.9 it is also possible to use @classmethods and @property # together, so that there are no parantheses necessarry. # See https://stackoverflow.com/questions/128573/using-property-on-classmethods\u00b4 class EnvProxy (): def __init__ ( self , key : str ) -> None : self . key = key def __get__ ( self , obj : Any , objtype : Any = None ) -> str : return os . getenv ( self . key ) class PredefinedVariables (): \"\"\" Gitlab CI predefined variables. https://docs.gitlab.com/ee/ci/variables/predefined_variables.html \"\"\" CHAT_CHANNEL = EnvProxy ( \"CHAT_CHANNEL\" ) \"\"\" Source chat channel which triggered the ChatOps command. Added in GitLab 10.6 Available in GitLab Runner all \"\"\" CHAT_INPUT = EnvProxy ( \"CHAT_INPUT\" ) \"\"\" Additional arguments passed in the ChatOps command. Added in GitLab 10.6 Available in GitLab Runner all \"\"\" CI = EnvProxy ( \"CI\" ) \"\"\" Mark that job is executed in CI environment. Added in GitLab all Available in GitLab Runner 0.4 \"\"\" CI_API_V4_URL = EnvProxy ( \"CI_API_V4_URL\" ) \"\"\" The GitLab API v4 root URL. Added in GitLab 11.7 Available in GitLab Runner all \"\"\" CI_BUILDS_DIR = EnvProxy ( \"CI_BUILDS_DIR\" ) \"\"\" Top-level directory where builds are executed. Added in GitLab all Available in GitLab Runner 11.10 \"\"\" CI_COMMIT_BEFORE_SHA = EnvProxy ( \"CI_COMMIT_BEFORE_SHA\" ) \"\"\" The previous latest commit present on a branch. Is always 0000000000000000000000000000000000000000 in pipelines for merge requests. Added in GitLab 11.2 Available in GitLab Runner all \"\"\" CI_COMMIT_DESCRIPTION = EnvProxy ( \"CI_COMMIT_DESCRIPTION\" ) \"\"\" The description of the commit the message without first line, if the title is shorter than 100 characters; full message in other case. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_COMMIT_MESSAGE = EnvProxy ( \"CI_COMMIT_MESSAGE\" ) \"\"\" The full commit message. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_COMMIT_REF_NAME = EnvProxy ( \"CI_COMMIT_REF_NAME\" ) \"\"\" The branch or tag name for which project is built. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_COMMIT_REF_PROTECTED = EnvProxy ( \"CI_COMMIT_REF_PROTECTED\" ) \"\"\" true if the job is running on a protected reference, false if not. Added in GitLab 11.11 Available in GitLab Runner all \"\"\" CI_COMMIT_REF_SLUG = EnvProxy ( \"CI_COMMIT_REF_SLUG\" ) \"\"\" $CI_COMMIT_REF_NAME in lowercase, shortened to 63 bytes, and with everything except 0-9 and a-z replaced with -. No leading / trailing -. Use in URLs, host names and domain names. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_COMMIT_SHA = EnvProxy ( \"CI_COMMIT_SHA\" ) \"\"\" The commit revision for which project is built. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_COMMIT_SHORT_SHA = EnvProxy ( \"CI_COMMIT_SHORT_SHA\" ) \"\"\" The first eight characters of CI_COMMIT_SHA. Added in GitLab 11.7 Available in GitLab Runner all \"\"\" CI_COMMIT_BRANCH = EnvProxy ( \"CI_COMMIT_BRANCH\" ) \"\"\" The commit branch name. Present in branch pipelines, including pipelines for the default branch. Not present in merge request pipelines or tag pipelines. Added in GitLab 12.6 Available in GitLab Runner 0.5 \"\"\" CI_COMMIT_TAG = EnvProxy ( \"CI_COMMIT_TAG\" ) \"\"\" The commit tag name. Present only when building tags. Added in GitLab 9.0 Available in GitLab Runner 0.5 \"\"\" CI_COMMIT_TITLE = EnvProxy ( \"CI_COMMIT_TITLE\" ) \"\"\" The title of the commit - the full first line of the message. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_COMMIT_TIMESTAMP = EnvProxy ( \"CI_COMMIT_TIMESTAMP\" ) \"\"\" The timestamp of the commit in the ISO 8601 format. Added in GitLab 13.4 Available in GitLab Runner all \"\"\" CI_CONCURRENT_ID = EnvProxy ( \"CI_CONCURRENT_ID\" ) \"\"\" Unique ID of build execution in a single executor. Added in GitLab all Available in GitLab Runner 11.10 \"\"\" CI_CONCURRENT_PROJECT_ID = EnvProxy ( \"CI_CONCURRENT_PROJECT_ID\" ) \"\"\" Unique ID of build execution in a single executor and project. Added in GitLab all Available in GitLab Runner 11.10 \"\"\" CI_CONFIG_PATH = EnvProxy ( \"CI_CONFIG_PATH\" ) \"\"\" The path to CI configuration file. Defaults to .gitlab-ci.yml. Added in GitLab 9.4 Available in GitLab Runner 0.5 \"\"\" CI_DEBUG_TRACE = EnvProxy ( \"CI_DEBUG_TRACE\" ) \"\"\" Whether debug logging (tracing) is enabled. Added in GitLab all Available in GitLab Runner 1.7 \"\"\" CI_DEFAULT_BRANCH = EnvProxy ( \"CI_DEFAULT_BRANCH\" ) \"\"\" The name of the default branch for the project. Added in GitLab 12.4 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX = EnvProxy ( \"CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX\" ) \"\"\" The image prefix for pulling images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_SERVER = EnvProxy ( \"CI_DEPENDENCY_PROXY_SERVER\" ) \"\"\" The server for logging in to the Dependency Proxy. This is equivalent to $CI_SERVER_HOST:$CI_SERVER_PORT. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_PASSWORD = EnvProxy ( \"CI_DEPENDENCY_PROXY_PASSWORD\" ) \"\"\" The password to use to pull images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_USER = EnvProxy ( \"CI_DEPENDENCY_PROXY_USER\" ) \"\"\" The username to use to pull images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPLOY_FREEZE = EnvProxy ( \"CI_DEPLOY_FREEZE\" ) \"\"\" Included with the value true if the pipeline runs during a deploy freeze window. Added in GitLab 13.2 Available in GitLab Runner all \"\"\" CI_DEPLOY_PASSWORD = EnvProxy ( \"CI_DEPLOY_PASSWORD\" ) \"\"\" Authentication password of the GitLab Deploy Token, only present if the Project has one related. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_DEPLOY_USER = EnvProxy ( \"CI_DEPLOY_USER\" ) \"\"\" Authentication username of the GitLab Deploy Token, only present if the Project has one related. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_DISPOSABLE_ENVIRONMENT = EnvProxy ( \"CI_DISPOSABLE_ENVIRONMENT\" ) \"\"\" Marks that the job is executed in a disposable environment (something that is created only for this job and disposed of/destroyed after the execution - all executors except shell and ssh). If the environment is disposable, it is set to true, otherwise it is not defined at all. Added in GitLab all Available in GitLab Runner 10.1 \"\"\" CI_ENVIRONMENT_NAME = EnvProxy ( \"CI_ENVIRONMENT_NAME\" ) \"\"\" The name of the environment for this job. Only present if environment:name is set. Added in GitLab 8.15 Available in GitLab Runner all \"\"\" CI_ENVIRONMENT_SLUG = EnvProxy ( \"CI_ENVIRONMENT_SLUG\" ) \"\"\" A simplified version of the environment name, suitable for inclusion in DNS, URLs, Kubernetes labels, and so on. Only present if environment:name is set. Added in GitLab 8.15 Available in GitLab Runner all \"\"\" CI_ENVIRONMENT_URL = EnvProxy ( \"CI_ENVIRONMENT_URL\" ) \"\"\" The URL of the environment for this job. Only present if environment:url is set. Added in GitLab 9.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_IID = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_IID\" ) \"\"\" Pull Request ID from GitHub if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_SOURCE_REPOSITORY = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_SOURCE_REPOSITORY\" ) \"\"\" The source repository name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 13.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_TARGET_REPOSITORY = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_TARGET_REPOSITORY\" ) \"\"\" The target repository name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 13.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_NAME = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_NAME\" ) \"\"\" The source branch name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_SHA = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the source branch of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_NAME = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_NAME\" ) \"\"\" The target branch name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_SHA = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the target branch of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_HAS_OPEN_REQUIREMENTS = EnvProxy ( \"CI_HAS_OPEN_REQUIREMENTS\" ) \"\"\" Included with the value true only if the pipeline\u2019s project has any open requirements. Not included if there are no open requirements for the pipeline\u2019s project. Added in GitLab 13.1 Available in GitLab Runner all \"\"\" CI_OPEN_MERGE_REQUESTS = EnvProxy ( \"CI_OPEN_MERGE_REQUESTS\" ) \"\"\" Available in branch and merge request pipelines. Contains a comma-separated list of up to four merge requests that use the current branch and project as the merge request source. For example gitlab-org/gitlab!333,gitlab-org/gitlab-foss!11. Added in GitLab 13.8 Available in GitLab Runner all \"\"\" CI_JOB_ID = EnvProxy ( \"CI_JOB_ID\" ) \"\"\" The unique ID of the current job that GitLab CI/CD uses internally. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_JOB_IMAGE = EnvProxy ( \"CI_JOB_IMAGE\" ) \"\"\" The name of the image running the CI job. Added in GitLab 12.9 Available in GitLab Runner 12.9 \"\"\" CI_JOB_MANUAL = EnvProxy ( \"CI_JOB_MANUAL\" ) \"\"\" The flag to indicate that job was manually started. Added in GitLab 8.12 Available in GitLab Runner all \"\"\" CI_JOB_NAME = EnvProxy ( \"CI_JOB_NAME\" ) \"\"\" The name of the job as defined in .gitlab-ci.yml. Added in GitLab 9.0 Available in GitLab Runner 0.5 \"\"\" CI_JOB_STAGE = EnvProxy ( \"CI_JOB_STAGE\" ) \"\"\" The name of the stage as defined in .gitlab-ci.yml. Added in GitLab 9.0 Available in GitLab Runner 0.5 \"\"\" CI_JOB_STATUS = EnvProxy ( \"CI_JOB_STATUS\" ) \"\"\" The state of the job as each runner stage is executed. Use with after_script where CI_JOB_STATUS can be either success, failed or canceled. Added in GitLab all Available in GitLab Runner 13.5 \"\"\" CI_JOB_TOKEN = EnvProxy ( \"CI_JOB_TOKEN\" ) \"\"\" Token used for authenticating with a few API endpoints and downloading dependent repositories. The token is valid as long as the job is running. Added in GitLab 9.0 Available in GitLab Runner 1.2 \"\"\" CI_JOB_JWT = EnvProxy ( \"CI_JOB_JWT\" ) \"\"\" RS256 JSON web token that can be used for authenticating with third party systems that support JWT authentication, for example HashiCorp\u2019s Vault. Added in GitLab 12.10 Available in GitLab Runner all \"\"\" CI_JOB_URL = EnvProxy ( \"CI_JOB_URL\" ) \"\"\" Job details URL. Added in GitLab 11.1 Available in GitLab Runner 0.5 \"\"\" CI_KUBERNETES_ACTIVE = EnvProxy ( \"CI_KUBERNETES_ACTIVE\" ) \"\"\" Included with the value true only if the pipeline has a Kubernetes cluster available for deployments. Not included if no cluster is available. Can be used as an alternative to only:kubernetes/except:kubernetes with rules:if. Added in GitLab 13.0 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_ASSIGNEES = EnvProxy ( \"CI_MERGE_REQUEST_ASSIGNEES\" ) \"\"\" Comma-separated list of username(s) of assignee(s) for the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_ID = EnvProxy ( \"CI_MERGE_REQUEST_ID\" ) \"\"\" The instance-level ID of the merge request. Only available if the pipelines are for merge requests and the merge request is created. This is a unique ID across all projects on GitLab. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_IID = EnvProxy ( \"CI_MERGE_REQUEST_IID\" ) \"\"\" The project-level IID (internal ID) of the merge request. Only available If the pipelines are for merge requests and the merge request is created. This ID is unique for the current project. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_LABELS = EnvProxy ( \"CI_MERGE_REQUEST_LABELS\" ) \"\"\" Comma-separated label names of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_MILESTONE = EnvProxy ( \"CI_MERGE_REQUEST_MILESTONE\" ) \"\"\" The milestone title of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_PROJECT_ID = EnvProxy ( \"CI_MERGE_REQUEST_PROJECT_ID\" ) \"\"\" The ID of the project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_PROJECT_PATH = EnvProxy ( \"CI_MERGE_REQUEST_PROJECT_PATH\" ) \"\"\" The path of the project of the merge request if the pipelines are for merge requests (for example namespace/awesome-project). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_PROJECT_URL = EnvProxy ( \"CI_MERGE_REQUEST_PROJECT_URL\" ) \"\"\" The URL of the project of the merge request if the pipelines are for merge requests (for example http://192.168.10.15:3000/namespace/awesome-project). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_REF_PATH = EnvProxy ( \"CI_MERGE_REQUEST_REF_PATH\" ) \"\"\" The ref path of the merge request if the pipelines are for merge requests. (for example refs/merge-requests/1/head). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_BRANCH_NAME = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_BRANCH_NAME\" ) \"\"\" The source branch name of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_BRANCH_SHA = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the source branch of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used, the merge request is created, and the pipeline is a merged result pipeline. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_PROJECT_ID = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_PROJECT_ID\" ) \"\"\" The ID of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_PROJECT_PATH = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_PROJECT_PATH\" ) \"\"\" The path of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_PROJECT_URL = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_PROJECT_URL\" ) \"\"\" The URL of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_TARGET_BRANCH_NAME = EnvProxy ( \"CI_MERGE_REQUEST_TARGET_BRANCH_NAME\" ) \"\"\" The target branch name of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_TARGET_BRANCH_SHA = EnvProxy ( \"CI_MERGE_REQUEST_TARGET_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the target branch of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used, the merge request is created, and the pipeline is a merged result pipeline. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_TITLE = EnvProxy ( \"CI_MERGE_REQUEST_TITLE\" ) \"\"\" The title of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_EVENT_TYPE = EnvProxy ( \"CI_MERGE_REQUEST_EVENT_TYPE\" ) \"\"\" The event type of the merge request, if the pipelines are for merge requests. Can be detached, merged_result or merge_train. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_DIFF_ID = EnvProxy ( \"CI_MERGE_REQUEST_DIFF_ID\" ) \"\"\" The version of the merge request diff, if the pipelines are for merge requests. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_DIFF_BASE_SHA = EnvProxy ( \"CI_MERGE_REQUEST_DIFF_BASE_SHA\" ) \"\"\" The base SHA of the merge request diff, if the pipelines are for merge requests. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_NODE_INDEX = EnvProxy ( \"CI_NODE_INDEX\" ) \"\"\" Index of the job in the job set. If the job is not parallelized, this variable is not set. Added in GitLab 11.5 Available in GitLab Runner all \"\"\" CI_NODE_TOTAL = EnvProxy ( \"CI_NODE_TOTAL\" ) \"\"\" Total number of instances of this job running in parallel. If the job is not parallelized, this variable is set to 1. Added in GitLab 11.5 Available in GitLab Runner all \"\"\" CI_PAGES_DOMAIN = EnvProxy ( \"CI_PAGES_DOMAIN\" ) \"\"\" The configured domain that hosts GitLab Pages. Added in GitLab 11.8 Available in GitLab Runner all \"\"\" CI_PAGES_URL = EnvProxy ( \"CI_PAGES_URL\" ) \"\"\" URL to GitLab Pages-built pages. Always belongs to a subdomain of CI_PAGES_DOMAIN. Added in GitLab 11.8 Available in GitLab Runner all \"\"\" CI_PIPELINE_ID = EnvProxy ( \"CI_PIPELINE_ID\" ) \"\"\" The instance-level ID of the current pipeline. This is a unique ID across all projects on GitLab. Added in GitLab 8.10 Available in GitLab Runner all \"\"\" CI_PIPELINE_IID = EnvProxy ( \"CI_PIPELINE_IID\" ) \"\"\" The project-level IID (internal ID) of the current pipeline. This ID is unique for the current project. Added in GitLab 11.0 Available in GitLab Runner all \"\"\" CI_PIPELINE_SOURCE = EnvProxy ( \"CI_PIPELINE_SOURCE\" ) \"\"\" Indicates how the pipeline was triggered. Possible options are push, web, schedule, api, external, chat, webide, merge_request_event, external_pull_request_event, parent_pipeline, trigger, or pipeline. For pipelines created before GitLab 9.5, this is displayed as unknown. Added in GitLab 10.0 Available in GitLab Runner all \"\"\" CI_PIPELINE_TRIGGERED = EnvProxy ( \"CI_PIPELINE_TRIGGERED\" ) \"\"\" The flag to indicate that job was triggered. Added in GitLab all Available in GitLab Runner all \"\"\" CI_PIPELINE_URL = EnvProxy ( \"CI_PIPELINE_URL\" ) \"\"\" Pipeline details URL. Added in GitLab 11.1 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_CONFIG_PATH = EnvProxy ( \"CI_PROJECT_CONFIG_PATH\" ) \"\"\" The CI configuration path for the project. Added in GitLab 13.8 Available in GitLab Runner all \"\"\" CI_PROJECT_DIR = EnvProxy ( \"CI_PROJECT_DIR\" ) \"\"\" The full path where the repository is cloned and where the job is run. If the GitLab Runner builds_dir parameter is set, this variable is set relative to the value of builds_dir. For more information, see Advanced configuration for GitLab Runner. Added in GitLab all Available in GitLab Runner all \"\"\" CI_PROJECT_ID = EnvProxy ( \"CI_PROJECT_ID\" ) \"\"\" The unique ID of the current project that GitLab CI/CD uses internally. Added in GitLab all Available in GitLab Runner all \"\"\" CI_PROJECT_NAME = EnvProxy ( \"CI_PROJECT_NAME\" ) \"\"\" The name of the directory for the project that is being built. For example, if the project URL is gitlab.example.com/group-name/project-1, the CI_PROJECT_NAME would be project-1. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_NAMESPACE = EnvProxy ( \"CI_PROJECT_NAMESPACE\" ) \"\"\" The project namespace (username or group name) that is being built. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_ROOT_NAMESPACE = EnvProxy ( \"CI_PROJECT_ROOT_NAMESPACE\" ) \"\"\" The root project namespace (username or group name) that is being built. For example, if CI_PROJECT_NAMESPACE is root-group/child-group/grandchild-group, CI_PROJECT_ROOT_NAMESPACE would be root-group. Added in GitLab 13.2 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_PATH = EnvProxy ( \"CI_PROJECT_PATH\" ) \"\"\" The namespace with project name. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_PATH_SLUG = EnvProxy ( \"CI_PROJECT_PATH_SLUG\" ) \"\"\" $CI_PROJECT_PATH in lowercase and with everything except 0-9 and a-z replaced with -. Use in URLs and domain names. Added in GitLab 9.3 Available in GitLab Runner all \"\"\" CI_PROJECT_REPOSITORY_LANGUAGES = EnvProxy ( \"CI_PROJECT_REPOSITORY_LANGUAGES\" ) \"\"\" Comma-separated, lowercase list of the languages used in the repository (for example ruby,javascript,html,css). Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_PROJECT_TITLE = EnvProxy ( \"CI_PROJECT_TITLE\" ) \"\"\" The human-readable project name as displayed in the GitLab web interface. Added in GitLab 12.4 Available in GitLab Runner all \"\"\" CI_PROJECT_URL = EnvProxy ( \"CI_PROJECT_URL\" ) \"\"\" The HTTP(S) address to access project. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_VISIBILITY = EnvProxy ( \"CI_PROJECT_VISIBILITY\" ) \"\"\" The project visibility (internal, private, public). Added in GitLab 10.3 Available in GitLab Runner all \"\"\" CI_REGISTRY = EnvProxy ( \"CI_REGISTRY\" ) \"\"\" GitLab Container Registry. This variable includes a :port value if one has been specified in the registry configuration. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_REGISTRY_IMAGE = EnvProxy ( \"CI_REGISTRY_IMAGE\" ) \"\"\" the address of the registry tied to the specific project. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_REGISTRY_PASSWORD = EnvProxy ( \"CI_REGISTRY_PASSWORD\" ) \"\"\" The password to use to push containers to the GitLab Container Registry, for the current project. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_REGISTRY_USER = EnvProxy ( \"CI_REGISTRY_USER\" ) \"\"\" The username to use to push containers to the GitLab Container Registry, for the current project. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_REPOSITORY_URL = EnvProxy ( \"CI_REPOSITORY_URL\" ) \"\"\" The URL to clone the Git repository. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_RUNNER_DESCRIPTION = EnvProxy ( \"CI_RUNNER_DESCRIPTION\" ) \"\"\" The description of the runner as saved in GitLab. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_RUNNER_EXECUTABLE_ARCH = EnvProxy ( \"CI_RUNNER_EXECUTABLE_ARCH\" ) \"\"\" The OS/architecture of the GitLab Runner executable (note that this is not necessarily the same as the environment of the executor). Added in GitLab all Available in GitLab Runner 10.6 \"\"\" CI_RUNNER_ID = EnvProxy ( \"CI_RUNNER_ID\" ) \"\"\" The unique ID of runner being used. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_RUNNER_REVISION = EnvProxy ( \"CI_RUNNER_REVISION\" ) \"\"\" GitLab Runner revision that is executing the current job. Added in GitLab all Available in GitLab Runner 10.6 \"\"\" CI_RUNNER_SHORT_TOKEN = EnvProxy ( \"CI_RUNNER_SHORT_TOKEN\" ) \"\"\" First eight characters of the runner\u2019s token used to authenticate new job requests. Used as the runner\u2019s unique ID. Added in GitLab all Available in GitLab Runner 12.3 \"\"\" CI_RUNNER_TAGS = EnvProxy ( \"CI_RUNNER_TAGS\" ) \"\"\" The defined runner tags. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_RUNNER_VERSION = EnvProxy ( \"CI_RUNNER_VERSION\" ) \"\"\" GitLab Runner version that is executing the current job. Added in GitLab all Available in GitLab Runner 10.6 \"\"\" CI_SERVER = EnvProxy ( \"CI_SERVER\" ) \"\"\" Mark that job is executed in CI environment. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_URL = EnvProxy ( \"CI_SERVER_URL\" ) \"\"\" The base URL of the GitLab instance, including protocol and port (like https://gitlab.example.com:8080). Added in GitLab 12.7 Available in GitLab Runner all \"\"\" CI_SERVER_HOST = EnvProxy ( \"CI_SERVER_HOST\" ) \"\"\" Host component of the GitLab instance URL, without protocol and port (like gitlab.example.com). Added in GitLab 12.1 Available in GitLab Runner all \"\"\" CI_SERVER_PORT = EnvProxy ( \"CI_SERVER_PORT\" ) \"\"\" Port component of the GitLab instance URL, without host and protocol (like 3000). Added in GitLab 12.8 Available in GitLab Runner all \"\"\" CI_SERVER_PROTOCOL = EnvProxy ( \"CI_SERVER_PROTOCOL\" ) \"\"\" Protocol component of the GitLab instance URL, without host and port (like https). Added in GitLab 12.8 Available in GitLab Runner all \"\"\" CI_SERVER_NAME = EnvProxy ( \"CI_SERVER_NAME\" ) \"\"\" The name of CI server that is used to coordinate jobs. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_REVISION = EnvProxy ( \"CI_SERVER_REVISION\" ) \"\"\" GitLab revision that is used to schedule jobs. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_VERSION = EnvProxy ( \"CI_SERVER_VERSION\" ) \"\"\" GitLab version that is used to schedule jobs. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_VERSION_MAJOR = EnvProxy ( \"CI_SERVER_VERSION_MAJOR\" ) \"\"\" GitLab version major component. Added in GitLab 11.4 Available in GitLab Runner all \"\"\" CI_SERVER_VERSION_MINOR = EnvProxy ( \"CI_SERVER_VERSION_MINOR\" ) \"\"\" GitLab version minor component. Added in GitLab 11.4 Available in GitLab Runner all \"\"\" CI_SERVER_VERSION_PATCH = EnvProxy ( \"CI_SERVER_VERSION_PATCH\" ) \"\"\" GitLab version patch component. Added in GitLab 11.4 Available in GitLab Runner all \"\"\" CI_SHARED_ENVIRONMENT = EnvProxy ( \"CI_SHARED_ENVIRONMENT\" ) \"\"\" Marks that the job is executed in a shared environment (something that is persisted across CI invocations like shell or ssh executor). If the environment is shared, it is set to true, otherwise it is not defined at all. Added in GitLab all Available in GitLab Runner 10.1 \"\"\" GITLAB_CI = EnvProxy ( \"GITLAB_CI\" ) \"\"\" Mark that job is executed in GitLab CI/CD environment. Added in GitLab all Available in GitLab Runner all \"\"\" GITLAB_FEATURES = EnvProxy ( \"GITLAB_FEATURES\" ) \"\"\" The comma separated list of licensed features available for your instance and plan. Added in GitLab 10.6 Available in GitLab Runner all \"\"\" GITLAB_USER_EMAIL = EnvProxy ( \"GITLAB_USER_EMAIL\" ) \"\"\" The email of the user who started the job. Added in GitLab 8.12 Available in GitLab Runner all \"\"\" GITLAB_USER_ID = EnvProxy ( \"GITLAB_USER_ID\" ) \"\"\" The ID of the user who started the job. Added in GitLab 8.12 Available in GitLab Runner all \"\"\" GITLAB_USER_LOGIN = EnvProxy ( \"GITLAB_USER_LOGIN\" ) \"\"\" The login username of the user who started the job. Added in GitLab 10.0 Available in GitLab Runner all \"\"\" GITLAB_USER_NAME = EnvProxy ( \"GITLAB_USER_NAME\" ) \"\"\" The real name of the user who started the job. Added in GitLab 10.0 Available in GitLab Runner all \"\"\" TRIGGER_PAYLOAD = EnvProxy ( \"TRIGGER_PAYLOAD\" ) \"\"\" This variable is available when a pipeline is triggered with a webhook Added in GitLab 13.9 Available in GitLab Runner all \"\"\"","title":"Module gcip.core.variables"},{"location":"reference/gcip/core/variables/#classes","text":"","title":"Classes"},{"location":"reference/gcip/core/variables/#envproxy","text":"class EnvProxy ( key : str ) View Source class EnvProxy (): def __init__ ( self , key: str ) -> None: self . key = key def __get__ ( self , obj: Any , objtype: Any = None ) -> str: return os . getenv ( self . key )","title":"EnvProxy"},{"location":"reference/gcip/core/variables/#predefinedvariables","text":"class PredefinedVariables ( / , * args , ** kwargs ) View Source class PredefinedVariables (): \"\"\" Gitlab CI predefined variables. https://docs.gitlab.com/ee/ci/variables/predefined_variables.html \"\"\" CHAT_CHANNEL = EnvProxy ( \"CHAT_CHANNEL\" ) \"\"\" Source chat channel which triggered the ChatOps command. Added in GitLab 10.6 Available in GitLab Runner all \"\"\" CHAT_INPUT = EnvProxy ( \"CHAT_INPUT\" ) \"\"\" Additional arguments passed in the ChatOps command. Added in GitLab 10.6 Available in GitLab Runner all \"\"\" CI = EnvProxy ( \"CI\" ) \"\"\" Mark that job is executed in CI environment. Added in GitLab all Available in GitLab Runner 0.4 \"\"\" CI_API_V4_URL = EnvProxy ( \"CI_API_V4_URL\" ) \"\"\" The GitLab API v4 root URL. Added in GitLab 11.7 Available in GitLab Runner all \"\"\" CI_BUILDS_DIR = EnvProxy ( \"CI_BUILDS_DIR\" ) \"\"\" Top-level directory where builds are executed. Added in GitLab all Available in GitLab Runner 11.10 \"\"\" CI_COMMIT_BEFORE_SHA = EnvProxy ( \"CI_COMMIT_BEFORE_SHA\" ) \"\"\" The previous latest commit present on a branch. Is always 0000000000000000000000000000000000000000 in pipelines for merge requests. Added in GitLab 11.2 Available in GitLab Runner all \"\"\" CI_COMMIT_DESCRIPTION = EnvProxy ( \"CI_COMMIT_DESCRIPTION\" ) \"\"\" The description of the commit the message without first line, if the title is shorter than 100 characters; full message in other case. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_COMMIT_MESSAGE = EnvProxy ( \"CI_COMMIT_MESSAGE\" ) \"\"\" The full commit message. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_COMMIT_REF_NAME = EnvProxy ( \"CI_COMMIT_REF_NAME\" ) \"\"\" The branch or tag name for which project is built. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_COMMIT_REF_PROTECTED = EnvProxy ( \"CI_COMMIT_REF_PROTECTED\" ) \"\"\" true if the job is running on a protected reference, false if not. Added in GitLab 11.11 Available in GitLab Runner all \"\"\" CI_COMMIT_REF_SLUG = EnvProxy ( \"CI_COMMIT_REF_SLUG\" ) \"\"\" $CI_COMMIT_REF_NAME in lowercase, shortened to 63 bytes, and with everything except 0-9 and a-z replaced with -. No leading / trailing -. Use in URLs, host names and domain names. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_COMMIT_SHA = EnvProxy ( \"CI_COMMIT_SHA\" ) \"\"\" The commit revision for which project is built. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_COMMIT_SHORT_SHA = EnvProxy ( \"CI_COMMIT_SHORT_SHA\" ) \"\"\" The first eight characters of CI_COMMIT_SHA. Added in GitLab 11.7 Available in GitLab Runner all \"\"\" CI_COMMIT_BRANCH = EnvProxy ( \"CI_COMMIT_BRANCH\" ) \"\"\" The commit branch name. Present in branch pipelines, including pipelines for the default branch. Not present in merge request pipelines or tag pipelines. Added in GitLab 12.6 Available in GitLab Runner 0.5 \"\"\" CI_COMMIT_TAG = EnvProxy ( \"CI_COMMIT_TAG\" ) \"\"\" The commit tag name. Present only when building tags. Added in GitLab 9.0 Available in GitLab Runner 0.5 \"\"\" CI_COMMIT_TITLE = EnvProxy ( \"CI_COMMIT_TITLE\" ) \"\"\" The title of the commit - the full first line of the message. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_COMMIT_TIMESTAMP = EnvProxy ( \"CI_COMMIT_TIMESTAMP\" ) \"\"\" The timestamp of the commit in the ISO 8601 format. Added in GitLab 13.4 Available in GitLab Runner all \"\"\" CI_CONCURRENT_ID = EnvProxy ( \"CI_CONCURRENT_ID\" ) \"\"\" Unique ID of build execution in a single executor. Added in GitLab all Available in GitLab Runner 11.10 \"\"\" CI_CONCURRENT_PROJECT_ID = EnvProxy ( \"CI_CONCURRENT_PROJECT_ID\" ) \"\"\" Unique ID of build execution in a single executor and project. Added in GitLab all Available in GitLab Runner 11.10 \"\"\" CI_CONFIG_PATH = EnvProxy ( \"CI_CONFIG_PATH\" ) \"\"\" The path to CI configuration file. Defaults to .gitlab-ci.yml. Added in GitLab 9.4 Available in GitLab Runner 0.5 \"\"\" CI_DEBUG_TRACE = EnvProxy ( \"CI_DEBUG_TRACE\" ) \"\"\" Whether debug logging (tracing) is enabled. Added in GitLab all Available in GitLab Runner 1.7 \"\"\" CI_DEFAULT_BRANCH = EnvProxy ( \"CI_DEFAULT_BRANCH\" ) \"\"\" The name of the default branch for the project. Added in GitLab 12.4 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX = EnvProxy ( \"CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX\" ) \"\"\" The image prefix for pulling images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_SERVER = EnvProxy ( \"CI_DEPENDENCY_PROXY_SERVER\" ) \"\"\" The server for logging in to the Dependency Proxy. This is equivalent to $CI_SERVER_HOST:$CI_SERVER_PORT. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_PASSWORD = EnvProxy ( \"CI_DEPENDENCY_PROXY_PASSWORD\" ) \"\"\" The password to use to pull images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPENDENCY_PROXY_USER = EnvProxy ( \"CI_DEPENDENCY_PROXY_USER\" ) \"\"\" The username to use to pull images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_DEPLOY_FREEZE = EnvProxy ( \"CI_DEPLOY_FREEZE\" ) \"\"\" Included with the value true if the pipeline runs during a deploy freeze window. Added in GitLab 13.2 Available in GitLab Runner all \"\"\" CI_DEPLOY_PASSWORD = EnvProxy ( \"CI_DEPLOY_PASSWORD\" ) \"\"\" Authentication password of the GitLab Deploy Token, only present if the Project has one related. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_DEPLOY_USER = EnvProxy ( \"CI_DEPLOY_USER\" ) \"\"\" Authentication username of the GitLab Deploy Token, only present if the Project has one related. Added in GitLab 10.8 Available in GitLab Runner all \"\"\" CI_DISPOSABLE_ENVIRONMENT = EnvProxy ( \"CI_DISPOSABLE_ENVIRONMENT\" ) \"\"\" Marks that the job is executed in a disposable environment (something that is created only for this job and disposed of/destroyed after the execution - all executors except shell and ssh). If the environment is disposable, it is set to true, otherwise it is not defined at all. Added in GitLab all Available in GitLab Runner 10.1 \"\"\" CI_ENVIRONMENT_NAME = EnvProxy ( \"CI_ENVIRONMENT_NAME\" ) \"\"\" The name of the environment for this job. Only present if environment:name is set. Added in GitLab 8.15 Available in GitLab Runner all \"\"\" CI_ENVIRONMENT_SLUG = EnvProxy ( \"CI_ENVIRONMENT_SLUG\" ) \"\"\" A simplified version of the environment name, suitable for inclusion in DNS, URLs, Kubernetes labels, and so on. Only present if environment:name is set. Added in GitLab 8.15 Available in GitLab Runner all \"\"\" CI_ENVIRONMENT_URL = EnvProxy ( \"CI_ENVIRONMENT_URL\" ) \"\"\" The URL of the environment for this job. Only present if environment:url is set. Added in GitLab 9.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_IID = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_IID\" ) \"\"\" Pull Request ID from GitHub if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_SOURCE_REPOSITORY = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_SOURCE_REPOSITORY\" ) \"\"\" The source repository name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 13.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_TARGET_REPOSITORY = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_TARGET_REPOSITORY\" ) \"\"\" The target repository name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 13.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_NAME = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_NAME\" ) \"\"\" The source branch name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_SHA = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the source branch of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_NAME = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_NAME\" ) \"\"\" The target branch name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_SHA = EnvProxy ( \"CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the target branch of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_HAS_OPEN_REQUIREMENTS = EnvProxy ( \"CI_HAS_OPEN_REQUIREMENTS\" ) \"\"\" Included with the value true only if the pipeline\u2019s project has any open requirements. Not included if there are no open requirements for the pipeline\u2019s project. Added in GitLab 13.1 Available in GitLab Runner all \"\"\" CI_OPEN_MERGE_REQUESTS = EnvProxy ( \"CI_OPEN_MERGE_REQUESTS\" ) \"\"\" Available in branch and merge request pipelines. Contains a comma-separated list of up to four merge requests that use the current branch and project as the merge request source. For example gitlab-org/gitlab!333,gitlab-org/gitlab-foss!11. Added in GitLab 13.8 Available in GitLab Runner all \"\"\" CI_JOB_ID = EnvProxy ( \"CI_JOB_ID\" ) \"\"\" The unique ID of the current job that GitLab CI/CD uses internally. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_JOB_IMAGE = EnvProxy ( \"CI_JOB_IMAGE\" ) \"\"\" The name of the image running the CI job. Added in GitLab 12.9 Available in GitLab Runner 12.9 \"\"\" CI_JOB_MANUAL = EnvProxy ( \"CI_JOB_MANUAL\" ) \"\"\" The flag to indicate that job was manually started. Added in GitLab 8.12 Available in GitLab Runner all \"\"\" CI_JOB_NAME = EnvProxy ( \"CI_JOB_NAME\" ) \"\"\" The name of the job as defined in .gitlab-ci.yml. Added in GitLab 9.0 Available in GitLab Runner 0.5 \"\"\" CI_JOB_STAGE = EnvProxy ( \"CI_JOB_STAGE\" ) \"\"\" The name of the stage as defined in .gitlab-ci.yml. Added in GitLab 9.0 Available in GitLab Runner 0.5 \"\"\" CI_JOB_STATUS = EnvProxy ( \"CI_JOB_STATUS\" ) \"\"\" The state of the job as each runner stage is executed. Use with after_script where CI_JOB_STATUS can be either success, failed or canceled. Added in GitLab all Available in GitLab Runner 13.5 \"\"\" CI_JOB_TOKEN = EnvProxy ( \"CI_JOB_TOKEN\" ) \"\"\" Token used for authenticating with a few API endpoints and downloading dependent repositories. The token is valid as long as the job is running. Added in GitLab 9.0 Available in GitLab Runner 1.2 \"\"\" CI_JOB_JWT = EnvProxy ( \"CI_JOB_JWT\" ) \"\"\" RS256 JSON web token that can be used for authenticating with third party systems that support JWT authentication, for example HashiCorp\u2019s Vault. Added in GitLab 12.10 Available in GitLab Runner all \"\"\" CI_JOB_URL = EnvProxy ( \"CI_JOB_URL\" ) \"\"\" Job details URL. Added in GitLab 11.1 Available in GitLab Runner 0.5 \"\"\" CI_KUBERNETES_ACTIVE = EnvProxy ( \"CI_KUBERNETES_ACTIVE\" ) \"\"\" Included with the value true only if the pipeline has a Kubernetes cluster available for deployments. Not included if no cluster is available. Can be used as an alternative to only:kubernetes/except:kubernetes with rules:if. Added in GitLab 13.0 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_ASSIGNEES = EnvProxy ( \"CI_MERGE_REQUEST_ASSIGNEES\" ) \"\"\" Comma-separated list of username(s) of assignee(s) for the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_ID = EnvProxy ( \"CI_MERGE_REQUEST_ID\" ) \"\"\" The instance-level ID of the merge request. Only available if the pipelines are for merge requests and the merge request is created. This is a unique ID across all projects on GitLab. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_IID = EnvProxy ( \"CI_MERGE_REQUEST_IID\" ) \"\"\" The project-level IID (internal ID) of the merge request. Only available If the pipelines are for merge requests and the merge request is created. This ID is unique for the current project. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_LABELS = EnvProxy ( \"CI_MERGE_REQUEST_LABELS\" ) \"\"\" Comma-separated label names of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_MILESTONE = EnvProxy ( \"CI_MERGE_REQUEST_MILESTONE\" ) \"\"\" The milestone title of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_PROJECT_ID = EnvProxy ( \"CI_MERGE_REQUEST_PROJECT_ID\" ) \"\"\" The ID of the project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_PROJECT_PATH = EnvProxy ( \"CI_MERGE_REQUEST_PROJECT_PATH\" ) \"\"\" The path of the project of the merge request if the pipelines are for merge requests (for example namespace/awesome-project). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_PROJECT_URL = EnvProxy ( \"CI_MERGE_REQUEST_PROJECT_URL\" ) \"\"\" The URL of the project of the merge request if the pipelines are for merge requests (for example http://192.168.10.15:3000/namespace/awesome-project). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_REF_PATH = EnvProxy ( \"CI_MERGE_REQUEST_REF_PATH\" ) \"\"\" The ref path of the merge request if the pipelines are for merge requests. (for example refs/merge-requests/1/head). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_BRANCH_NAME = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_BRANCH_NAME\" ) \"\"\" The source branch name of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_BRANCH_SHA = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the source branch of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used, the merge request is created, and the pipeline is a merged result pipeline. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_PROJECT_ID = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_PROJECT_ID\" ) \"\"\" The ID of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_PROJECT_PATH = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_PROJECT_PATH\" ) \"\"\" The path of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_SOURCE_PROJECT_URL = EnvProxy ( \"CI_MERGE_REQUEST_SOURCE_PROJECT_URL\" ) \"\"\" The URL of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_TARGET_BRANCH_NAME = EnvProxy ( \"CI_MERGE_REQUEST_TARGET_BRANCH_NAME\" ) \"\"\" The target branch name of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_TARGET_BRANCH_SHA = EnvProxy ( \"CI_MERGE_REQUEST_TARGET_BRANCH_SHA\" ) \"\"\" The HEAD SHA of the target branch of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used, the merge request is created, and the pipeline is a merged result pipeline. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_TITLE = EnvProxy ( \"CI_MERGE_REQUEST_TITLE\" ) \"\"\" The title of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_EVENT_TYPE = EnvProxy ( \"CI_MERGE_REQUEST_EVENT_TYPE\" ) \"\"\" The event type of the merge request, if the pipelines are for merge requests. Can be detached, merged_result or merge_train. Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_DIFF_ID = EnvProxy ( \"CI_MERGE_REQUEST_DIFF_ID\" ) \"\"\" The version of the merge request diff, if the pipelines are for merge requests. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_MERGE_REQUEST_DIFF_BASE_SHA = EnvProxy ( \"CI_MERGE_REQUEST_DIFF_BASE_SHA\" ) \"\"\" The base SHA of the merge request diff, if the pipelines are for merge requests. Added in GitLab 13.7 Available in GitLab Runner all \"\"\" CI_NODE_INDEX = EnvProxy ( \"CI_NODE_INDEX\" ) \"\"\" Index of the job in the job set. If the job is not parallelized, this variable is not set. Added in GitLab 11.5 Available in GitLab Runner all \"\"\" CI_NODE_TOTAL = EnvProxy ( \"CI_NODE_TOTAL\" ) \"\"\" Total number of instances of this job running in parallel. If the job is not parallelized, this variable is set to 1. Added in GitLab 11.5 Available in GitLab Runner all \"\"\" CI_PAGES_DOMAIN = EnvProxy ( \"CI_PAGES_DOMAIN\" ) \"\"\" The configured domain that hosts GitLab Pages. Added in GitLab 11.8 Available in GitLab Runner all \"\"\" CI_PAGES_URL = EnvProxy ( \"CI_PAGES_URL\" ) \"\"\" URL to GitLab Pages-built pages. Always belongs to a subdomain of CI_PAGES_DOMAIN. Added in GitLab 11.8 Available in GitLab Runner all \"\"\" CI_PIPELINE_ID = EnvProxy ( \"CI_PIPELINE_ID\" ) \"\"\" The instance-level ID of the current pipeline. This is a unique ID across all projects on GitLab. Added in GitLab 8.10 Available in GitLab Runner all \"\"\" CI_PIPELINE_IID = EnvProxy ( \"CI_PIPELINE_IID\" ) \"\"\" The project-level IID (internal ID) of the current pipeline. This ID is unique for the current project. Added in GitLab 11.0 Available in GitLab Runner all \"\"\" CI_PIPELINE_SOURCE = EnvProxy ( \"CI_PIPELINE_SOURCE\" ) \"\"\" Indicates how the pipeline was triggered. Possible options are push, web, schedule, api, external, chat, webide, merge_request_event, external_pull_request_event, parent_pipeline, trigger, or pipeline. For pipelines created before GitLab 9.5, this is displayed as unknown. Added in GitLab 10.0 Available in GitLab Runner all \"\"\" CI_PIPELINE_TRIGGERED = EnvProxy ( \"CI_PIPELINE_TRIGGERED\" ) \"\"\" The flag to indicate that job was triggered. Added in GitLab all Available in GitLab Runner all \"\"\" CI_PIPELINE_URL = EnvProxy ( \"CI_PIPELINE_URL\" ) \"\"\" Pipeline details URL. Added in GitLab 11.1 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_CONFIG_PATH = EnvProxy ( \"CI_PROJECT_CONFIG_PATH\" ) \"\"\" The CI configuration path for the project. Added in GitLab 13.8 Available in GitLab Runner all \"\"\" CI_PROJECT_DIR = EnvProxy ( \"CI_PROJECT_DIR\" ) \"\"\" The full path where the repository is cloned and where the job is run. If the GitLab Runner builds_dir parameter is set, this variable is set relative to the value of builds_dir. For more information, see Advanced configuration for GitLab Runner. Added in GitLab all Available in GitLab Runner all \"\"\" CI_PROJECT_ID = EnvProxy ( \"CI_PROJECT_ID\" ) \"\"\" The unique ID of the current project that GitLab CI/CD uses internally. Added in GitLab all Available in GitLab Runner all \"\"\" CI_PROJECT_NAME = EnvProxy ( \"CI_PROJECT_NAME\" ) \"\"\" The name of the directory for the project that is being built. For example, if the project URL is gitlab.example.com/group-name/project-1, the CI_PROJECT_NAME would be project-1. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_NAMESPACE = EnvProxy ( \"CI_PROJECT_NAMESPACE\" ) \"\"\" The project namespace (username or group name) that is being built. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_ROOT_NAMESPACE = EnvProxy ( \"CI_PROJECT_ROOT_NAMESPACE\" ) \"\"\" The root project namespace (username or group name) that is being built. For example, if CI_PROJECT_NAMESPACE is root-group/child-group/grandchild-group, CI_PROJECT_ROOT_NAMESPACE would be root-group. Added in GitLab 13.2 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_PATH = EnvProxy ( \"CI_PROJECT_PATH\" ) \"\"\" The namespace with project name. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_PATH_SLUG = EnvProxy ( \"CI_PROJECT_PATH_SLUG\" ) \"\"\" $CI_PROJECT_PATH in lowercase and with everything except 0-9 and a-z replaced with -. Use in URLs and domain names. Added in GitLab 9.3 Available in GitLab Runner all \"\"\" CI_PROJECT_REPOSITORY_LANGUAGES = EnvProxy ( \"CI_PROJECT_REPOSITORY_LANGUAGES\" ) \"\"\" Comma-separated, lowercase list of the languages used in the repository (for example ruby,javascript,html,css). Added in GitLab 12.3 Available in GitLab Runner all \"\"\" CI_PROJECT_TITLE = EnvProxy ( \"CI_PROJECT_TITLE\" ) \"\"\" The human-readable project name as displayed in the GitLab web interface. Added in GitLab 12.4 Available in GitLab Runner all \"\"\" CI_PROJECT_URL = EnvProxy ( \"CI_PROJECT_URL\" ) \"\"\" The HTTP(S) address to access project. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_PROJECT_VISIBILITY = EnvProxy ( \"CI_PROJECT_VISIBILITY\" ) \"\"\" The project visibility (internal, private, public). Added in GitLab 10.3 Available in GitLab Runner all \"\"\" CI_REGISTRY = EnvProxy ( \"CI_REGISTRY\" ) \"\"\" GitLab Container Registry. This variable includes a :port value if one has been specified in the registry configuration. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_REGISTRY_IMAGE = EnvProxy ( \"CI_REGISTRY_IMAGE\" ) \"\"\" the address of the registry tied to the specific project. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_REGISTRY_PASSWORD = EnvProxy ( \"CI_REGISTRY_PASSWORD\" ) \"\"\" The password to use to push containers to the GitLab Container Registry, for the current project. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_REGISTRY_USER = EnvProxy ( \"CI_REGISTRY_USER\" ) \"\"\" The username to use to push containers to the GitLab Container Registry, for the current project. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_REPOSITORY_URL = EnvProxy ( \"CI_REPOSITORY_URL\" ) \"\"\" The URL to clone the Git repository. Added in GitLab 9.0 Available in GitLab Runner all \"\"\" CI_RUNNER_DESCRIPTION = EnvProxy ( \"CI_RUNNER_DESCRIPTION\" ) \"\"\" The description of the runner as saved in GitLab. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_RUNNER_EXECUTABLE_ARCH = EnvProxy ( \"CI_RUNNER_EXECUTABLE_ARCH\" ) \"\"\" The OS/architecture of the GitLab Runner executable (note that this is not necessarily the same as the environment of the executor). Added in GitLab all Available in GitLab Runner 10.6 \"\"\" CI_RUNNER_ID = EnvProxy ( \"CI_RUNNER_ID\" ) \"\"\" The unique ID of runner being used. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_RUNNER_REVISION = EnvProxy ( \"CI_RUNNER_REVISION\" ) \"\"\" GitLab Runner revision that is executing the current job. Added in GitLab all Available in GitLab Runner 10.6 \"\"\" CI_RUNNER_SHORT_TOKEN = EnvProxy ( \"CI_RUNNER_SHORT_TOKEN\" ) \"\"\" First eight characters of the runner\u2019s token used to authenticate new job requests. Used as the runner\u2019s unique ID. Added in GitLab all Available in GitLab Runner 12.3 \"\"\" CI_RUNNER_TAGS = EnvProxy ( \"CI_RUNNER_TAGS\" ) \"\"\" The defined runner tags. Added in GitLab 8.10 Available in GitLab Runner 0.5 \"\"\" CI_RUNNER_VERSION = EnvProxy ( \"CI_RUNNER_VERSION\" ) \"\"\" GitLab Runner version that is executing the current job. Added in GitLab all Available in GitLab Runner 10.6 \"\"\" CI_SERVER = EnvProxy ( \"CI_SERVER\" ) \"\"\" Mark that job is executed in CI environment. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_URL = EnvProxy ( \"CI_SERVER_URL\" ) \"\"\" The base URL of the GitLab instance, including protocol and port (like https://gitlab.example.com:8080). Added in GitLab 12.7 Available in GitLab Runner all \"\"\" CI_SERVER_HOST = EnvProxy ( \"CI_SERVER_HOST\" ) \"\"\" Host component of the GitLab instance URL, without protocol and port (like gitlab.example.com). Added in GitLab 12.1 Available in GitLab Runner all \"\"\" CI_SERVER_PORT = EnvProxy ( \"CI_SERVER_PORT\" ) \"\"\" Port component of the GitLab instance URL, without host and protocol (like 3000). Added in GitLab 12.8 Available in GitLab Runner all \"\"\" CI_SERVER_PROTOCOL = EnvProxy ( \"CI_SERVER_PROTOCOL\" ) \"\"\" Protocol component of the GitLab instance URL, without host and port (like https). Added in GitLab 12.8 Available in GitLab Runner all \"\"\" CI_SERVER_NAME = EnvProxy ( \"CI_SERVER_NAME\" ) \"\"\" The name of CI server that is used to coordinate jobs. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_REVISION = EnvProxy ( \"CI_SERVER_REVISION\" ) \"\"\" GitLab revision that is used to schedule jobs. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_VERSION = EnvProxy ( \"CI_SERVER_VERSION\" ) \"\"\" GitLab version that is used to schedule jobs. Added in GitLab all Available in GitLab Runner all \"\"\" CI_SERVER_VERSION_MAJOR = EnvProxy ( \"CI_SERVER_VERSION_MAJOR\" ) \"\"\" GitLab version major component. Added in GitLab 11.4 Available in GitLab Runner all \"\"\" CI_SERVER_VERSION_MINOR = EnvProxy ( \"CI_SERVER_VERSION_MINOR\" ) \"\"\" GitLab version minor component. Added in GitLab 11.4 Available in GitLab Runner all \"\"\" CI_SERVER_VERSION_PATCH = EnvProxy ( \"CI_SERVER_VERSION_PATCH\" ) \"\"\" GitLab version patch component. Added in GitLab 11.4 Available in GitLab Runner all \"\"\" CI_SHARED_ENVIRONMENT = EnvProxy ( \"CI_SHARED_ENVIRONMENT\" ) \"\"\" Marks that the job is executed in a shared environment (something that is persisted across CI invocations like shell or ssh executor). If the environment is shared, it is set to true, otherwise it is not defined at all. Added in GitLab all Available in GitLab Runner 10.1 \"\"\" GITLAB_CI = EnvProxy ( \"GITLAB_CI\" ) \"\"\" Mark that job is executed in GitLab CI/CD environment. Added in GitLab all Available in GitLab Runner all \"\"\" GITLAB_FEATURES = EnvProxy ( \"GITLAB_FEATURES\" ) \"\"\" The comma separated list of licensed features available for your instance and plan. Added in GitLab 10.6 Available in GitLab Runner all \"\"\" GITLAB_USER_EMAIL = EnvProxy ( \"GITLAB_USER_EMAIL\" ) \"\"\" The email of the user who started the job. Added in GitLab 8.12 Available in GitLab Runner all \"\"\" GITLAB_USER_ID = EnvProxy ( \"GITLAB_USER_ID\" ) \"\"\" The ID of the user who started the job. Added in GitLab 8.12 Available in GitLab Runner all \"\"\" GITLAB_USER_LOGIN = EnvProxy ( \"GITLAB_USER_LOGIN\" ) \"\"\" The login username of the user who started the job. Added in GitLab 10.0 Available in GitLab Runner all \"\"\" GITLAB_USER_NAME = EnvProxy ( \"GITLAB_USER_NAME\" ) \"\"\" The real name of the user who started the job. Added in GitLab 10.0 Available in GitLab Runner all \"\"\" TRIGGER_PAYLOAD = EnvProxy ( \"TRIGGER_PAYLOAD\" ) \"\"\" This variable is available when a pipeline is triggered with a webhook Added in GitLab 13.9 Available in GitLab Runner all \"\"\"","title":"PredefinedVariables"},{"location":"reference/gcip/core/variables/#class-variables","text":"CHAT_CHANNEL Source chat channel which triggered the ChatOps command. Added in GitLab 10.6 Available in GitLab Runner all CHAT_INPUT Additional arguments passed in the ChatOps command. Added in GitLab 10.6 Available in GitLab Runner all CI Mark that job is executed in CI environment. Added in GitLab all Available in GitLab Runner 0.4 CI_API_V4_URL The GitLab API v4 root URL. Added in GitLab 11.7 Available in GitLab Runner all CI_BUILDS_DIR Top-level directory where builds are executed. Added in GitLab all Available in GitLab Runner 11.10 CI_COMMIT_BEFORE_SHA The previous latest commit present on a branch. Is always 0000000000000000000000000000000000000000 in pipelines for merge requests. Added in GitLab 11.2 Available in GitLab Runner all CI_COMMIT_BRANCH The commit branch name. Present in branch pipelines, including pipelines for the default branch. Not present in merge request pipelines or tag pipelines. Added in GitLab 12.6 Available in GitLab Runner 0.5 CI_COMMIT_DESCRIPTION The description of the commit the message without first line, if the title is shorter than 100 characters; full message in other case. Added in GitLab 10.8 Available in GitLab Runner all CI_COMMIT_MESSAGE The full commit message. Added in GitLab 10.8 Available in GitLab Runner all CI_COMMIT_REF_NAME The branch or tag name for which project is built. Added in GitLab 9.0 Available in GitLab Runner all CI_COMMIT_REF_PROTECTED true if the job is running on a protected reference, false if not. Added in GitLab 11.11 Available in GitLab Runner all CI_COMMIT_REF_SLUG $CI_COMMIT_REF_NAME in lowercase, shortened to 63 bytes, and with everything except 0-9 and a-z replaced with -. No leading / trailing -. Use in URLs, host names and domain names. Added in GitLab 9.0 Available in GitLab Runner all CI_COMMIT_SHA The commit revision for which project is built. Added in GitLab 9.0 Available in GitLab Runner all CI_COMMIT_SHORT_SHA The first eight characters of CI_COMMIT_SHA. Added in GitLab 11.7 Available in GitLab Runner all CI_COMMIT_TAG The commit tag name. Present only when building tags. Added in GitLab 9.0 Available in GitLab Runner 0.5 CI_COMMIT_TIMESTAMP The timestamp of the commit in the ISO 8601 format. Added in GitLab 13.4 Available in GitLab Runner all CI_COMMIT_TITLE The title of the commit - the full first line of the message. Added in GitLab 10.8 Available in GitLab Runner all CI_CONCURRENT_ID Unique ID of build execution in a single executor. Added in GitLab all Available in GitLab Runner 11.10 CI_CONCURRENT_PROJECT_ID Unique ID of build execution in a single executor and project. Added in GitLab all Available in GitLab Runner 11.10 CI_CONFIG_PATH The path to CI configuration file. Defaults to .gitlab-ci.yml. Added in GitLab 9.4 Available in GitLab Runner 0.5 CI_DEBUG_TRACE Whether debug logging (tracing) is enabled. Added in GitLab all Available in GitLab Runner 1.7 CI_DEFAULT_BRANCH The name of the default branch for the project. Added in GitLab 12.4 Available in GitLab Runner all CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX The image prefix for pulling images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all CI_DEPENDENCY_PROXY_PASSWORD The password to use to pull images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all CI_DEPENDENCY_PROXY_SERVER The server for logging in to the Dependency Proxy. This is equivalent to $CI_SERVER_HOST:$CI_SERVER_PORT. Added in GitLab 13.7 Available in GitLab Runner all CI_DEPENDENCY_PROXY_USER The username to use to pull images through the Dependency Proxy. Added in GitLab 13.7 Available in GitLab Runner all CI_DEPLOY_FREEZE Included with the value true if the pipeline runs during a deploy freeze window. Added in GitLab 13.2 Available in GitLab Runner all CI_DEPLOY_PASSWORD Authentication password of the GitLab Deploy Token, only present if the Project has one related. Added in GitLab 10.8 Available in GitLab Runner all CI_DEPLOY_USER Authentication username of the GitLab Deploy Token, only present if the Project has one related. Added in GitLab 10.8 Available in GitLab Runner all CI_DISPOSABLE_ENVIRONMENT Marks that the job is executed in a disposable environment (something that is created only for this job and disposed of/destroyed after the execution - all executors except shell and ssh). If the environment is disposable, it is set to true, otherwise it is not defined at all. Added in GitLab all Available in GitLab Runner 10.1 CI_ENVIRONMENT_NAME The name of the environment for this job. Only present if environment:name is set. Added in GitLab 8.15 Available in GitLab Runner all CI_ENVIRONMENT_SLUG A simplified version of the environment name, suitable for inclusion in DNS, URLs, Kubernetes labels, and so on. Only present if environment:name is set. Added in GitLab 8.15 Available in GitLab Runner all CI_ENVIRONMENT_URL The URL of the environment for this job. Only present if environment:url is set. Added in GitLab 9.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_IID Pull Request ID from GitHub if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_NAME The source branch name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_SHA The HEAD SHA of the source branch of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_SOURCE_REPOSITORY The source repository name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 13.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_NAME The target branch name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_SHA The HEAD SHA of the target branch of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 12.3 Available in GitLab Runner all CI_EXTERNAL_PULL_REQUEST_TARGET_REPOSITORY The target repository name of the pull request if the pipelines are for external pull requests. Available only if only [external_pull_requests] or rules syntax is used and the pull request is open. Added in GitLab 13.3 Available in GitLab Runner all CI_HAS_OPEN_REQUIREMENTS Included with the value true only if the pipeline\u2019s project has any open requirements. Not included if there are no open requirements for the pipeline\u2019s project. Added in GitLab 13.1 Available in GitLab Runner all CI_JOB_ID The unique ID of the current job that GitLab CI/CD uses internally. Added in GitLab 9.0 Available in GitLab Runner all CI_JOB_IMAGE The name of the image running the CI job. Added in GitLab 12.9 Available in GitLab Runner 12.9 CI_JOB_JWT RS256 JSON web token that can be used for authenticating with third party systems that support JWT authentication, for example HashiCorp\u2019s Vault. Added in GitLab 12.10 Available in GitLab Runner all CI_JOB_MANUAL The flag to indicate that job was manually started. Added in GitLab 8.12 Available in GitLab Runner all CI_JOB_NAME The name of the job as defined in .gitlab-ci.yml. Added in GitLab 9.0 Available in GitLab Runner 0.5 CI_JOB_STAGE The name of the stage as defined in .gitlab-ci.yml. Added in GitLab 9.0 Available in GitLab Runner 0.5 CI_JOB_STATUS The state of the job as each runner stage is executed. Use with after_script where CI_JOB_STATUS can be either success, failed or canceled. Added in GitLab all Available in GitLab Runner 13.5 CI_JOB_TOKEN Token used for authenticating with a few API endpoints and downloading dependent repositories. The token is valid as long as the job is running. Added in GitLab 9.0 Available in GitLab Runner 1.2 CI_JOB_URL Job details URL. Added in GitLab 11.1 Available in GitLab Runner 0.5 CI_KUBERNETES_ACTIVE Included with the value true only if the pipeline has a Kubernetes cluster available for deployments. Not included if no cluster is available. Can be used as an alternative to only:kubernetes/except:kubernetes with rules:if. Added in GitLab 13.0 Available in GitLab Runner all CI_MERGE_REQUEST_ASSIGNEES Comma-separated list of username(s) of assignee(s) for the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all CI_MERGE_REQUEST_DIFF_BASE_SHA The base SHA of the merge request diff, if the pipelines are for merge requests. Added in GitLab 13.7 Available in GitLab Runner all CI_MERGE_REQUEST_DIFF_ID The version of the merge request diff, if the pipelines are for merge requests. Added in GitLab 13.7 Available in GitLab Runner all CI_MERGE_REQUEST_EVENT_TYPE The event type of the merge request, if the pipelines are for merge requests. Can be detached, merged_result or merge_train. Added in GitLab 12.3 Available in GitLab Runner all CI_MERGE_REQUEST_ID The instance-level ID of the merge request. Only available if the pipelines are for merge requests and the merge request is created. This is a unique ID across all projects on GitLab. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_IID The project-level IID (internal ID) of the merge request. Only available If the pipelines are for merge requests and the merge request is created. This ID is unique for the current project. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_LABELS Comma-separated label names of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all CI_MERGE_REQUEST_MILESTONE The milestone title of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all CI_MERGE_REQUEST_PROJECT_ID The ID of the project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_PROJECT_PATH The path of the project of the merge request if the pipelines are for merge requests (for example namespace/awesome-project). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_PROJECT_URL The URL of the project of the merge request if the pipelines are for merge requests (for example http://192.168.10.15:3000/namespace/awesome-project). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_REF_PATH The ref path of the merge request if the pipelines are for merge requests. (for example refs/merge-requests/1/head). Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_SOURCE_BRANCH_NAME The source branch name of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_SOURCE_BRANCH_SHA The HEAD SHA of the source branch of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used, the merge request is created, and the pipeline is a merged result pipeline. Added in GitLab 11.9 Available in GitLab Runner all CI_MERGE_REQUEST_SOURCE_PROJECT_ID The ID of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_SOURCE_PROJECT_PATH The path of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_SOURCE_PROJECT_URL The URL of the source project of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_TARGET_BRANCH_NAME The target branch name of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.6 Available in GitLab Runner all CI_MERGE_REQUEST_TARGET_BRANCH_SHA The HEAD SHA of the target branch of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used, the merge request is created, and the pipeline is a merged result pipeline. Added in GitLab 11.9 Available in GitLab Runner all CI_MERGE_REQUEST_TITLE The title of the merge request if the pipelines are for merge requests. Available only if only [merge_requests] or rules syntax is used and the merge request is created. Added in GitLab 11.9 Available in GitLab Runner all CI_NODE_INDEX Index of the job in the job set. If the job is not parallelized, this variable is not set. Added in GitLab 11.5 Available in GitLab Runner all CI_NODE_TOTAL Total number of instances of this job running in parallel. If the job is not parallelized, this variable is set to 1. Added in GitLab 11.5 Available in GitLab Runner all CI_OPEN_MERGE_REQUESTS Available in branch and merge request pipelines. Contains a comma-separated list of up to four merge requests that use the current branch and project as the merge request source. For example gitlab-org/gitlab!333,gitlab-org/gitlab-foss!11. Added in GitLab 13.8 Available in GitLab Runner all CI_PAGES_DOMAIN The configured domain that hosts GitLab Pages. Added in GitLab 11.8 Available in GitLab Runner all CI_PAGES_URL URL to GitLab Pages-built pages. Always belongs to a subdomain of CI_PAGES_DOMAIN. Added in GitLab 11.8 Available in GitLab Runner all CI_PIPELINE_ID The instance-level ID of the current pipeline. This is a unique ID across all projects on GitLab. Added in GitLab 8.10 Available in GitLab Runner all CI_PIPELINE_IID The project-level IID (internal ID) of the current pipeline. This ID is unique for the current project. Added in GitLab 11.0 Available in GitLab Runner all CI_PIPELINE_SOURCE Indicates how the pipeline was triggered. Possible options are push, web, schedule, api, external, chat, webide, merge_request_event, external_pull_request_event, parent_pipeline, trigger, or pipeline. For pipelines created before GitLab 9.5, this is displayed as unknown. Added in GitLab 10.0 Available in GitLab Runner all CI_PIPELINE_TRIGGERED The flag to indicate that job was triggered. Added in GitLab all Available in GitLab Runner all CI_PIPELINE_URL Pipeline details URL. Added in GitLab 11.1 Available in GitLab Runner 0.5 CI_PROJECT_CONFIG_PATH The CI configuration path for the project. Added in GitLab 13.8 Available in GitLab Runner all CI_PROJECT_DIR The full path where the repository is cloned and where the job is run. If the GitLab Runner builds_dir parameter is set, this variable is set relative to the value of builds_dir. For more information, see Advanced configuration for GitLab Runner. Added in GitLab all Available in GitLab Runner all CI_PROJECT_ID The unique ID of the current project that GitLab CI/CD uses internally. Added in GitLab all Available in GitLab Runner all CI_PROJECT_NAME The name of the directory for the project that is being built. For example, if the project URL is gitlab.example.com/group-name/project-1, the CI_PROJECT_NAME would be project-1. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_PROJECT_NAMESPACE The project namespace (username or group name) that is being built. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_PROJECT_PATH The namespace with project name. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_PROJECT_PATH_SLUG $CI_PROJECT_PATH in lowercase and with everything except 0-9 and a-z replaced with -. Use in URLs and domain names. Added in GitLab 9.3 Available in GitLab Runner all CI_PROJECT_REPOSITORY_LANGUAGES Comma-separated, lowercase list of the languages used in the repository (for example ruby,javascript,html,css). Added in GitLab 12.3 Available in GitLab Runner all CI_PROJECT_ROOT_NAMESPACE The root project namespace (username or group name) that is being built. For example, if CI_PROJECT_NAMESPACE is root-group/child-group/grandchild-group, CI_PROJECT_ROOT_NAMESPACE would be root-group. Added in GitLab 13.2 Available in GitLab Runner 0.5 CI_PROJECT_TITLE The human-readable project name as displayed in the GitLab web interface. Added in GitLab 12.4 Available in GitLab Runner all CI_PROJECT_URL The HTTP(S) address to access project. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_PROJECT_VISIBILITY The project visibility (internal, private, public). Added in GitLab 10.3 Available in GitLab Runner all CI_REGISTRY GitLab Container Registry. This variable includes a :port value if one has been specified in the registry configuration. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_REGISTRY_IMAGE the address of the registry tied to the specific project. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_REGISTRY_PASSWORD The password to use to push containers to the GitLab Container Registry, for the current project. Added in GitLab 9.0 Available in GitLab Runner all CI_REGISTRY_USER The username to use to push containers to the GitLab Container Registry, for the current project. Added in GitLab 9.0 Available in GitLab Runner all CI_REPOSITORY_URL The URL to clone the Git repository. Added in GitLab 9.0 Available in GitLab Runner all CI_RUNNER_DESCRIPTION The description of the runner as saved in GitLab. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_RUNNER_EXECUTABLE_ARCH The OS/architecture of the GitLab Runner executable (note that this is not necessarily the same as the environment of the executor). Added in GitLab all Available in GitLab Runner 10.6 CI_RUNNER_ID The unique ID of runner being used. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_RUNNER_REVISION GitLab Runner revision that is executing the current job. Added in GitLab all Available in GitLab Runner 10.6 CI_RUNNER_SHORT_TOKEN First eight characters of the runner\u2019s token used to authenticate new job requests. Used as the runner\u2019s unique ID. Added in GitLab all Available in GitLab Runner 12.3 CI_RUNNER_TAGS The defined runner tags. Added in GitLab 8.10 Available in GitLab Runner 0.5 CI_RUNNER_VERSION GitLab Runner version that is executing the current job. Added in GitLab all Available in GitLab Runner 10.6 CI_SERVER Mark that job is executed in CI environment. Added in GitLab all Available in GitLab Runner all CI_SERVER_HOST Host component of the GitLab instance URL, without protocol and port (like gitlab.example.com). Added in GitLab 12.1 Available in GitLab Runner all CI_SERVER_NAME The name of CI server that is used to coordinate jobs. Added in GitLab all Available in GitLab Runner all CI_SERVER_PORT Port component of the GitLab instance URL, without host and protocol (like 3000). Added in GitLab 12.8 Available in GitLab Runner all CI_SERVER_PROTOCOL Protocol component of the GitLab instance URL, without host and port (like https). Added in GitLab 12.8 Available in GitLab Runner all CI_SERVER_REVISION GitLab revision that is used to schedule jobs. Added in GitLab all Available in GitLab Runner all CI_SERVER_URL The base URL of the GitLab instance, including protocol and port (like https://gitlab.example.com:8080). Added in GitLab 12.7 Available in GitLab Runner all CI_SERVER_VERSION GitLab version that is used to schedule jobs. Added in GitLab all Available in GitLab Runner all CI_SERVER_VERSION_MAJOR GitLab version major component. Added in GitLab 11.4 Available in GitLab Runner all CI_SERVER_VERSION_MINOR GitLab version minor component. Added in GitLab 11.4 Available in GitLab Runner all CI_SERVER_VERSION_PATCH GitLab version patch component. Added in GitLab 11.4 Available in GitLab Runner all CI_SHARED_ENVIRONMENT Marks that the job is executed in a shared environment (something that is persisted across CI invocations like shell or ssh executor). If the environment is shared, it is set to true, otherwise it is not defined at all. Added in GitLab all Available in GitLab Runner 10.1 GITLAB_CI Mark that job is executed in GitLab CI/CD environment. Added in GitLab all Available in GitLab Runner all GITLAB_FEATURES The comma separated list of licensed features available for your instance and plan. Added in GitLab 10.6 Available in GitLab Runner all GITLAB_USER_EMAIL The email of the user who started the job. Added in GitLab 8.12 Available in GitLab Runner all GITLAB_USER_ID The ID of the user who started the job. Added in GitLab 8.12 Available in GitLab Runner all GITLAB_USER_LOGIN The login username of the user who started the job. Added in GitLab 10.0 Available in GitLab Runner all GITLAB_USER_NAME The real name of the user who started the job. Added in GitLab 10.0 Available in GitLab Runner all TRIGGER_PAYLOAD This variable is available when a pipeline is triggered with a webhook Added in GitLab 13.9 Available in GitLab Runner all","title":"Class variables"},{"location":"reference/gcip/lib/","text":"Module gcip.lib None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' Sub-modules gcip.lib.rules","title":"Index"},{"location":"reference/gcip/lib/#module-gciplib","text":"None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com'","title":"Module gcip.lib"},{"location":"reference/gcip/lib/#sub-modules","text":"gcip.lib.rules","title":"Sub-modules"},{"location":"reference/gcip/lib/rules/","text":"Module gcip.lib.rules None None View Source from gcip.core.rule import Rule __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def on_branch ( branch_name : str ) -> Rule : return Rule ( if_statement = f '$CI_COMMIT_BRANCH == \"{branch_name}\"' ) def not_on_branch ( branch_name : str ) -> Rule : return Rule ( if_statement = f '$CI_COMMIT_BRANCH != \"{branch_name}\"' ) def on_main () -> Rule : return on_branch ( \"main\" ) def not_on_main () -> Rule : return not_on_branch ( \"main\" ) def on_master () -> Rule : return on_branch ( \"master\" ) def not_on_master () -> Rule : return not_on_branch ( \"master\" ) def on_merge_request_events () -> Rule : return Rule ( if_statement = '$CI_PIPELINE_SOURCE == \"merge_request_event\"' ) def on_success () -> Rule : return Rule () def on_pipeline_trigger () -> Rule : \"\"\" ``` if: '$CI_PIPELINE_SOURCE == \"pipeline\"' ``` From https://docs.gitlab.com/ee/ci/yaml/ |pipeline|For multi-project pipelines created by using the API with CI_JOB_TOKEN, or the trigger keyword.| \"\"\" return Rule ( if_statement = '$CI_PIPELINE_SOURCE == \"pipeline\"' ) def on_tags () -> Rule : return Rule ( if_statement = '$CI_COMMIT_TAG' ) Functions not_on_branch def not_on_branch ( branch_name : str ) -> gcip . core . rule . Rule View Source def not_on_branch ( branch_name : str ) -> Rule : return Rule ( if_statement = f '$CI_COMMIT_BRANCH != \"{branch_name}\"' ) not_on_main def not_on_main ( ) -> gcip . core . rule . Rule View Source def not_on_main () -> Rule : return not_on_branch ( \"main\" ) not_on_master def not_on_master ( ) -> gcip . core . rule . Rule View Source def not_on_master () -> Rule : return not_on_branch ( \"master\" ) on_branch def on_branch ( branch_name : str ) -> gcip . core . rule . Rule View Source def on_branch ( branch_name : str ) -> Rule : return Rule ( if_statement = f '$CI_COMMIT_BRANCH == \"{branch_name}\"' ) on_main def on_main ( ) -> gcip . core . rule . Rule View Source def on_main () -> Rule : return on_branch ( \"main\" ) on_master def on_master ( ) -> gcip . core . rule . Rule View Source def on_master () -> Rule : return on_branch ( \"master\" ) on_merge_request_events def on_merge_request_events ( ) -> gcip . core . rule . Rule View Source def on_merge_request_events () -> Rule : return Rule ( if_statement = '$CI_PIPELINE_SOURCE == \"merge_request_event\"' ) on_pipeline_trigger def on_pipeline_trigger ( ) -> gcip . core . rule . Rule if: '$CI_PIPELINE_SOURCE == \"pipeline\"' From https://docs.gitlab.com/ee/ci/yaml/ |pipeline|For multi-project pipelines created by using the API with CI_JOB_TOKEN, or the trigger keyword.| View Source def on_pipeline_trigger () -> Rule : \"\"\" ``` if: '$CI_PIPELINE_SOURCE == \" pipeline \"' ``` From https://docs.gitlab.com/ee/ci/yaml/ |pipeline|For multi-project pipelines created by using the API with CI_JOB_TOKEN, or the trigger keyword.| \"\"\" return Rule ( if_statement = '$CI_PIPELINE_SOURCE == \"pipeline\"' ) on_success def on_success ( ) -> gcip . core . rule . Rule View Source def on_success () -> Rule : return Rule () on_tags def on_tags ( ) -> gcip . core . rule . Rule View Source def on_tags () -> Rule : return Rule ( if_statement = '$CI_COMMIT_TAG' )","title":"Rules"},{"location":"reference/gcip/lib/rules/#module-gciplibrules","text":"None None View Source from gcip.core.rule import Rule __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' def on_branch ( branch_name : str ) -> Rule : return Rule ( if_statement = f '$CI_COMMIT_BRANCH == \"{branch_name}\"' ) def not_on_branch ( branch_name : str ) -> Rule : return Rule ( if_statement = f '$CI_COMMIT_BRANCH != \"{branch_name}\"' ) def on_main () -> Rule : return on_branch ( \"main\" ) def not_on_main () -> Rule : return not_on_branch ( \"main\" ) def on_master () -> Rule : return on_branch ( \"master\" ) def not_on_master () -> Rule : return not_on_branch ( \"master\" ) def on_merge_request_events () -> Rule : return Rule ( if_statement = '$CI_PIPELINE_SOURCE == \"merge_request_event\"' ) def on_success () -> Rule : return Rule () def on_pipeline_trigger () -> Rule : \"\"\" ``` if: '$CI_PIPELINE_SOURCE == \"pipeline\"' ``` From https://docs.gitlab.com/ee/ci/yaml/ |pipeline|For multi-project pipelines created by using the API with CI_JOB_TOKEN, or the trigger keyword.| \"\"\" return Rule ( if_statement = '$CI_PIPELINE_SOURCE == \"pipeline\"' ) def on_tags () -> Rule : return Rule ( if_statement = '$CI_COMMIT_TAG' )","title":"Module gcip.lib.rules"},{"location":"reference/gcip/lib/rules/#functions","text":"","title":"Functions"},{"location":"reference/gcip/lib/rules/#not_on_branch","text":"def not_on_branch ( branch_name : str ) -> gcip . core . rule . Rule View Source def not_on_branch ( branch_name : str ) -> Rule : return Rule ( if_statement = f '$CI_COMMIT_BRANCH != \"{branch_name}\"' )","title":"not_on_branch"},{"location":"reference/gcip/lib/rules/#not_on_main","text":"def not_on_main ( ) -> gcip . core . rule . Rule View Source def not_on_main () -> Rule : return not_on_branch ( \"main\" )","title":"not_on_main"},{"location":"reference/gcip/lib/rules/#not_on_master","text":"def not_on_master ( ) -> gcip . core . rule . Rule View Source def not_on_master () -> Rule : return not_on_branch ( \"master\" )","title":"not_on_master"},{"location":"reference/gcip/lib/rules/#on_branch","text":"def on_branch ( branch_name : str ) -> gcip . core . rule . Rule View Source def on_branch ( branch_name : str ) -> Rule : return Rule ( if_statement = f '$CI_COMMIT_BRANCH == \"{branch_name}\"' )","title":"on_branch"},{"location":"reference/gcip/lib/rules/#on_main","text":"def on_main ( ) -> gcip . core . rule . Rule View Source def on_main () -> Rule : return on_branch ( \"main\" )","title":"on_main"},{"location":"reference/gcip/lib/rules/#on_master","text":"def on_master ( ) -> gcip . core . rule . Rule View Source def on_master () -> Rule : return on_branch ( \"master\" )","title":"on_master"},{"location":"reference/gcip/lib/rules/#on_merge_request_events","text":"def on_merge_request_events ( ) -> gcip . core . rule . Rule View Source def on_merge_request_events () -> Rule : return Rule ( if_statement = '$CI_PIPELINE_SOURCE == \"merge_request_event\"' )","title":"on_merge_request_events"},{"location":"reference/gcip/lib/rules/#on_pipeline_trigger","text":"def on_pipeline_trigger ( ) -> gcip . core . rule . Rule if: '$CI_PIPELINE_SOURCE == \"pipeline\"' From https://docs.gitlab.com/ee/ci/yaml/ |pipeline|For multi-project pipelines created by using the API with CI_JOB_TOKEN, or the trigger keyword.| View Source def on_pipeline_trigger () -> Rule : \"\"\" ``` if: '$CI_PIPELINE_SOURCE == \" pipeline \"' ``` From https://docs.gitlab.com/ee/ci/yaml/ |pipeline|For multi-project pipelines created by using the API with CI_JOB_TOKEN, or the trigger keyword.| \"\"\" return Rule ( if_statement = '$CI_PIPELINE_SOURCE == \"pipeline\"' )","title":"on_pipeline_trigger"},{"location":"reference/gcip/lib/rules/#on_success","text":"def on_success ( ) -> gcip . core . rule . Rule View Source def on_success () -> Rule : return Rule ()","title":"on_success"},{"location":"reference/gcip/lib/rules/#on_tags","text":"def on_tags ( ) -> gcip . core . rule . Rule View Source def on_tags () -> Rule : return Rule ( if_statement = '$CI_COMMIT_TAG' )","title":"on_tags"},{"location":"reference/gcip/tools/","text":"Module gcip.tools None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' Sub-modules gcip.tools.evaluate_git_tag_pep404_conformity gcip.tools.evaluate_git_tag_semver_conformity gcip.tools.url","title":"Index"},{"location":"reference/gcip/tools/#module-gciptools","text":"None None View Source __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com'","title":"Module gcip.tools"},{"location":"reference/gcip/tools/#sub-modules","text":"gcip.tools.evaluate_git_tag_pep404_conformity gcip.tools.evaluate_git_tag_semver_conformity gcip.tools.url","title":"Sub-modules"},{"location":"reference/gcip/tools/evaluate_git_tag_pep404_conformity/","text":"Module gcip.tools.evaluate_git_tag_pep404_conformity None None View Source import os import re import sys __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' # https://www.python.org/dev/peps/pep-0440/#appendix-b-parsing-version-strings-with-regular-expressions def is_canonical ( version : str ) -> bool : return re . match ( r '^([1-9][0-9]*!)?(0|[1-9][0-9]*)(\\.(0|[1-9][0-9]*))*((a|b|rc)(0|[1-9][0-9]*))?(\\.post(0|[1-9][0-9]*))?(\\.dev(0|[1-9][0-9]*))?$' , version ) is not None if __name__ == \"__main__\" : ci_commit_tag = os . getenv ( 'CI_COMMIT_TAG' ) if ci_commit_tag is None : raise ValueError ( \"Environment variable CI_COMMIT_TAG must be set.\" ) if is_canonical ( ci_commit_tag ): sys . exit () print ( f \"'{ci_commit_tag}' is not a valid Python package version.\" ) print ( 'See https://www.python.org/dev/peps/pep-0440' ) sys . exit ( 1 ) Functions is_canonical def is_canonical ( version : str ) -> bool View Source def is_canonical ( version : str ) -> bool : return re . match ( r '^([1-9][0-9]*!)?(0|[1-9][0-9]*)(\\.(0|[1-9][0-9]*))*((a|b|rc)(0|[1-9][0-9]*))?(\\.post(0|[1-9][0-9]*))?(\\.dev(0|[1-9][0-9]*))?$' , version ) is not None","title":"Evaluate Git Tag Pep404 Conformity"},{"location":"reference/gcip/tools/evaluate_git_tag_pep404_conformity/#module-gciptoolsevaluate_git_tag_pep404_conformity","text":"None None View Source import os import re import sys __author__ = \"Thomas Steinbach\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Thomas Steinbach\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'thomas.t.steinbach@deutschebahn.com' # https://www.python.org/dev/peps/pep-0440/#appendix-b-parsing-version-strings-with-regular-expressions def is_canonical ( version : str ) -> bool : return re . match ( r '^([1-9][0-9]*!)?(0|[1-9][0-9]*)(\\.(0|[1-9][0-9]*))*((a|b|rc)(0|[1-9][0-9]*))?(\\.post(0|[1-9][0-9]*))?(\\.dev(0|[1-9][0-9]*))?$' , version ) is not None if __name__ == \"__main__\" : ci_commit_tag = os . getenv ( 'CI_COMMIT_TAG' ) if ci_commit_tag is None : raise ValueError ( \"Environment variable CI_COMMIT_TAG must be set.\" ) if is_canonical ( ci_commit_tag ): sys . exit () print ( f \"'{ci_commit_tag}' is not a valid Python package version.\" ) print ( 'See https://www.python.org/dev/peps/pep-0440' ) sys . exit ( 1 )","title":"Module gcip.tools.evaluate_git_tag_pep404_conformity"},{"location":"reference/gcip/tools/evaluate_git_tag_pep404_conformity/#functions","text":"","title":"Functions"},{"location":"reference/gcip/tools/evaluate_git_tag_pep404_conformity/#is_canonical","text":"def is_canonical ( version : str ) -> bool View Source def is_canonical ( version : str ) -> bool : return re . match ( r '^([1-9][0-9]*!)?(0|[1-9][0-9]*)(\\.(0|[1-9][0-9]*))*((a|b|rc)(0|[1-9][0-9]*))?(\\.post(0|[1-9][0-9]*))?(\\.dev(0|[1-9][0-9]*))?$' , version ) is not None","title":"is_canonical"},{"location":"reference/gcip/tools/evaluate_git_tag_semver_conformity/","text":"Module gcip.tools.evaluate_git_tag_semver_conformity None None View Source import os import re __ author__ = \"Daniel von E\u00dfen\" __ copyright__ = \"Copyright 2020 DB Systel GmbH\" __ credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __ license__ = \"Apache-2.0\" __ maintainer__ = \"Thomas Steinbach\" __ email__ = \"thomas.t.steinbach@deutschebahn.com\" def is_semver ( version : str ) -> bool : \"\"\" Checks if `version` is semver compliant. :param version: Version number to check for compliance. :type version: str :return: True if `version` is semver compliant, otherwise false. :rtype: bool \"\"\" return re . match ( ( r \" ^ ( ? P < major > 0 |[ 1 - 9 ] \\d* ) \\. ( ? P < minor > 0 |[ 1 - 9 ] \\d* ) \\. ( ? P < patch > 0 |[ 1 - 9 ] \\d* ) \" r\" ( ?:- ( ? P < prerelease> ( ?: 0 |[ 1 - 9 ] \\d* | \\d * [ a - zA - Z - ][ 0 - 9 a - zA - Z - ] * ) \" r\" ( ?:\\. ( ?: 0 |[ 1 - 9 ] \\d* | \\d * [ a - zA - Z - ][ 0 - 9 a - zA - Z - ] * )) * )) ? ( ?:\\+ ( ? P < buildmetadata > [ 0 - 9 a - zA - Z - ] + ( ?:\\. [ 0 - 9 a - zA - Z - ] + ) * )) ? $ \" ), version ) is not None if __name__ == \" __ main__ \": ci_commit_tag = os.getenv(\" CI_COMMIT_TAG \") if ci_commit_tag is None: raise ValueError(\" Environment variable CI_COMMIT_TAG must be set . \") if not is_semver(ci_commit_tag): raise ValueError(f\" '{ci_commit_tag}' is not a valid Semver version . https : // semver . org/ \" ) Functions is_semver def is_semver ( version : str ) -> bool Checks if version is semver compliant. Parameters: Name Type Description Default version None Version number to check for compliance. None Returns: Type Description None True if version is semver compliant, otherwise false. View Source def is_semver ( version : str ) -> bool : \"\"\" Checks if `version` is semver compliant. :param version: Version number to check for compliance. :type version: str :return: True if `version` is semver compliant, otherwise false. :rtype: bool \"\"\" return re . match ( ( r \" ^ ( ? P < major > 0 |[ 1 - 9 ] \\d* ) \\. ( ? P < minor > 0 |[ 1 - 9 ] \\d* ) \\. ( ? P < patch > 0 |[ 1 - 9 ] \\d* ) \" r\" ( ?:- ( ? P < prerelease> ( ?: 0 |[ 1 - 9 ] \\d* | \\d * [ a - zA - Z - ][ 0 - 9 a - zA - Z - ] * ) \" r\" ( ?:\\. ( ?: 0 |[ 1 - 9 ] \\d* | \\d * [ a - zA - Z - ][ 0 - 9 a - zA - Z - ] * )) * )) ? ( ?:\\+ ( ? P < buildmetadata > [ 0 - 9 a - zA - Z - ] + ( ?:\\. [ 0 - 9 a - zA - Z - ] + ) * )) ? $\" ), version ) is not None","title":"Evaluate Git Tag Semver Conformity"},{"location":"reference/gcip/tools/evaluate_git_tag_semver_conformity/#module-gciptoolsevaluate_git_tag_semver_conformity","text":"None None View Source import os import re __ author__ = \"Daniel von E\u00dfen\" __ copyright__ = \"Copyright 2020 DB Systel GmbH\" __ credits__ = [ \"Thomas Steinbach\" ] # SPDX - License - Identifier : Apache - 2.0 __ license__ = \"Apache-2.0\" __ maintainer__ = \"Thomas Steinbach\" __ email__ = \"thomas.t.steinbach@deutschebahn.com\" def is_semver ( version : str ) -> bool : \"\"\" Checks if `version` is semver compliant. :param version: Version number to check for compliance. :type version: str :return: True if `version` is semver compliant, otherwise false. :rtype: bool \"\"\" return re . match ( ( r \" ^ ( ? P < major > 0 |[ 1 - 9 ] \\d* ) \\. ( ? P < minor > 0 |[ 1 - 9 ] \\d* ) \\. ( ? P < patch > 0 |[ 1 - 9 ] \\d* ) \" r\" ( ?:- ( ? P < prerelease> ( ?: 0 |[ 1 - 9 ] \\d* | \\d * [ a - zA - Z - ][ 0 - 9 a - zA - Z - ] * ) \" r\" ( ?:\\. ( ?: 0 |[ 1 - 9 ] \\d* | \\d * [ a - zA - Z - ][ 0 - 9 a - zA - Z - ] * )) * )) ? ( ?:\\+ ( ? P < buildmetadata > [ 0 - 9 a - zA - Z - ] + ( ?:\\. [ 0 - 9 a - zA - Z - ] + ) * )) ? $ \" ), version ) is not None if __name__ == \" __ main__ \": ci_commit_tag = os.getenv(\" CI_COMMIT_TAG \") if ci_commit_tag is None: raise ValueError(\" Environment variable CI_COMMIT_TAG must be set . \") if not is_semver(ci_commit_tag): raise ValueError(f\" '{ci_commit_tag}' is not a valid Semver version . https : // semver . org/ \" )","title":"Module gcip.tools.evaluate_git_tag_semver_conformity"},{"location":"reference/gcip/tools/evaluate_git_tag_semver_conformity/#functions","text":"","title":"Functions"},{"location":"reference/gcip/tools/evaluate_git_tag_semver_conformity/#is_semver","text":"def is_semver ( version : str ) -> bool Checks if version is semver compliant. Parameters: Name Type Description Default version None Version number to check for compliance. None Returns: Type Description None True if version is semver compliant, otherwise false. View Source def is_semver ( version : str ) -> bool : \"\"\" Checks if `version` is semver compliant. :param version: Version number to check for compliance. :type version: str :return: True if `version` is semver compliant, otherwise false. :rtype: bool \"\"\" return re . match ( ( r \" ^ ( ? P < major > 0 |[ 1 - 9 ] \\d* ) \\. ( ? P < minor > 0 |[ 1 - 9 ] \\d* ) \\. ( ? P < patch > 0 |[ 1 - 9 ] \\d* ) \" r\" ( ?:- ( ? P < prerelease> ( ?: 0 |[ 1 - 9 ] \\d* | \\d * [ a - zA - Z - ][ 0 - 9 a - zA - Z - ] * ) \" r\" ( ?:\\. ( ?: 0 |[ 1 - 9 ] \\d* | \\d * [ a - zA - Z - ][ 0 - 9 a - zA - Z - ] * )) * )) ? ( ?:\\+ ( ? P < buildmetadata > [ 0 - 9 a - zA - Z - ] + ( ?:\\. [ 0 - 9 a - zA - Z - ] + ) * )) ? $\" ), version ) is not None","title":"is_semver"},{"location":"reference/gcip/tools/url/","text":"Module gcip.tools.url None None View Source import re __author__ = \"Daniel von E\u00dfen\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'daniel.von-essen@deutschebahn.com' def is_valid_url ( url : str ) -> bool : \"\"\" Validates given `url`. Implementation details 1. https://stackoverflow.com/a/7160778 2. https://github.com/django/django/blob/6726d750979a7c29e0dd866b4ea367eef7c8a420/django/core/validators.py#L45 Args: url (str): Uniform Resource Locator (URL) to check. Returns: bool: ``True`` if ``url`` is valid. If not, ``False`` is returned. \"\"\" regex = re . compile ( r '^(?:http|ftp)s?://' # http:// or https:// r '(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' # domain... r 'localhost|' # localhost... r '\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip r '(?::\\d+)?' # optional port r '(?:/?|[/?]\\S+)$' , re . IGNORECASE ) return re . match ( regex , url ) is not None Functions is_valid_url def is_valid_url ( url : str ) -> bool Validates given url . Implementation details 1. https://stackoverflow.com/a/7160778 2. https://github.com/django/django/blob/6726d750979a7c29e0dd866b4ea367eef7c8a420/django/core/validators.py#L45 Parameters: Name Type Description Default url str Uniform Resource Locator (URL) to check. None Returns: Type Description bool True if url is valid. If not, False is returned. View Source def is_valid_url ( url : str ) -> bool : \" \"\" Validates given `url`. Implementation details 1. https://stackoverflow.com/a/7160778 2. https://github.com/django/django/blob/6726d750979a7c29e0dd866b4ea367eef7c8a420/django/core/validators.py#L45 Args: url (str): Uniform Resource Locator (URL) to check. Returns: bool: ``True`` if ``url`` is valid. If not, ``False`` is returned. \"\" \" regex = re . compile ( r '^(?:http|ftp)s?://' # http:// or https:// r '(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])? \\ .)+(?:[A-Z]{2,6} \\ .?|[A-Z0-9-]{2,} \\ .?)|' # domain... r 'localhost|' # localhost... r ' \\ d{1,3} \\ . \\ d{1,3} \\ . \\ d{1,3} \\ . \\ d{1,3})' # ...or ip r '(?:: \\ d+)?' # optional port r '(?:/?|[/?] \\ S+)$' , re . IGNORECASE ) return re . match ( regex , url ) is not None","title":"Url"},{"location":"reference/gcip/tools/url/#module-gciptoolsurl","text":"None None View Source import re __author__ = \"Daniel von E\u00dfen\" __copyright__ = \"Copyright 2020 DB Systel GmbH\" __credits__ = [ \"Daniel von E\u00dfen\" ] # SPDX-License-Identifier: Apache-2.0 __license__ = 'Apache-2.0' __maintainer__ = 'Thomas Steinbach' __email__ = 'daniel.von-essen@deutschebahn.com' def is_valid_url ( url : str ) -> bool : \"\"\" Validates given `url`. Implementation details 1. https://stackoverflow.com/a/7160778 2. https://github.com/django/django/blob/6726d750979a7c29e0dd866b4ea367eef7c8a420/django/core/validators.py#L45 Args: url (str): Uniform Resource Locator (URL) to check. Returns: bool: ``True`` if ``url`` is valid. If not, ``False`` is returned. \"\"\" regex = re . compile ( r '^(?:http|ftp)s?://' # http:// or https:// r '(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' # domain... r 'localhost|' # localhost... r '\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip r '(?::\\d+)?' # optional port r '(?:/?|[/?]\\S+)$' , re . IGNORECASE ) return re . match ( regex , url ) is not None","title":"Module gcip.tools.url"},{"location":"reference/gcip/tools/url/#functions","text":"","title":"Functions"},{"location":"reference/gcip/tools/url/#is_valid_url","text":"def is_valid_url ( url : str ) -> bool Validates given url . Implementation details 1. https://stackoverflow.com/a/7160778 2. https://github.com/django/django/blob/6726d750979a7c29e0dd866b4ea367eef7c8a420/django/core/validators.py#L45 Parameters: Name Type Description Default url str Uniform Resource Locator (URL) to check. None Returns: Type Description bool True if url is valid. If not, False is returned. View Source def is_valid_url ( url : str ) -> bool : \" \"\" Validates given `url`. Implementation details 1. https://stackoverflow.com/a/7160778 2. https://github.com/django/django/blob/6726d750979a7c29e0dd866b4ea367eef7c8a420/django/core/validators.py#L45 Args: url (str): Uniform Resource Locator (URL) to check. Returns: bool: ``True`` if ``url`` is valid. If not, ``False`` is returned. \"\" \" regex = re . compile ( r '^(?:http|ftp)s?://' # http:// or https:// r '(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])? \\ .)+(?:[A-Z]{2,6} \\ .?|[A-Z0-9-]{2,} \\ .?)|' # domain... r 'localhost|' # localhost... r ' \\ d{1,3} \\ . \\ d{1,3} \\ . \\ d{1,3} \\ . \\ d{1,3})' # ...or ip r '(?:: \\ d+)?' # optional port r '(?:/?|[/?] \\ S+)$' , re . IGNORECASE ) return re . match ( regex , url ) is not None","title":"is_valid_url"}]}